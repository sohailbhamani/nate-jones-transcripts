---
title: "OpenAI: Voice Mode is out!"
video_id: "zqv5jhzD-h8"
youtube_url: "https://www.youtube.com/watch?v=zqv5jhzD-h8"
substack_url: null
publish_date: "2024-09-24"
duration: "5:00"
duration_seconds: 300
view_count: 760
author: "AI News & Strategy Daily | Nate B Jones"

yt_tags:
  []



# AI-enriched metadata
content_type: "Framework"
primary_topic: "AI Strategy"
difficulty: "Intermediate"
audience:
  - "Executives"
  - "Product Managers"
entities:
  companies:
    - "OpenAI"
    - "YouTube"
  people:
    []
  products:
    - "Make"
  models:
    []
concepts:
  []
summary:
  []
keywords:
  - "ai-news"
  - "ai-strategy"
  - "frameworks"
  - "leadership"
  - "make"
  - "openai"
  - "product-management"
  - "tutorials"
  - "workflows"
  - "youtube"
---

# OpenAI: Voice Mode is out!

guess who finally dropped voice mode that's right open Ai and it's funny because they came out and they did this whole national news build momentum thing where they did simultaneous translation in different languages all of that was six months ago they did the pr Blitz already and then nothing happened and now all they do is drop a tweet and say hey by the way we're rolling out voice mode to everyone who's gone a plus plan over the next few days and it can say I'm sorry I'm late in 50 languages which credit to them right this is the thing with open AI they have to show momentum and so in these situations when they actually have something to drop the drop is the momentum and they don't have to make a Big Splash in other cases they will show their flag and they will wave their flag early to indicate momentum and just buy themselves a few months to finish the feature it's actually a very distinct corporate strategy for them if you watch their release pattern you can see it over and over again but in addition to saying it's out I want to talk about the design implications of voice mode because I've played around with it and it is making me realize how generative systems require different thinking for designers fundamentally when you are using an llm you are exploring the latent space of that llm so the llm basically has been trained on this massive massive data set for a shorthand would be the whole internet right everything we've ever written ever and a lot of YouTube and if that's the case at the end of the day your queries are the only Guiding Light into that giant latent space and so your mental model of what the system knows and how it responds is absolutely critical to understanding how to get it to respond in a way that's useful to you and when I Ed voice mode I realized how much I have been missing talking to llms I've only been talking to them in writing my writing has been more formal it's been more structured it's been more like a product manager I am expecting quick responses I'm expecting clear responses I'm expecting it to go quickly well voice Mode's different voice Mode's like a conversation I found myself not minding that it took a little bit to respond in fact they did this funny little thing I have no idea if it's real like if it's actually thinking or not but every few seconds I would get some haptic feedback on my iPhone that basically said hey I'm still here I'm still thinking at least that's the impression it Formed for me it could be entirely artificial I don't really care it was a good design experience because I've paid attention I believed it was thinking and I was not minding the weight because you have silences and conversations with people and that's the key voice seems to be a key for me in a lot of others for unlocking more humanlike conversations with AI I found myself getting into more creative relaxed brainstorming latent space with the llm than I had ever done before very very quickly I was more conversational I was looser and it was a super productive and engaging conversation it wasn't even with their newest model it was with 40 and I felt like I was talking to a helpful brainstorming companion it felt like talking to a person for that moment and I walked way feeling like I'd had a productive exchange with someone who felt a little artificial but who had helped me move my thinking process forward and who was going to be a frequent conversationalist in my life like I would go back and talk again and the key is that designed experience with voice unlocked something in my brain that allowed me to ask for something different in the lm's latent space I became lucer and more relaxed and so I was able to access more of the brainstorming qualities of the AI that is part of what makes AI application so tricky we have to change our own mindsets to work effectively with artificial intelligence we have to figure out what they can do well and not well evolve that understanding as their models get better and also recognize that we ourselves are learning and our understanding of that latent space is still evolving and can change with particular modes of interaction it's multi-dimensional complexity hats off to all the designers out there who are working through AI design problems you guys have the design challenge of a lifetime it's really exciting to see what's going on out there I for one I'm going to be having fun playing with voice mode I'm sure I'll work some voice mode into my Maven uh free lightning lesson on October 3D if you haven't signed up you can go grab that I think there's a lot of potential here both for work and uh for after workor for personal stuff I can see planning a vacation with this thing really easily so there you go advanced voice mode is out what do you think
