---
title: "Gemini 3 Just Rewired Product, Engineering, and Marketing Jobs"
video_id: "_Z-YppWti1E"
youtube_url: "https://www.youtube.com/watch?v=_Z-YppWti1E"
substack_url: "https://natesnewsletter.substack.com/p/how-gemini-3-changes-your-job-a-practical?r=1z4sm5&utm_campaign=post&utm_medium=web&showWelcomeOnShare=true"
publish_date: "2025-11-19"
duration: "22:00"
duration_seconds: 1320
view_count: 59431
author: "AI News & Strategy Daily | Nate B Jones"

yt_tags:
  - "AI strategy"
  - "AI jobs"
  - "AI labor market"
  - "future of work"
  - "large language models"
  - "AI agents"
  - "prompt engineering"
  - "automation at work"
  - "Gemini 3"
  - "antigravity editor"
  - "product managers"
  - "engineers"
  - "marketers"
  - "designers"
  - "customer support"
  - "video analysis"
  - "UI debugging"
  - "AI platform teams"
  - "AI strategy for teams"



# AI-enriched metadata
content_type: "Framework"
primary_topic: "AI Strategy"
difficulty: "Intermediate"
audience:
  - "Engineers"
  - "Executives"
  - "Product Managers"
entities:
  companies:
    - "Anthropic"
    - "Google"
    - "Box"
    - "Cursor"
    - "LinkedIn"
    - "Lovable"
  people:
    []
  products:
    - "Claude"
    - "Claude Code"
    - "Gemini"
    - "Cursor"
    - "Make"
    - "MCP"
    - "Artifacts"
    - "Projects"
  models:
    - "Gemini"
    - "Gemini 3"
concepts:
  - "If you think one staff engineer who's a champion on ai can just do this, you're probably underinvested"
summary:
  - "# Gemini 3 Just Rewired Product, Engineering, and Marketing Jobs

Gemini 3 came out and it is the number one model in the world"
keywords:
  - "ai-agents"
  - "ai-strategy"
  - "ai-tools"
  - "anthropic"
  - "artifacts"
  - "box"
  - "career"
  - "claude"
  - "claude-code"
  - "coding"
  - "cursor"
  - "frameworks"
  - "gemini"
  - "google"
  - "leadership"
  - "linkedin"
  - "lovable"
  - "make"
  - "mcp"
  - "product-management"
  - "projects"
  - "prompting"
  - "tutorials"
  - "workflows"
---

# Gemini 3 Just Rewired Product, Engineering, and Marketing Jobs

Gemini 3 came out and it is the number one model in the world. What does that mean for all of us and what does that mean for particular jobs like product manager, engineer, marketer? I'm going to get into both of those in this video and we're going to start with the overall takeaways. Number one, the unit of strategy is no longer the model. You should not be asking which frontier model is best. And I realize that's ironic because we're talking about Gemini 3 as the number one model, but really what you should take away is that Gemini 3 makes it unavoidable to ask which model is best for which workflow because it is clearly a lot better at some things like video screens, handling huge context, and it's not as obviously better at others like persuasive writing or everyday chat. So the implication is if you're still arguing and saying we're an open AI shop, that's all we do. Or we're an anthropic shop, that's all we do. You're kind of missing the plot. Someone in your org needs to own the routing layer. And I want to suggest a very, very cheap, easy, usefully incorrect abstraction for you. Every abstraction is incorrect. Some of them are useful. I think this one is useful. If it is a see or do task, think about Gemini 3. If it is a write or talk task, think about claude and chat GPT. If it is a cheap bulk task, you got to go with some small flash models. Is that going to work for every single thing? Absolutely not. Is it a nice handy abstraction that you can work with? Yeah, it fits on a flash card. Takeaway number two, Gemini 3 turns AI silent zones into AI native territory. There are places where AI has been silent in the past. That's no longer true. Let me give you a few examples. Before Gemini 3, a lot of high-value surfaces that we computed with were effectively dark to AI, right? Raw user interfaces and dashboards. We didn't always get great results coding them. We didn't always get great great results designing them. We didn't always get great results figuring out what they said, right? The being able to analyze them. Long messy video definitely was dark to LLMs. Giant piles of code with docs and screenshots. We are making progress there. There's definitely examples that I've seen with cloud code and codecs, but it's not necessarily a super easy space for most AIs to operate. You needed humans to try and digest some of that long and messy context and summarize it before an AI could do anything useful. So, Gemini 3's real unlock is that those surfaces are starting to become legible. Gemini 3 can read the UI directly instead of guessing from the logs. Gemini 3 can watch footage instead of just reading transcripts. Gemini 3 can digest much bigger chunks of everything related to this system at once. So the most interesting new new workflows won't be better chat. There'll be new places you can use AI that you couldn't before like UI debugging, like design QA, like maybe admin panel automation of some sort, maybe figuring out how to do video research or user testing. So a good question to ask each of your teams right now or ask yourself is where do I have a lot of eyes on the glass work today? Gemini is probably more relevant there. Takeaway number three, the hard skill now is specification and review, not figuring out the keystrokes. So models are getting better and better at doing and the bottleneck is starting to shift toward telling them what to do and deciding whether that's an acceptable choice. I think that Gemini 3 plus the new anti-gravity code editor makes this very literal because in anti-gravity agents propose terminal commands, they propose code diffs, they have browser actions, and you approve or reject their artifacts, their plans, their patches, their refactor proposals. That's not really prompt engineering in the sense that it gets made fun of. It's much closer to working with a colleague to write a runbook, to design a spec, to do fast and highquality code. I'm not here to tell you that this is the only way to develop. One thing I know having worked with engineers for a couple of decades is every engineer has a stack that feels ergonomic to them. Some are finding anti-gravity really compelling and easy. Others are preferring to stick with cursor, are preferring to stick with codeex or preferring to stick with claw code. All viable AI options. The thing I want you to know, regardless of which you prefer, is that anti-gravity is shifting our sense of how we pay attention in coding in ways that we all need to understand, even if you're not a coder. Because what anti-gravity does is it dares you to focus on where you need to intervene with an agent that's building something rather than to focus you on the code side of things. And we have seen glimpses of this in the direction that cursor is evolving. But anti-gravity really really leans in. And I think that this implies that a lot of the great work that we do going forward is going to look weirdly similar for great product managers and great tech leads because it's going to to be work that is done by people who can describe what they want built really really clearly and who can smell a bad artifact really really quickly. That is absolutely a vibe thing but anyone who has worked around code will tell you it's true. And so really, you should evaluate how you want to work with Gemini less in terms of its ability to purely write code and more in terms of your ability to articulate intent, see useful results, and your ability to quickly refine and review. Increasingly the models will get there on the code that needs to be done but you need to be the one who is given space to review, refine, pay attention and decide what's acceptable. The models and the interfaces that make it easier for you to get your hands on the work and decide what's acceptable are the ones that are going to win. And so I think anti-gravity is an interesting development in the AI landscape for exactly that reason because that's where Google is focusing you. Takeaway number four, context abundance is just going to change where you pay your cognitive taxes. So a million token context window and very strong retrieval does not mean hey dump in your knowledge base and go to sleep. It does shift where you spend your effort. So you spend a lot less time curating perfect little packets of context, but you're going to spend a lot more time deciding what is the shape of the question that is worth asking. How do I want this answer structured? Gemini is now good enough that the marginal return on another hour of cleaning the context window is often lower than the marginal return on a better question and a better output format. And the implication is pretty stark. you need to start thinking in terms of query design and not just data preparation. So as an example and I know not every repo is this small but given that we can throw in a chunk of the repo and docs what is the most valuable question to ask as an engineer or what structured artifact do we want back here? Do we want a diff? Do we want a table? Do we want a synthesis of the data in some fashion? Do we want a solid six pager? What is the output? Teams that are excellent at asking sharp questions and at defining outputs are going to start to run ahead of teams that obsess over shaving a little bit of noise out of the context window. Takeaway number five is that safety is becoming a visible part of the user experience. This is not a policy PDF anymore. Anti-gravity is designed around the idea that safety guard rails need to be visible. So the whole idea of draft for approval flows, the clear separation between suggestion and execution, the ability to review the plans of the agents, the ability to view diffs really cleanly in anti-gravity. Essentially, Google is putting their money where their mouth is and saying that they want design of our surfaces to reflect the need for humans to be deeply engaged with what models should and shouldn't do. And I appreciate that because I think we need a lot more work in that direction. We need more user interfaces that help us to put our hands on what the models are doing. Takeaway number six is actually for us and for our teams. AI operations is becoming a fullfledged headcount function. It is not a hobby job. And so once you start to accept the idea that some tasks go to Gemini, some tasks go to Claude, some tasks go to chat GPT, who maintains that? Who maintains the prompts? who maintains the tools and the artifacts, who teaches teams how to work with these different layers. This is part software engineering, part product management, part platform team. We're still evolving what the role means. But fundamentally, if you think one staff engineer who's a champion on AI can just do this, you're probably underinvested. One very reasonable 2025 move is to explicitly charter an AI platform group and give them a mandate around how they handle routing, how they handle internal education, how they handle shared prompts. give them a charter that is big enough that they can evolve the impact of AI across the organization because these models are going to keep getting better in specific areas and you need a team that champions moving workflows where it makes sense. And I'm going to get into the job functions in a second and start to give you a few hints as to where I see that happening with Gemini 3. Takeaway number seven, your intuitions about this model. And I will go so far as to say almost any model from here on out are almost certainly incorrect if you only test chat stuff. So if your lived experience with these models is biased toward writing emails or just answer me this question or very light coding or just summarize this doc quickly, these are exactly the areas where Gemini 3's advantage is the least visible. So if you poke around in chat for an hour and conclude it's not that different, you're not wrong. you're just looking in the wrong place. So, I would suggest to you if that's you, don't judge Gemini 3 on your first 10 prompts. Instead, ask yourself, does this give me the ability to imagine accelerating a piece of work that used to be off limits? And I'm trying to go through these takeaways in such a way that you can open your imagination and see some possibilities. Okay, now it's time to get into takeaways for job families. We're going to go job family by job family and I'm going to lay out where I think Gemini 3 has an opportunity to help uh and maybe where there's some nuance and maybe where Claude or Chad GPT should still be on the list. For product managers, you can now treat UX and video artifacts as first class inputs and not homework you have to watch to get into the AI. This is a big deal because it simplifies a lot of early discovery and user experience. You can ask Gemini 3 directly for opinions on these artifacts in a way you couldn't before. You can ask Gemini 3 for competitive analysis across raw input data on an app video recording. Now, I'm not here to say that Gemini 3 is the only thing you should be using narrative prder documents emails where you want maximal clarity. I would still stick with claude particularly set 4.5. I don't find that Gemini 3's persuasive writing is there yet. For marketers, you have a lot of really interesting workflows that open up as well. Similarly, in the video and visual space, you could ask things like, "What patterns do you see in our winning Tik Toks? What's visually different between our high click-through rate and our low click-through rate ads?" And you're going to get really structured takes that you just would not get from AI before. And so, post hawk creative analysis is really interesting. you have the chance to do some creative asset audits that you didn't have before. But again, I'm going to say I don't think it's going to be as easy to get brand voice, especially punchy brand voice out of Gemini 3. On the customer support and op side, think about tickets with screenshots. Now, not just tickets as strings of text, right? You can actually look at cluster these issues by what's broken on the screen, right? You can take a screenshot. you can look at tickets and Gemini 3 can put that together. Again, AI couldn't do that before. And so if you want to do something around an automated triage workflow, you want to tag parts of the UI to places that are broken in your customers supports, if you want to draft actions on admin panels and like play around with aic workflows, all things that Gemini 3 would be interesting to explore for. What stays on Claude or chat GPT is going to be that text piece. Again, I would actually lean on Claude for that. Chat GPT even after 5.1 is not as easy to work with. Sales, you want to think about call reviews here. How can you think about slides, faces, body language in a more structured way and not just feed AI transcripts? How do you start to think about really heavy lifting with Gemini 3 on RFP compliance or on contract comparisons or on video call analytics? You can do things like say summarize this 60-minute discovery call and white paper for my next meeting. Stuff like that is becoming possible in a way that it just wasn't before. What stays in claw or chat GPT? Cold outreach, follow-ups, LinkedIn messages. The conversational style layer is again not really there. Are you seeing a pattern? Executives and leadership, there's some really interesting takeaways here. You can ask where is there a difference between what the deck is telling me and what the raw KPI tables are telling me. I know a lot of execs who would love that one. Uh where is and by the way that is something that if you are presenting you should assume your exec will now be asking. You can ask how do I digest a large mixed packet like a board deck with annexes with screenshots with uh a whole set of data tables? How can I make this digestible as a single object with really good synthesis? Gemini 3 is good at that. Gemini 3 also makes presentations. I find that the visual style is quite creative. The narrative piece again is not quite where Claude is. front-end engineers. Look, UI state and visual bugs are now something the model can see. It's a massive breakthrough. The model is also much easier to push out of that blue purple convergence that it's been stuck in. And so visual debugging is easier, design QA is easier, accessibility QA is easier. Now, if you're doing some of the simple bug fixes, some of the simple tweaks, it doesn't really matter what model you're using. And if you're looking at what is your overall day-to-day model on front end, I think you are going to have to start to code up parallel projects in Gemini 3 codeex and clog code and see where the model feels ergonomic for you. I'll say it again with engineers, the fit of the model is a personal thing. And so as much as I can say, look, the model is better at seeing bugs and you should use it for QA, your daily coding driver is something that in part depends on your degree of comfort with how autonomous the model is and how often it checks in and how much code it burns and how many tokens it burns along the way. And so you need to test it and decide if it's worth switching from codeex or clock code. All I will tell you is you are probably incorrect if you're unwilling to test. I think it is worth a shot. Backend and platform engineers, you can now productively ask, here's the whole service, the code, the configs, the runbooks, the diagrams. Help me reason and think about this. And you don't have to elaborately shard the context window unless it's very very large. And so terminal terminal agents and sort of the way you engage with assistants are beginning to evolve for you. You can start to actually have a assistant that you supervise. And I felt that when I started to play with anti-gravity and we are starting to get that a bit with codeex as well and with cloud code. So this is very much something where we should expect the model makers to continue to push. The thing that I will call out is that it is handy to have the large context window and it is worth it to ask yourself if that large context window is something you need for a particular debugging task. I have less determined opinions here on debugging on backend. It may well be that codeex is still very very strong at debugging complex code bases. It just for lack of a better term, there's a special smell to it and it's solid. Just as for lack of a better term, there's a special smell to claude code and the way it can work within an ecosystem of skills and MCP and write good code. Those are both strengths and that's why I keep coming back to its ergonomics. You'd be wrong not to test it. It's going to be a matter of fit for you on the coding side. For designers, this is absolutely revolutionary. The model can critique, it can compare, it can spot inconsistencies in UIs, it can see, right? You can feed it screens. And so, if you are not using Gemini 3, you are absolutely missing out as a designer. It's big. This model is also going to help you to translate visual intent into code ready descriptions for engineers. And so being able to say this layout is whatever it is technically is something that Gemini 3 can really help you with because it can see the design. For data analysts, the boundary between data in your dashboard and data in your documents keeps getting thinner because you can treat screenshots and PDFs and CSVs as one blob of evidence and ask for conclusions and it can be one big conversation. Right? A quarterly or multi-report analysis might stay inside one context window and not be spread across a dozen chats. So having that exploratory analysis is really helpful. I think I would not use it to substitute for SQL. I feel like I have to say that. I hope you know that that's obvious. If you want it to start to draft SQL for you, it and Chad GPT and Claude are all going to do that. Well, if you want it to write Pandas code for you, it will do that, but so will Chad GPT and so will Claude. Really at that point it's just about tight code feedback loops and it's very table stakes. If you are in the video space it is required like you have to start working with this model. This model can be helpful in suggesting how long footage can be turned into candidate timelines that you can then refine in a cut. It can help with pacing. It can help with rough cuts. It can help with show me the good hooks in this recording. There's all kinds of things it can help with and we are just scratching the surface on this. Video is one of the places I'm most bullish on for Gemini 3. AI enthusiasts and vibe coders, you get to play with agents that use an editor, a terminal, and a browser together without building a specific harness to do that. That is by itself a big deal. And so that means that we are going to start to see small admin tasks and small personal desktop automation tasks get interesting. And we're going to start to see frameworks for that. And there's going to be a whole lot of build around that. And so Gemini 3 fits in a world where you're tinkering with environments like anti-gravity. It fits in a world where you are building proof of concept workflows. If you are still looking for the polished website that you can launch quickly with a minimum of fuss, lovable.dev is great. If you are still looking to do a comprehensive review of an ecosystem with markdown files and touching all the files on your computer and you have your cloud code all set up to do that, Gemini 3 is going to have a high bar to climb, right? It may be more intelligence, but it's it's a brain in a box and you have the hooks from MCP and you have the tools that you need with cloud code and you don't want to touch it. Fair. I would say try it and see what you think. If you're using codecs, codecs may have the power that you want from a debugging perspective, and you may not feel that you miss the planning and review and agentic thinking that anti-gravity lets you do. Try it. You'll see. I'm not saying you'll like it. I'm not saying you'll hate it. I think it's worth a try. This gets back to the engineering side where people get comfortable with cloud code. We get comfortable with codecs. And that comfort in and of itself drives productivity. And so I want to be careful, but I want to suggest that you should at least give Gemini F3 a try, a fair shake, and see how it does. If we zoom out across all of these job families, I think we see some pretty consistent patterns. Gemini 3 is for the work that you do with your eyes and your patients. Claude or chat GPT tend to be for work that you do with your voice and your keyboard. And so one of the simpler questions I would encourage you to ask is where am I stuck watching, scrolling, clicking, and reading for hours and I I just need to understand what's going on. Those are great Gemini 3 candidates. So summing it all up, Gemini 3 is beyond the benchmarks a fascinating push for all of us to start to think intentionally about where our workflows are focused on seeing and doing versus where our workflows are focused on talking, where our workflows are focused on writing. I think that we're going to see a ton of really interesting use cases explode out. I think anti-gravity is super exciting. I think the video application is exciting. We're just at the beginning of seeing what this model can do.
