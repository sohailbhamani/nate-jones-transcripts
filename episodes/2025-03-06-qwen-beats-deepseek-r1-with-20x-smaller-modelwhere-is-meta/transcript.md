---
title: "Qwen Beats DeepSeek R1 with 20x Smaller Model—where is Meta?"
video_id: "OzMZI9Hcs-k"
youtube_url: "https://www.youtube.com/watch?v=OzMZI9Hcs-k"
substack_url: null
publish_date: "2025-03-06"
duration: "3:24"
duration_seconds: 204
view_count: 4042
author: "AI News & Strategy Daily | Nate B Jones"

yt_tags:
  []



# AI-enriched metadata
content_type: "Framework"
primary_topic: "AI Strategy"
difficulty: "Intermediate"
audience:
  - "Engineers"
entities:
  companies:
    - "Meta"
  people:
    []
  products:
    []
  models:
    - "Llama"
    - "Qwen"
    - "DeepSeek"
concepts:
  []
summary:
  - "# Qwen Beats DeepSeek R1 with 20x Smaller Model—where is Meta"
keywords:
  - "ai-agents"
  - "ai-news"
  - "career"
  - "coding"
  - "frameworks"
  - "meta"
---

# Qwen Beats DeepSeek R1 with 20x Smaller Model—where is Meta?

quen was released yesterday it's a 32 billion parameter model which obviously sounds big but is not actually big uh not certainly not compared to the larger 600 and change parameter models that are out there now uh in particular I'm saying 600 and change billion parameters because qwq 32b is equivalent to the 671 billion parameter deep seek R1 and so if you're keeping track at home deep seek had a nice TW month run where it was considered sort of state-of-the-art for open- Source models and now you have a model that's approximately 20 times smaller that does a phenomenal job of matching deep seek uh capabilities on specified tasks like coding reasoning Etc now there's a ton of advantages to smaller models they're mostly intuitive right lower costs faster response time more accessibility it's just easier to run them right uh and you might wonder how did quen do this well they released a paper and they say they did it by using really aggressive reinforcement learning which makes a lot of sense so if you're giving the agent rewards for policies all the time and giving it negative rewards where it doesn't give the response you want you're going to be able to tune the model against specific tasks really cleanly in a small parameter space the problem is that smaller models tend to be less stable and so I've seen reports where quen will sometimes lose train of thought or sometimes Circle back on itself um or sometimes sort of change its own point of view and argue against itself in the same sort of chat within a small context window those kinds of slippages are somewhat common for small models because small models don't have the larger context to draw from that gives them a stable place to respond when they are not specifically inside a particular reinforcement Lear earning Lane uh and so if you want broad general knowledge I would not expect that quen 32b is going to be phenomenal at that uh I think you will feel the difference I like to think of it as a um a more brittle model think of it uh visually as a glass Arrow it can be pointed at the center of the target it can hit it it can deliver extraordinary performance for things it's been trained for but it's fragile um and it may not do as well outside those specific use cases so that's quen and if you're wondering the the big question here is what happens to meta Because deep seek has already announced R2 they don't want to wait uh meta has reportedly delayed llama 4 and is starting War rooms about R1 well R1 is two months ago and the models that are coming out that are open source continue to March along quickly and so one of the things that is surpris surprising a little bit to me is that uh Zuck has invested so much in Ai and continues to say he's investing in AI he wants an AI engineer by the end of the year but he hasn't shipped lately and he's struggling to ship he's struggling to keep Pace with the other open source models and he's in danger of losing the open source ecosystem he wanted to build so we will see where that goes but that's definitely one to watch
