---
title: "AI News Today: Google AI coding, AI in US Nuclear Policy, OpenAI Agent Workflows  in Notion"
video_id: "ODCFocnG_dY"
youtube_url: "https://www.youtube.com/watch?v=ODCFocnG_dY"
substack_url: null
publish_date: "2024-10-30"
duration: "3:02"
view_count: 560



# AI-enriched metadata
content_type: "News Roundup"
primary_topic: "AI News"
difficulty: "Advanced"
audience:
  - "Engineers"
  - "Product Managers"
entities:
  companies:
    - "OpenAI"
    - "Google"
    - "Amazon"
    - "Notion"
    - "Box"
  people:
    []
  products:
    - "Make"
  models:
    []
concepts:
  []
summary:
  []
keywords:
  - "ai-agents"
  - "ai-news"
  - "ai-strategy"
  - "ai-tools"
  - "amazon"
  - "box"
  - "coding"
  - "frameworks"
  - "google"
  - "make"
  - "notion"
  - "openai"
  - "product-management"
  - "workflows"
---

# AI News Today: Google AI coding, AI in US Nuclear Policy, OpenAI Agent Workflows  in Notion

three quick pieces of AI news to get your day going number one Google shared at their earnings call yesterday that 25% of the code they are producing at Google is produced by large language models that doesn't mean that large language models are automatically deploying code Sundar clarified that he still has human engineers in the loop reviewing code it would probably be more accurate to see this more in line with what Amazon has done with uh leveraging their Q model to automate a bunch of the boring code production for lack of a better term uh that Amazon Engineers previously had to spend time on uh if you recall back in August Andy jasse had a lengthy post talking about how Amazon had saved something like 4,500 years of developer work by automating a lot of boring code with Q which is their in-house large language model so llms are being used for Enterprise code that's the takeaway number two this mostly flew under the radar but it's definitely worth paying attention to the general in charge of stratcom which is uh the United States government strategic command and control uh for nuclear weapons shared with Congress that he sees a role for artificial intelligence in increasing situational awareness in the nuclear command and control chain but not for decision-making for which I for one am grateful anything in that entire realm feels very newsworthy and I was a little bit surprised that this one snuck under the radar number three uh a new white paper is out from open AI talking about agentic workflows and how they're already being used at scale in this case open AI partnered with decagon which is a back office for customer success focused on AI native solutions they power uh companies like notion and they use multiple different large language models in a tool chain in an a gentic workflow which means that they have agents making decisions to send customer requests to different routes to go to different agents for other things Etc they did not describe the agentic workflow in detail probably because decagon doesn't want to reveal their secret sauce but they did share a couple of tidb bets they said they're using multiple models like 3.5 40 and 01 mini and that 3.5 in particular which you might think of as a weaker model is being used to reframe vague customer utterances or queries in a chat box window so that they are more strong and more specific and more useful for a large language model down the way in the workflow to parse and then make decisions about so basically 3.5 is being used to amplify a customer query so that other llms can take care of it I thought that was really interesting I'm going to link that white paper for you to look at and I'll link the other news stories too there you go we got news on Google News on nuclear command and control and news on how agentic workflows are already here cheers
