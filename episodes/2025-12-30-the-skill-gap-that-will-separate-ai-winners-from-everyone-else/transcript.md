---
title: "The Skill Gap That Will Separate AI Winners from Everyone Else"
video_id: "LwKnvqVdUgA"
youtube_url: "https://www.youtube.com/watch?v=LwKnvqVdUgA"
publish_date: "2025-12-30"
duration: "11:52"
duration_seconds: 712
view_count: 54758
author: "AI News & Strategy Daily | Nate B Jones"

yt_tags:
  - "AI agents"
  - "AI strategy"
  - "future of work"
  - "LLMs"
  - "personal AI assistant"
  - "Anthropic"
  - "ChatGPT"
  - "automation at work"
  - "agent memory"
  - "perpetual agents"
  - "model context protocol"
  - "executive assistant"
  - "task delegation"
  - "always on agents"
  - "AI agents 2026"
  - "AI strategy for executives"


# AI-enriched metadata
content_type: "Tutorial"
primary_topic: "AI Agents"
difficulty: "Intermediate"
audience:
  - "Engineers"
  - "Executives"
  - "Product Managers"
entities:
  companies:
    - "Anthropic"
    - "Slack"
    - "Cursor"
  people:
    []
  products:
    - "Claude"
    - "Claude Code"
    - "Cursor"
    - "Make"
    - "Model Context Protocol"
    - "Atlas"
  models:
    []
concepts:
  - "2025 was a year when agents got talked about a lot, got implemented by enterprises and other businesses"
summary:
  - "# The Skill Gap That Will Separate AI Winners from Everyone Else

I think we're all going to have personal chief of staff agents in 2026"
keywords:
  - "ai-agents"
  - "ai-strategy"
  - "ai-tools"
  - "anthropic"
  - "atlas"
  - "claude"
  - "claude-code"
  - "coding"
  - "cursor"
  - "frameworks"
  - "make"
  - "model-context-protocol"
  - "slack"
  - "tutorials"
---

# The Skill Gap That Will Separate AI Winners from Everyone Else

I think we're all going to have personal chief of staff agents in 2026. And I think that one of the reasons why that has not happened in 2025 is now solved. Fundamentally, 2025 was a year when agents got talked about a lot, got implemented by enterprises and other businesses. But we were not able to get to the point where agents were simple enough that it's trivial or easy for just about anyone to get an agent going any time. You can absolutely do it even as a non-technical person. I've written guides about it. I've talked about how to get Claude code to spin up agents. I've talked about how to get chat GPT to do agentic work for you. Talked about how to use codecs, but it's not as easy as it should be. And that's just an honest reality that we need to acknowledge. I think we're going to get there to where it's really, really easy to spin up agents for multiple reasons in 2026. Number one, we are going to have a massive hardware upgrade cycle. 2026 is when consumerfacing laptops are going to finally get GPU friendly chips so that we have the ability to run these agents effectively whether we're using the cloud or whether we're using a local device for our agents. Why does that matter if you're using the cloud? That's a great question. It turns out that chips still need to tokenize all of the data that you enter into an LLM right on the device itself. So if you're on your laptop and you're typing a question to chat GPT or on your phone and you're typing it out, it needs to tokenize that information and convert it into tokens that it can send to the AI in order to do anything else. We have not had a chip cycle that puts that front and foremost as the key thing that a computer needs to do. And so most of our hardware devices as consumers aren't ready for that yet. And so we're going to see a big upgrade cycle in 2026 that gets us to that point. So that's number one. I think that that's going to make it like we have a bigger envelope to work with from an AI perspective. Number two, agents are smarter and able to sa sustain attention for a longer period of time. Now that's a big deal because at the beginning of the year in 2025, we were lucky to get a few minutes of work out of our agent. Now we're getting to the point where we have multiple hours and we have model makers talking openly about this idea of longunning perpetual agents where essentially you can build scaffolding around the agent and just keep the agent running all the time where it just writes a particular task list. It goes out and it just executes against that task list one piece at a time. Maybe it spins up sub aents but the task list itself the task list the place it records its work. Maybe it's working memory if that's separate. any sub agents, those might be separate. Those all act together to keep the agent on the track and focused on the long-term goals. We have for the first time, in other words, in late 2025, the option to design a perpetually on AI agent. I think that's really critical because it helps us to resolve one of the key issues in the way of more widespread AI adoption, which is that the AI so far is super reactive and it just forgets stuff. Like we talk about agents as amnesiacs, right? Like it just it forgets. If you're going to interact with an AI agent, you want that problem solved as a consumer or frankly as an everyday professional. It's not acceptable to have an AI agent that just forgets. And I think that what we're getting to now is an understanding of the kinds of tricks that you need to do behind the curtain so that you have an agent that looks like it has memory to someone who is using it perpetually. So for example, if you want to tell the agent to get four things done today, the agent can literally go write those down and can execute on them in order and doesn't have to remember the four things you gave it because it has a notepad. That's a super simple example, but we we've come up with a dozen different tricks like that that allow us to start to define agentic systems at the enterprise level that have ongoing memory and the ability to execute over very long periods of time. This is one of the breakthroughs, this memory breakthrough, this ability to scaffold agents that run for a while. It's one of the things that stood in the way of having that dream of a personal assistant who is always on. I think at this point in late 2025, we finally can get to a point where that's true in early 2026. You, you know, you see what I mean? The key is understanding that the agent tasks that we give need to be achievable within the framework we're allocating. And so that's going to be one of the pieces that I think is a really big question mark for us. We may have agents that can run for a while. We may have chipsets that allow us to tokenize this information, but if we can't define work that our agents can do, then we're going to be in trouble. And that's another area where I think we've made a lot of progress in 2025. And we're at the point where we can start to do interesting work through the model context protocol layer through skills which are now getting widely adopted. Kudos to Anthropic for both. Uh we are now at a point where you can imagine an AI using your computer to do autonomous tasks and we have models for how that works. We have a concept of what the permissions layer would need to look like for that to be secure and we have an understanding of what it looks like for an agent to manipulate files on our behalf which is the heart of a lot of computer work. Meanwhile, we have an idea of what browser use looks like from Atlas and from Comet. And so these pieces are all starting to add up and come together. And it's sort of one of the things I look at is if you expect this breakthrough technology to occur, where do we see all of the different pieces lining up? And this is a case where I think a breakthrough in adoption is an always on mini me or always on chief of staff that you can just talk to. We have all those pieces lined up, people. We have the hardware cycle all set. We have the understanding of how to execute in a local environment and touch files all set. We have the idea of always on and memory management all set and figured out. But no one has put those pieces together into an intuitive interface that is missing. You need something like a right pane that is always on where you can talk to your mini me and say hey these are my priorities for the day. And then it should be able to spin up sub agents that you can keep an eye on that will go through and start to set things up and prepare. Maybe one is scheduling your calendar, one is working on your email, maybe another one is working hard on getting you briefed for an upcoming presentation, maybe another is doing some analysis for you. We will see that kind of world and it will require us to be that kind of organized because I got to be honest with you, I don't have a mini me like that yet. But I have to be that organized to get through my day. I have enough to do that I've had to develop these systems of organization and I would love to be able to get them into a space where a mini me could help me take them. I don't think that's true for everyone. I think you know in a lot of cases in in previous parts of my career I was also not that organized. This is a new phase for me. And if we're not that organized as humans, it's going to be hard for us to be effective as we work with our agents. And so where I'm going with this is I think the conditions are ripe for a breakthrough technology UX layer that basically says here's your personal agent. Your agent is always on. Your agent magically remembers what happened in the past. Talk to your agent about what you want to get done. The question then becomes, can you define useful work for your agent to do in a prioritized and efficient manner? And I think that is going to be a new skill for a lot of us. And I think that we are going to need to be really intentional about learning it because it's not automatic. Like when I go through and if I don't write out a to-do list and I'm not organized because I'm not perfect, right? I don't always do that. Then I'm flying by the seat of my pants all day long and I'm just making it up as I go and it's all up here. I'm not going to be an effective agent delegator in that situation. This is going to require us to be able to formulate effective intention. And so I think one of the things that we will need to see is something like a translation layer. Something that takes the ramblings, the thinkings, the intent, the late night shower thoughts, whatever it is, and puts those into a format that other agents can go and execute. Like I almost think what we need is two parts to this agent. There's the organized part of the agent that goes out and farms these tasks out to sub agents. And then there's going to be a translation layer over the top where you just need something that will take your random thinking and translate it into an efficient set of to-do lists with implied priority and give that to an agent that actually does it. And so the technical underpinnings that may be two or three agents in the background, but it's going to feel like one agent. It's going to feel like a mini me that sits there in the right pane and all I do is I just talk to it when I want stuff done and it formulates and adds that to the task in a way that's really visual and obvious and gives me updates on how my other tasks are doing. That may sound like it's science fiction today, but all of the pieces to make that true are already out there on the table. All you have to do to put together a business for that is to lay those pieces together. That's it. And then you have to put that in front of someone in such a way that they feel the tangible benefit because the other piece of this like people have tried this before and even if they got past the memory issue, the always on issue, the laptop and hardware issues, you still have to have work product that is good or else there's no point. And that's something that the LLMs themselves, the model makers themselves have made progress on. And so now we're at a point where making PowerPoints is becoming trivial, making spreadsheets is becoming trivial, making docs is becoming trivial. And so it's easier to imagine, hey, just get this done and the LLM capabilities themselves are coming to a point where they can just do that. The rule in product strategy with AI is always to build six or nine months ahead because the models will catch up. We are at the point where someone building six or nine months ahead can build this mini me and we're going to all be there and ready to grab it. I am really curious to see who that is. Is that going to be a model maker that wants to own that part of the layer? Is there going to be a Chad GPT always on mini me? Is there going to be an anthropic always on mini me? I'm sure they would like to grab our attention that way, but I don't think it has to be that. You could have a a cursor for personal agents or a cursor a cursor for executive assistants or whatever you want to call it that would essentially do this and enable you to grab this layer independent of a model maker and deliver value to the end customer. I think that would be a really interesting move because it would immediately change where you spend your time. One of the things that Stuart Butterfield talks about when he launched Slack in his famous memo, we don't sell saddles here back in 2014 is he said, "We are changing how people spend their time." And he called on his staff to be really intentional about that. This is the kind of launch that changes how people spend their time. And so if it works, it's going to be a profoundly disruptive and valuable business for somebody. But getting people into the habit, as Stuart notes, requires delivering that excellent work product in a very seamless way that they haven't had before. People aren't going to go through this process of chatting with an agent if they don't get extraordinary value. I think all the ingredients are in place to demonstrate that value and someone I suspect is going to put that together in 2026. Who do you think is going to be producing the mini me executive assistant agent for 2026?
