---
title: "NEW ChatGPT 5.2 Complete Breakdown: Tested on Excel, PowerPoint, Massive Data Sets, and More"
video_id: "821UqXHineU"
youtube_url: "https://www.youtube.com/watch?v=821UqXHineU"
publish_date: "2025-12-12"
duration: "14:37"
duration_seconds: 877
view_count: 33095
author: "AI News & Strategy Daily | Nate B Jones"

yt_tags:
  - "AI strategy"
  - "AI agents"
  - "large language models"
  - "automation at work"
  - "future of work"
  - "AI career advice"
  - "GPT-5.2"
  - "ChatGPT thinking mode"
  - "OpenAI models"
  - "Gemini 3 comparison"
  - "Claude Opus 4.5"
  - "agentic workflows"
  - "prompt engineering skills"
  - "delegation to AI"
  - "AI strategy for teams"


# AI-enriched metadata
content_type: "Tutorial"
primary_topic: "AI Tools"
difficulty: "Intermediate"
audience:
  - "Engineers"
  - "Executives"
  - "Product Managers"
entities:
  companies:
    - "Anthropic"
    - "Google"
    - "Stripe"
    - "Box"
    - "Twitter"
    - "YouTube"
  people:
    []
  products:
    - "ChatGPT"
    - "Claude"
    - "Gemini"
    - "Make"
    - "Opus"
    - "Artifacts"
  models:
    - "Claude Opus"
    - "Opus 4.5"
    - "Gemini"
    - "Gemini 3"
concepts:
  []
summary:
  - "2 Complete Breakdown: Tested on Excel, PowerPoint, Massive Data Sets, and More

Chad GPT 5"
keywords:
  - "ai-agents"
  - "ai-tools"
  - "anthropic"
  - "artifacts"
  - "box"
  - "career"
  - "chatgpt"
  - "claude"
  - "coding"
  - "deep-dives"
  - "frameworks"
  - "gemini"
  - "google"
  - "leadership"
  - "make"
  - "openai"
  - "opus"
  - "stripe"
  - "tutorials"
  - "twitter"
  - "youtube"
---

# NEW ChatGPT 5.2 Complete Breakdown: Tested on Excel, PowerPoint, Massive Data Sets, and More

Chad GPT 5.2 time traveled back to see us here. I am convinced that this is a model that shows us what the future is like for 2026. It's not an incremental upgrade, guys. I know it's positioned that way, but it's actually got some capabilities that I haven't seen in other models that I want to lay out here so that you understand what they are and you can figure out for yourself whether the model is right for you. First and foremost, this model is agentic by defaults. So if you think about models on a range of how long they can run and execute tasks, this is the first generally available model where it's very very easy to get it to do a tremendous amount of work on a huge bucket of inputs like a data set with thousands of rows. I tried it with a data set with 10,000 rows, right? It can do all of that, compute against it, develop insights, come back with a PowerPoint, come back with a doc, come back with an Excel spreadsheet, and it actually works. That means that it's accurate. It's coherent. It's cogent. It's thoughtful. It's able to craft an executive narrative. Guys, the PowerPoint is not nearly as gnarly as it was in 5.1 and 5.0. The PowerPoint artifacts actually work now. It's wonderful. But this creates a skill problem for us, doesn't it? Because what we have to do is we have to figure out how do we now define work that is ready to be delegated for that period of time. And that's a new skill for a lot of us. For many of us, we have been trying to figure out how to make these models help us do our work faster all year long. And that's been most of the conversation I've had with folks. Guess what? the models keep getting better and we have to keep scaling up. And in this situation, the skill that we need to learn whether we're technical or non-technical is how do we define a piece of work correctly so that we can assign it to a longunning agent. That is what feels like 2026 about chat GPT 5.2. That's what feels novel, new, and super interesting. And if you can't define that work, you are going to be behind people who can really define it well and come out with a fullyfledged analysis from a deep data set or a deep problem in the code or what have you and then get an answer that they can use and run with that would normally have taken them hours. Because when I take and I'm not kidding 20 minutes, 30 minutes, 40 minutes on a chat GPT 5.2 two task which I did today. It's it's really good and it's better than work that would have taken me four or five hours to do. And so it's not just about can it save me 20 minutes. It is understanding that the model can do in 20 minutes what would have taken someone six or eight hours to do and how do you understand that block of work and give it to the model. Now you might think if it can do six or eight hours of work can it just do my job? The answer is no. It needs clear scope. When I talk about the skill to delegate to the model, the first thing to do is to be able to define what output you want. A scoped output that matters. If you want a PowerPoint deck, it can do that. You have to define what you want there. If you want a word doc, it can do that. If you want an Excel, it can do that. Specify. Be clear about what you want. You also need to be really clear about what you need from the inputs. Especially if you're going to use that nice big context window and you're going to put a bunch of stuff in. Please explain to the model what is in the box and what you want the model to do with it. Because if you don't, the model's going to fill in its best guess and it's going to try and make it intelligible as best it can and you may or may not get what you want. And that has higher stakes now, doesn't it? One of the big things that shifted in the last 6 months is that we are no longer in a world where instant responses are the best a model can do. The best a model can do is often longer running. And so if you're in a world where the model can take a while to come back with a response, you better get it right. You'd better be correct in your problem framing. And that's not just an executive skill set anymore. That's an everybody's skill set. All of us need to learn more about framing problems and chunking problems into scopes of work that that can fit with a model that is truly agentic. And the reason I'm emphasizing that here is because Chad GPT 5.2 is so widely distributed. Everybody's going to get it because everybody has Chad GPT. So, we all need to learn this. Now, now you might be wondering, how does this compare to some of the other models out there? Well, I want to give you some very specific comparison notes that I've been seeing in early testing because I did a cross analysis where I gave the same assignment to different models to see what the quality would look like. I tested against Gemini 3. I tested against Claude Opus 4.5. I tested on Chat GPT 5.1 as well just to see what the sense of of of a difference is versus 5.2. I think that I'm getting a real clear sense of where these different models stack up. One of the things that is standing out to me is that the ergonomics of the model matter a lot. By ergonomics, I mean how do you have the full environment around the model feel comfortable like a good ergonomic chair so you can use it for useful work. That's not just comfort. That's actually value. Specifically, Gemini 3 has really poor user ergonomics right now. They have embedded Gemini 3 inside Google products and you can access Gemini 3 in the developer studio and you can access Gemini in the mobile app. But in none of those places is it easy to throw a bunch of data to throw a bunch of docs into the model and say please come out with a fully finished output. That is just not the product that Google has built. And so even if the brain power is there to do meaningful work against these artifacts and analyze it and come back with a fully featured output, you can't get to it. I could not upload a PowerPoint to Gemini 3. I could not upload a PowerPoint to or an Excel or a CSV. It's just not good, guys. you you you have to have the ability to put a lot of data in if you want to do complex work and it's a problem if you can't do that. And so I love Gemini 3. I did a great review on it. I still use it. I love their image generator. It's a smart model. I use it for thinking a fair bit. But the ergonomics are a and they really pop out when you compare it to Chat GPT 5.2 because Chad GPT 5.2 YouTube will take anything. Like you can throw anything in there. It will take it all and it will just chew on it. You can throw a screenshot and a CSV and a doc and a PowerPoint and it will just chew it all and process it and come out with something useful. And I think that's really really helpful. And I think that one of the things that really popped as a difference in my test between 5.2 is that the ability to intelligently coherently with less hallucinations process this data is way up. And that showed up in their benchmarks. They saw like 38% less hallucinations or something like that. And and it just it pops like you can see it. You can you can see the coherence. Now comparing it to Opus 4.5 is interesting because the ergonomics in Opus 4.5 are also quite solid. You can throw in a wide variety of input documents. I like the way Opus 4.5 is able to craft effective output artifacts just like Chad GPT 5.2. And so if I were to look for a difference between the two, I think the thing that I want to call out is first the way the models are architected is very very different. Chad GPT 5.2 especially in thinking mode which is a very different mode. If you're using instant mode, it's not the same thing. Chad GPT 5.2 thinking mode is a longunning thoughtful intentional model. It takes a while to respond. It does very thorough work and these days it now does artifacts well too. It really does. there's not really that gap on PowerPoint functionally speaking. Opus uses tools instead of reasoning. And so Opus will work for a while, but it's using tools as a non-reasoning model to get that work done. So it's a very different approach. I like the aesthetics of the PowerPoint that Opus 4.5 produces slightly better. The functionality is about the same. Like from a functional PowerPoint narrative perspective, it's about the same. And critically, the thing that gives Chat GPT 5.2 to an edge is that it can take so much data to solve your problems. And that's why I started this conversation saying pay attention to how long these agents can work. Because if you were going to give an agent a meaningful task, that only really works if you trust it with a ton of data. If you give it a lot of data to work with and ask it to handle a complex task. Otherwise, even in thinking mode, it won't take that long. and you won't have solved that meaningful a problem. And so I think the thing that we need to shift toward is a world where we recognize that increasingly the models have a better understanding across larger swaths of data than we do. So maybe it's a a customer service set of tickets that we need to analyze. Maybe it's hundreds of Twitter responses from a question that we had. Maybe it's uh a bunch of Stripe transaction data. Maybe it's a big Excel spreadsheet of customer issues. You get the idea, right? It's anything that has that sort of very large variagated data types all in one big place, right? Because you could have like customer tickets in one hand, you could have transcripts and recording in another. The data can be quite variegated. It's a big enough context window you can throw it all in there and you can ask it to make sense of it. And it does. and it's able to translate it into something useful. I think this is a little bit of an intangible, but one of the things that comes out when you have a model that is strong at coherence that reduces on hallucinations that has the tools to build something like a PowerPoint well is the ability to build narrative comes as an emergent property. And so what I noticed is it's able to take data that I don't necessarily have a clear story for and it's able to pull it in and say there's a story here. here's the overall story and here's why I know that and you can check it and prove it because of course you do. You have to go in and check and and see that it actually works. And so if you're looking at 2026 and you're asking yourself, what are the skills I need to thrive? How do I build this into my teams? I would say the number one skill that you're going to need in chat GPT 5.2 too and in the other models that follow not just from Chad Chad GBT but from Gemini from XAI from Anthropic you're going to see more agentic models and your number one skill needs to be grow my ability to delegate we are moving from a world where execution with models was the story for 2025 delegation to models is going to be the story of 2026 we're not ready we're not ready. We're not ready with the data side. We're not ready with the skill side. We don't know how to frame problems. Look, I the first thing I did when I started getting into 5.2 and seeing what it could do is I went over to 5.2 and I asked it to start to help me think through prompting this model differently because we have to think about prompting not as give me a response now, but as let me give you a lot of stuff and then go away and think about it. Now, eventually we're going to get to a world where I think we have more interaction patterns with running agents and you can interrupt the agent. We're starting to see hints of that. We'll see more of that in 2026. But the skill for now is really intentionally aim the model in the direction you want it to go and then focus and make sure you have the right stuff and then give it give it time to work. Let it work for a while. It is not unusual to see a model like 5.2 two work for 20, 30, 40 minutes and it's not like deep research because deep research comes back and it just gives you a web report and it's very well written. It can be 50 pages. 5.2 thinking will come back in a similar amount of time but it will give you much more control over what you get. You can define the output type that you want. You can define the kind of analysis you want. It's like a much broader Swiss Army knife versus the scalpel that is deep research. So if you're wondering where to put this into your workflow, I would say 5.2 to thinking is a agentic workflow executor that is almost more powerful than we're ready for. It is something that if you know how to delegate well, it is going to eat work for you. You want to analyze a P&L, let it let it analyze the P&L for you. Let it take the first pass. You want to analyze an acquisition, let it do that. You want to analyze your investments or your personal savings and budget, let it do that. This thing loves to solve problems. And so really the rate limiter for us, the question for us is do we have the taste to find the right problems to solve? Do can we can we locate the data for it? Can we throw the data in and then can we give it clear enough directions about the output and the kind of analysis it needs to run in order to get successful outcomes because the stakes are higher. Now if you're running Chad GBT 5.2 too for 20, 30, 40 minutes and you didn't give it the right directions. Your feedback loop is slow. You're going to be like, "Oh no, now I have to redo it. It's going to be like another hour out of my day to get this done." So, our prompting skills are now higher leverage because it's so important. And so, I put together some prompts to make sure that we have a good sense of what this looks like. But beyond prompting, the key thing that I want to call out is we need the soft skills to delegate better, to understand those problem frames. And that's what I want to leave you with because I believe that that is the key skill for 2026. And I think that is what 5.2 shows us in a way that no other model does. It will eat entire workflows because it is so good at correct coherent longunning agentic execution. I think they kind of undersold it as a 0.1 upgrade. I think it's bigger than that. But you tell me. You test it out. You tell me what you think. I'm really curious. I love the model. It's going to be a lot of fun to use.
