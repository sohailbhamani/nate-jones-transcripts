---
title: "$1,000 a Day in AI Costs. Three Engineers. No Writing Code. No Code Review. But More Output."
video_id: "-bQcWs1Z9a0"
youtube_url: "https://www.youtube.com/watch?v=-bQcWs1Z9a0"
publish_date: "2026-02-20"
duration: "30:13"
duration_seconds: 1813
view_count: 75482
author: "AI News & Strategy Daily | Nate B Jones"

yt_tags:
  - "AI strategy"
  - "token economics"
  - "AI agents"
  - "software development"
  - "AI career advice"
  - "future of work"
  - "OpenAI"
  - "Anthropic"
  - "Cursor"
  - "enterprise AI"
  - "AI productivity"
  - "AI costs"
  - "developer careers"
  - "AI infrastructure"
  - "solopreneur"
  - "AI strategy for teams"


# AI-enriched metadata
content_type: "Deep Dive"
primary_topic: "AI Strategy"
difficulty: "Intermediate"
audience:
  - "Engineers"
  - "Executives"
  - "Product Managers"
  - "Founders"
entities:
  companies:
    - "OpenAI"
    - "Anthropic"
    - "Google"
    - "Meta"
    - "Microsoft"
    - "Amazon"
    - "Perplexity"
    - "Cursor"
    - "AWS"
  people:
    []
  products:
    - "Claude"
    - "Cursor"
    - "Perplexity"
    - "Make"
    - "Opus"
    - "Sonnet"
    - "Haiku"
    - "Projects"
  models:
    - "Claude 4"
    - "DeepSeek"
concepts:
  - "In a way we haven't seen in 50 years or 60"
summary:
  - "OpenAI is rumored to be working on a new 20,000 a month AI employee"
keywords:
  - "ai-news"
  - "ai-tools"
  - "amazon"
  - "anthropic"
  - "aws"
  - "career"
  - "claude"
  - "coding"
  - "cursor"
  - "google"
  - "haiku"
  - "leadership"
  - "make"
  - "meta"
  - "microsoft"
  - "openai"
  - "opus"
  - "perplexity"
  - "projects"
  - "sonnet"
  - "workflows"
---

# $1,000 a Day in AI Costs. Three Engineers. No Writing Code. No Code Review. But More Output.

OpenAI is rumored to be working on a new 20,000 a month AI employee. And you know what? That's not even the most interesting part of the story. The real story here is that across Anthropic, across OpenAI, across other AI native organizations, the new unit of work is turning into the token. And that is changing the job of engineering so fast, it's making current engineering work almost unrecognizable. There are now three kinds of developers in 2026. And I'll go through all three. One of these kinds is about to get very, very rich. One of them is about to become obsolete. And the third kind of developer doesn't even know they're a developer yet. And this all sounds like clickbait, right? I get very hypy. It's not. It's what happens when computing is changing form. Not incrementally, but categorically, fundamentally, in a way we haven't seen in 50 years or 60. For 60 years, the unit of work in software was the instruction. It was deterministic. A human writes code. A machine executes code. And the value was denominated. And how cleverly the human could sequence those instructions. The developer's entire job was just translation. Please turn this business logic into machine logic. One function at a time, one Jira ticket at a time. That era is done. The unit of work is now the token. A token is not an instruction. It's a unit of purchased intelligence. You don't tell the machine what to do step by step anymore. You describe what you want. You feed it context and you buy enough intelligence to get a result. We call it inference. The machine figures out all the workflow steps on its own. The human's job is abstracting, right? It's shifting up from writing the logic to specifying the outcome and managing the intelligence budget. The human's job is shifting up. It's abstracting from writing the logic to specifying the outcome and managing the intelligence budget that produces that outcome. That is not a tools upgrade. That is not a software upgrade. It is a change in what computing is. And once you see it that way, you can't unsee it. Once you follow the second order effects on careers, on companies, on entire markets, the three kinds of developers I talked about, that stops sounding like clickbait. That just sounds like a map to where we're going. I am not just talking about OpenAI. I know I open by saying they're working on a $20,000 a month employee. If that was the whole story, it wouldn't be a story. The numbers are arriving from all over the computing map. In early February of 2026, Strong DM CTO Justin McCarthy disclosed that his threeperson team targets a thousand bucks a day in token spent. No handwritten code. You get a similar story in October 2025 when journalist Ed Zitron reported that Curser, Anthropic's single largest customer, saw its AWS cost spike from 6 million bucks to over 12 between May and June of 2025. a spike that coincided with Anthropic's launch of priority service tiers, which is a new pricing regime. In the same reporting, Zitran disclosed that Anthropic itself had spent 2.66 billion on AWS through September 2025 against an estimated 2.5 smaller number billion in cumulative revenue over the same period. In that same reporting, Zitron disclosed that Anthropic itself had spent 2.66 66 billion on Amazon Web Services through September 2025 against an estimated 2.55 billion in cumulative revenue over that same period in the fall of 2025. In other words, more than 100% of the topline revenue for Anthropic went straight to AWS alone before even accounting for Anthropic's Google Cloud spent. Zitron was a busy guy because he separately reported that Perplexity spent well over 100% 164% of its entire 2024 revenue across AWS, Anthropic, and OpenAI combined. Are you getting the idea? These numbers are anchoring us in a new way of computing. These companies are not setting out to aggressively find a more expensive way to do things. They're operating a fundamentally different paradigm. Intelligence is now a purchasable input, a commodity. It has a price curve. It has a consumption curve. And there are a set of second order effects that reshape how organizations operate when software is a function of intelligence. And the reason this is worth it is because the companies I am talking about OpenAI, Anthropic, Cursor are among the fastest growing companies in the world today. These companies may be spending more than their top line right now, but they are betting that they can grow their top line so quickly that they're going to get back into positive unit economic territory over time. But let's start with how these companies are making that bet. We'll look at the price curve first. Per token inference costs have been falling at rates that make Moore's law look gentle. Somewhere between 10x and 200x a year, depending on the benchmark and how you measure it. So for example, GPT4 equivalent performance cost $20 per million tokens in late 2022. It costs about 40 today. Claude 4.5 sonnet runs at $3 per million input tokens and the raw commodity there is deflating faster than any computing resource in history. You fast forward a year or two, 4.5 sonnet is going to be down into the cents again. Now look at the consumption curve on the other side. When a resource gets cheaper, you don't use less of it. you use an enormous amount more. This is called Jieven's paradox. It's a well-known observation that efficiency gains in resource use lead to increased total consumption. You don't decrease the usage when it gets cheaper. So, steam engines got more efficient, coal consumption exploded, cloud computing got cheaper, and AWS bills ironically went up. Sachi Nandela invoked that paradox by name earlier in 2025 after the deepseek moment when he said as AI gets more efficient and accessible we will see its use skyrocket. He was 100% correct and we have lived to see that come true as we have seen all of the AI topline revenue numbers explode over the last year. Now in this case Sasha was defending Microsoft's infrastructure spending but he could have been speaking for Google. He could have been speaking for Meta. He could have been speaking for any other hyperscaler investing so much in hyperscaling AI right now. There is a new physics of compute that is being built on top of all of their infrastructure and it reshapes how organizations allocate resources. The average organization now spends $85,000 a month on AI, up 36% year-over-year. And the share planning to spend more than that. Over $100,000 monthly has doubled from 20 to 45%, which is a fancy way of saying $85,000 ain't enough and people are going to spend more into six figures on average. Now, those averages are obviously skewed. There's going to be some companies that are spending millions and planning to spend 10 millions, but the trend line is clear. Open AAI is seeing that trend line and that is where that $20,000 a month AI employee is coming in. They are reportedly actually planning multiple agent pricing tiers from $2,000 a month for knowledge worker agents perhaps up to $10,000 a month for specialized agents maybe in coding or software and up to $20,000 for AI research. Or so the rumor goes. Look, the point is not will they launch at exactly that price point next month. The point is that that is a conceivable price point for AI intelligence when organizations are reframing their entire budget around compute that is measured in tokens. Intelligence is now purchasable. And it turns out we have a huge appetite to buy it because enterprise buyers are doing the math and concluding that even at $20,000 a month, the price is cheap relative to the cost of the human professionals they'd otherwise employ. The price per unit of intelligence is collapsing. And it's not as simple as saying, "Okay, they're going to buy the $20,000 a month employee and they and they will fire the PhD researcher." At many companies, it looks like we're going to keep our PhD researchers. We're not going to hire more, but we're going to give each of these researchers a mini me, and they're going to expand their footprint by two or 3x. The number of intelligence units, the number of tokens consumed per engineer, per company, per industry is exploding. There's no other word for it. And the gap between what different levels of consumption can produce is widening every week. But we're not talking about that part. And this is where the interesting effects start to happen. It's not in the price tag. It's in what happens to an entire economy when intelligence becomes a variable cost that you can dial up or down. We've never had this before and it's going to affect all of our lives. So the first thing to recognize as you start to move into a token economy is that in the old paradigm, the scarce resource was time, specifically often developer time. You hired engineers, you gave them tools, and the constraint on output was how many hours of skilled labor you could deploy. The management challenge was therefore headcount planning, recruiting, retention, all the machinery that goes with human capital management. In the new paradigm, the scarce resource has changed. The bottleneck has moved. It is now the ability to convert tokens into usable economic value. So the raw intelligence that's coming in is abundant and it's getting as I described like massively cheaper quickly. What's scarce right now is knowing how to aim all of those tokens, how to structure context, how to route tasks to the right model at the right cost, how to build agent loops that sustain quality over a long period of time, and then to measure whether the intelligence you're purchasing is actually producing the outcomes that you need. This creates an entirely new organizational capability. You can call it token management. You can call it intelligence operations. You can call it context engineering. The name is not so important right now. What matters is that it's a real skill. It's measurable. And the organizations that build it are starting to pull away from everybody else. The enterprises that have figured this out are actively and aggressively building internal platforms that route work to the right model at the right price point. Haiku for the cheap stuff, Opus for the hard stuff, Sonnet for the metal, or you're on a Google platform and you're doing that with Google models or OpenAI models. The point is they're treating token spend not as a cost to minimize, but as a lever to maximize ROI and value. And so they'll negotiate custom API agreements with the big hyperscalers. They will commit to consumption floors in exchange for dedicated capacity and volume pricing. A16Z's Enterprise AI survey found that average enterprise LLM spend hit $7 million in 2025. By the way, that is a different number than what I shared earlier because we're talking about the enterprise scale here. These are big company scales into seven figures and that's up from 4.5 million just two years prior and projections are it's going to get into eight figures and 11 million plus in 2026. And that spending has shifted really fast. It's shifted from what was I guess an innovation budget previously into a centralized IT and business unit budget. In other words, the language has moved from let's explore to this is critical for our business. Let's build the infrastructure. The flip side of all of this change is that token management can still go catastrophically wrong and it matters more when you're spending more on it. Cursor, which became a billion-dollar revenue AI coding editor really, really fast, found itself in a structural trap with token economics. It sends essentially all of its revenue to Anthropic in API costs. When Anthropic introduced priorities and raised cashing prices, as I was sharing, Cursor's costs were uncontrollable. They exploded overnight, forcing it to gut out its unlimited 20 buck a month plan and introduce a 200 buck a month tier. users revolted. The subreddit turned into a complaint forum. We've seen this story before. When you have a downstream provider of intelligence, they don't have control over the intelligence costs they're paying for and they have to pass those costs on. The lesson here is not that tokens are expensive or the hyperscalers are going to play games of gotcha. The lesson lesson is that token economics is now a core business competency and companies that don't figure out how to master it are just one supplier pricing change away from being in a crisis. There is a reason that part of cursor's response was to build their own model. They needed to get out of that situation and they have introduced their own model since. This is where the conversation gets personal for anyone who writes software for a living and it's where most of the current discourse is missing it or getting it wrong. Remember when I started this video by talking about the fact that there are three developer career paths opening up? This is where we're going to talk about that. The standard narrative has been really binary. Either AI replaces the developer or it doesn't. That framing is not super helpful. What's actually happening is that the role of the developer is starting to differentiate really rapidly into at least three distinct tracks. each of them having different skill requirements, different compensation dynamics, and very different career trajectories. We'll call track one the orchestrator. This is sort of like the strong DM model where the developer does not write code, but specifies outcomes and manages the intelligence that produces those outcomes. The core skills are system design, specification writing, quality evaluation, and token economics. These developers think in terms of agent architectures, context windows, eval frameworks, cost per outcome. They're effectively factory managers with intelligence. Their value scales with the volume of intelligence that they can direct, which means their compensation is probably going to correlate with token budgets long term rather than lines of code. This track tends to favor people who are very very good at decomposing problems, who can write precise specs and who can evaluate output quality really carefully and those are skills that overlap with but are not identical to traditional software engineering. Track 2 is more like the systems builder. This is someone who has to build the infrastructure that the orchestrators use, the agent frameworks, the evaluation pipelines, the context management systems, the routing layers that send the right task to the right model at the right cost. This is very deep technical work. It's closer to traditional systems engineering than to application development. But with an entirely new stack. So these developers need to understand model behavior at really a mechanical level. How context windows affect output quality, how different architectures handle different task types, how to build reliable systems on top of probabilistic components. This track is much smaller in volume and much more specialized, but the compensation ceiling is super high because the leverage they wield is companywide. It's enormous. And track three is the domain translator. This is the track that almost nobody is talking about and it may be the largest of the three. These are the developers or increasingly the non-developers who combine enough technical fluency to work with the AI systems and enough deep domain expertise to know which problems are worth solving in a specific market. The dental practice management specialist is now a developer. The construction scheduling expert is now a developer, although he may not know it yet. The insurance compliance analyst can now build tools instead of just using them. These are real stories, by the way. Their value isn't in their ability to manage tokens or build infrastructure. It's in their ability to point intelligence at the right problem in the right market with the right context. And that value is going up as intelligence gets cheaper because cheaper intelligence makes more niche problems economically viable to solve. The career implication here is stark. The middle of the old software engineering distribution is most exposed. Think of the developer who writes competent application code, but he or she struggles with deep systems expertise or with deep domain expertise. They're the ones that are most exposed. Not because AI is by definition going to immediately replace them tomorrow, but because the value of generic code production is going to zero at the same rate as the cost of tokens. The developers who thrive are going to be the ones who move decisively toward one of these longer term tracks. ideally the one that best matches existing strengths and interests. But regardless, you're going to have to pick one because the only clear track that doesn't work is that content because the only clear track that doesn't work is doing what you're already doing and just being AI assisted with competent application code. That is no longer going to be enough. And yes, people tell me all the time, I'm using AI to code. Is it enough? And I'm going to say, no, it's not enough. You're going to have to think more deeply about how you can either manage agents doing production code, build systems that enable that to happen, or get in there with a customer and deep domain expertise and solve problems. Those are the three ways to get leverage right now. Those are the ways that you can deliver extraordinary value. Remember at the top when I said there's going to be rich developers, there's going to be developers that are out of luck, and there's developers that don't even know they're developers. The construction specialist doesn't know he or she's a developer yet. The ones that are getting rich are the ones that are figuring out how to leverage their skills to put this new token intelligence into place at scale in enterprise systems. And the ones who are out of luck, those are the ones who are writing competent application code. That's just the way it's going to be. And when the unit of work changes, when we move to a world with tokens, our organizational structures are going to be rebuilt around tokens. Right now, most engineering orgs are structured around headcount, which has been our bottleneck for 60 years. They're structured around full-time equivalent resources. Productivity is measured very badly in output per engineer. That's a whole debate we can get into another day. Hiring plans are built around projected workload. In a token-based paradigm, you can turn that whole world upside down. Output ends up being limited not by headcount, but by the ability to convert intelligent spend into business value, which is harder. It's complex. We're having to invent it. But that's the reality. So an organization that employs 500 engineers to write code by hand may indeed produce less than an organization that employs 50 engineers managing agents. If the 50 person or has better specs, better evaluation frameworks, better context engineering, and of course a higher token budget per engineer. That is not an exaggeration. I see smaller orgs running circles around bigger orgs all the time. That doesn't mean that enterprises who fire 90% of their engineers next quarter are going to immediately be productive. And some of them are making that mistake. Organizational change is slow. It's human. It's often political. It's very path dependent. But even with all of those caveats, enterprises that are able to walk that path and figure out the new token first model are going to start to develop a compounding advantage in productivity because they're essentially internalizing a new paradigm for compute. CLA has been a really interesting example of this. They had a completely disastrous initial AI rollout. They had to rehire a bunch of their customer service folks. But because they built AI tooling along that journey, even though it was badly rolled out, even though they made firings they shouldn't have made and had to rehire people, they still are seeing revenue starting to scale per employee into seven figures, which is way higher than the average SAS revenue per employee. And so CEO Sebastian and so when the CEO of CLA goes on TV and says, you know, the world isn't ready for the impact AI will have on knowledge work, which is something he did say, he's not describing a theoretical. He's describing some of the journey his company has been on, however rocky it's been. And data from A16Z shows that this pattern is spreading. AI native companies keep running at 3 to 5x or even more revenue per employee versus traditional SAS companies. A $10 million ARR AI startup might operate with only 15 people whereas a traditional SAS company that number would be like 55 60 maybe even 70 people. That ratio is going to get wider as the tooling keeps mature and it will eventually force larger organizations to restructure or else accept a permanent productivity disadvantage. The second order enterprise effect here is more subtle and more important. What gets built is going to change when the cost of building falls. Every enterprise tends to have a backlog of projects that were never ever economically viable. Maybe interesting for customers, but we didn't make time for it. The internal tool that would save 200 hours a year but cost 2,000 hours to build, we were never going to build that. The integration that would unlock a new revenue stream but require a team of four for 6 months, that wasn't worth building. You get the idea. The enterprises that recognize that their backlogs are now frankly a gold mine are going to dramatically expand the scope of what they build and not just the speed at which they build it. In other words, if you're just optimizing for headcount, you're missing the point. Your competitors that optimize for output and software quality are going to beat you. But the second order effects of moving to token economics and per token pricing and thinking as a fundamental unit of compute to moving to a new paradigm for compute. They go beyond thinking in terms of headcount or even thinking in terms of developer career stories. The stratification of the software world is being played out in terms of token volume. Goldman Socks is going to spend more on inference than you or me or any small startup. JP Morgan is going to commit to larger consumption contracts than most small businesses ever could possibly hope to afford. If the competitive axis ends up just being who can buy the most intelligence, the incumbents, the big companies are just going to win by definition. They have the revenue base to fund that flywheel and that transition to a new paradigm of compute. But intelligence is a commodity and when the core input gets commoditized the competitive advantage is going to migrate to somewhere else to everything around that commodity to distribution to domain expertise to customer relationships to proprietary data to workflow integrations to brand to trust sure Goldman can run more inference than a small AI powered startup that aims to be a fintech operating in the restaurant space but Goldman can't sell AI powered inventory management to a 50 location restaurant chain because that intelligence is purchasable. But Goldman never set up a channel to sell it and probably won't. And frankly, it's not just Goldman in that boat. Any big company that isn't focused on a particular distribution niche is going to not be well positioned to compete for that space. And because the cost of building is falling so dramatically, there are niches opening up that were never viable before. The addressable market for software is expanding explosively. This is Jieven's paradox applied to the total addressable market of software. And so most people are missing that vertical AI companies have new opportunities in the niches that weren't possible even six months ago and that big companies are not going to spend dollars on to compete in. So the startup playbook in this paradigm isn't really raise more money, buy more tokens. Is know a market so well. It is know a market so well that a $200 a month claude max subscription aimed really well creates more downstream value than a fancy enterprise $20,000 a month agent budget pointed at a different problem entirely. Distribution and knowing your local market is going to beat the compute advantage that an enterprise has. Knowing your customer is going to beat everything else. And that is true regardless, right? Enterprises need to know the larger companies they serve just as small startups need to learn where they can compete in those niches. What about solopreneurs? There's been so much discussion around billion-dollar companies founded by one person. There's a bet apparently going around in Silicon Valley around when the first oneperson billion dollar company is going to exist with some people thinking it's happening this year. I think that we're missing the real implications of the story because we're looking for the headlines and the person who's going to be on the cover of the newspaper. The point is not the individual who founds the company. The point is that when intelligence is purchasable by the token and the cost of building software is continuing to fall because those tokens get cheaper, then the minimum viable team for software is inevitably approaching one. That is a much more interesting insight than trying to bet on when the first solo founder is going to hit a billion dollars because the larger implication is that going independent is less and less of a lifestyle trade-off and is increasingly a very rational economic choice for anybody with deep domain knowledge and sufficient AI fluency. This also is a dynamic that affects the size of software teams in large businesses because a soloreneur is effectively a team of one. If token costs are falling and intelligence is rising and you are getting a convergence toward a team of one, it implies that there is a huge downward pressure on team size at big software companies. We talked about two pizza teams a lot at Amazon. We are headed toward a world with one pizza or half a pizza teams at this point. I don't know about you, but sometimes I can eat a half a pizza. So, I think the market is splitting. That much is really clear. But because of the way the token compute paradigm is hitting big companies and little companies differently, I don't think it's splitting into as simple a world as the big companies are the halves and the little companies are the have nots just based on token budget just because the big companies can afford the $20,000 a month OpenAI PhD researcher if and when they launch it. It's splitting instead along a more interesting axis. Generalized scale versus specialized precision. At the top are enterprises and really well-funded AI native companies that are competing on token volume, building horizontal platforms, running agents around the clock on very broad workflows that every large organization shares. Their advantage compounds with every model upgrade and their moat is frankly capital and infrastructure. But that's not the whole world. across the enormous surface area of the rest of the market, which is expanding rapidly. Builders can win if they're small, if they're startups, maybe a few people on the team. They win on specificity, the sharp angle, the niche market, the customer relationship that no amount of token spend can replicate. Their advantage compounds with domain knowledge. Their moat is distribution and trust. Both sides benefit from the same underlying trend. Intelligence is getting cheaper. Cheaper intelligence makes more things possible. We're moving to a tokenized compute framework. The enterprises are using this new token paradigm to scale horizontally in ways they never could. Specialists that are smart are going to use the same capability, the same token paradigm to go deeper vertically. The paradigm shift doesn't necessarily pick a winner or force a winner between these two. It makes both strategies more leveraged, more powerful, and it widens the gap between either strategy and the old model where it was denominated in time and you were writing code by hand. The developer career can be operative across either one of these. You can be a developer that is an orchestrator or a system builder as I described in a big enterprise and you can increasingly do one or both of those jobs at the same time in a small startup. Enterprise org charts are going to reorganize. They're going to reorganize around intelligence throughput instead of headcount. Startups are going to start aggressively competing to get the best people who can build that intelligence throughput and focus it on specific angles where enterprises just aren't going to get in and compete because they're forced to build larger solutions that justify their token economics. And so when you step back and you see the headlines that say, you know, $20,000 a month AI employee or a,000 bucks a day in tokens, the question you should ask yourself isn't whether you can afford that amount of money or maybe you can't compete. I don't think that's the right question. I think the question is whether you understand that computing as a paradigm is changing. And then you think about where you're positioning yourself, right? Are you positioning your career, your company, your product for a world that understands that tokens are the fundamental material of computing today? Intelligence is becoming a commodity. And I've taken this video to sketch out some of the second order effects of what that looks like. What you do in this world, how you navigate a tokenized world, that's up to you. And I've sketched out a few career paths, but there are going to be thousands of permutations of those journeys. And you are going to have to frankly use inference, use machine intelligence to start to figure out what is the most effective journey for you. Maybe that looks like being a soloreneur. Maybe that's an orchestrator. Maybe if you're a business owner, you're thinking about the niche that you could play in. Whatever it is, remember changing the fundamental unit of computing is going to change everything for all of us. Best of luck in the new
