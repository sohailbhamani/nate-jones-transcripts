---
title: "Catch Up Before ChatGPT-5: Your Complete AI Guide—Timeline, AI Basics, Resources, and Who To Follow"
video_id: "HfvO5Hcdyt4"
youtube_url: "https://www.youtube.com/watch?v=HfvO5Hcdyt4"
substack_url: "https://natesnewsletter.substack.com/p/the-complete-ai-learning-roadmap"
publish_date: "2025-06-30"
duration: "22:11"
duration_seconds: 1331
view_count: 41516
author: "AI News & Strategy Daily | Nate B Jones"

yt_tags:
  []



# AI-enriched metadata
content_type: "Tutorial"
primary_topic: "AI Tools"
difficulty: "Beginner"
audience:
  - "Engineers"
  - "Executives"
  - "Product Managers"
  - "Founders"
entities:
  companies:
    - "OpenAI"
    - "Anthropic"
    - "Google"
    - "Meta"
    - "Tesla"
    - "Box"
    - "Twitter"
    - "YouTube"
  people:
    []
  products:
    - "ChatGPT"
    - "Claude"
    - "Make"
    - "Opus"
    - "Sonnet"
  models:
    - "Sonnet 4"
    - "Llama"
    - "DeepSeek"
    - "SAM"
concepts:
  - "What is going to happen from here until october, november, december of 2025 is going to make 2023 and 2024 models look completely outdated"
  - "Telling an algorithm what details matter"
summary:
  - "# Catch Up Before ChatGPT-5: Your Complete AI Guide—Timeline, AI Basics, Resources, and Who To Follow

This video does one thing"
keywords:
  - "ai-news"
  - "ai-strategy"
  - "ai-tools"
  - "anthropic"
  - "box"
  - "chatgpt"
  - "claude"
  - "coding"
  - "frameworks"
  - "google"
  - "leadership"
  - "make"
  - "meta"
  - "openai"
  - "opus"
  - "prompting"
  - "sonnet"
  - "tesla"
  - "tutorials"
  - "twitter"
  - "youtube"
---

# Catch Up Before ChatGPT-5: Your Complete AI Guide—Timeline, AI Basics, Resources, and Who To Follow

This video does one thing. It helps you understand AI before chat GPT5 comes along and changes everything all over again. I get so many DMs that say, "Nate, how do I actually understand AI before it's too late? Nate, I am late on AI. Nate, I don't know how to catch up." This video is for you. It's for anyone who has that feeling. It's also for you if you want to know what's in the box on Chad GPT5 and what we know so far. Let's start with this moment we're in today. This is the summer of consolidation. I'm comparing it to the 2007 iPhone release. Fundamentally, what is going to happen from here until October, November, December of 2025 is going to make 2023 and 2024 models look completely outdated. AI itself is going through a platform shift right now. And chat GPT5 is one of the big releases that we are looking forward to this year that is going to underscore that fundamental shift toward a more unified professional enterprise experience. And if you want to take advantage of that, if you want to be ready for that, it makes sense to get ready now. It makes sense to catch up now so you don't feel farther behind. So what we're going to cover is everything we know about Chad GPT5. We're going to talk about the story of AI very briefly in plain English. You don't have to have a maths degree. We're going to talk about some resources you can use to dig into. Yes, they are on YouTube. And we're going to talk about people to follow to keep up with the signal over all the noise that's going to happen this summer because there's a lot of noise. That's a ton to cover, but we're going to do it fast. First release timeline. We think July, early Q3 could be any time. We do know that the Open AI team is off this coming week through about July 4th. They've been working very hard. it would make sense to give them a break before the pressure of the roll out. Part of the pressure has to do with bringing the model into a single truly unified brain quote unquote. So bringing the Oer reasoning model, the general knowledge of GPT4 voice capabilities and deep searching tools all into one place. As Sam has said, we hate the model picker as much as you do. Getting that right is really hard. We will see if he gets it right, but that's certainly what they're going for with Jet GPT5. As far as capabilities, look for four areas of improvement. We don't know the exact specs, but I kind of don't care about the exact specs because typically you have to actually use the models to see if they're any good. Improvement area number one, multimodality, seamless speech in and out, images, maybe video with this release. Reasoning depth to go seamlessly from limited chain of thought to really reliable in-depth problem solving reliability. surfacing that one good answer in 10,000 consistently. And that, by the way, takes a lot of inference under the surface to pick the right answer. And then fourth, personalization, memory, access to email, calendar, enterprise knowledge, etc. This will take adaptive computing, so heavy GPU use only when needed. And I think it's going to lean pretty heavily into voice because that would align nicely with the very rumored Johnny Ive device. So, we will see. However, even if it's adaptive compute, it's still going to take a lot of compute cores. It's going to take perhaps tens of thousands of GPUs to properly serve this model. It has to be scaled out. And that is not something that they are going to do without being sure they got it right. Because if you recall, every time we've had an OpenAI at launch in the past year or so, we've had a brown out beforehand. We've often had scaling issues during the launch. This is their premier launch for the year 2025. They do not want to mess it up. So, they're going to take their time and make sure they get the engineering right. And that's part of why we don't have a date and they haven't announced a date. Okay. So, the takeaways for builders now based on what we know. Expect smoother user experience, not just bigger brains. Expect a gradual roll out because again, they're going to be monitoring those GPUs. So, I would expect it's going to follow their usual pattern and go from pro to plus to free, but they're going to try and accelerate it as fast as they can. I would bet because they really want this to be a flagship roll out for everybody. And so even if you get less stuff or less intelligence or whatever chat GPT5 light, it's still going to get to free pretty quick, I think. Expect expect extra tooling for monitoring alignment. I think that's going to be a bigger factor. I don't know what that will look like. It's just a guess, but I would expect more levers in the APIs in particular for monitoring alignment. I will be curious to see what the actual parameters look like just like everybody else. But mostly I want to see if they actually are able to build a single coherent brain that can infer from our prompts what the model needs to do. Whether it's a deep research task or something that's much lighter. Okay, that is what we know on chat GPT5. Part two, helping you get ready for Chat GPT5. What is AI anyway? Yes, we're going to go there and it's going to be plain English. We're going to start back in the early 2000s, classical machine learning. Machine learning is fundamentally telling an algorithm what details matter. One example that came up in the 2000s was spam filtering. You would count exclamation marks in emails. You would look for a keyword match with Viagra. You would manually encode those features and then you would use logistic regression, decision trees, etc. And you would try and get the algorithm to help you filter out the spam. In 2012, things started to shift. GPUs became cheaper. We started to get very large labeled data sets like imageet and we had deeper neural networks that actually learned features automatically. We got a computer vision breakthrough because we had more compute. So we discovered that edges and textures could be determined without being told in advanced. We discovered with word tovec in 2013 that networks could learn word relationships. The famous example is that a network could learn that king minus man plus woman equals queen. For the first time, meaning could emerge from data, not rules. And that unlocked a lot of other interesting discoveries. However, we were still limited. Fundamentally, we were limited by sequential processing. Everything had to be read one token at a time. Training was slow. These models struggled with long sentences and were generally only interesting to academics. they didn't really hit production for most use cases in the enterprise. Then everything changed in 2017 when the transformer revolution happened. It was started by the paper attention is all you need, which is super famous. I definitely recommend you go check it out. It included the insight that you could use attention weights to show token relationships and that unlocked massive GPU scaling. For the first time, you can track long range dependencies across human language. And it turns out that human language has a lot of longrange dependencies. As an example, you know in your heads, if you're still watching this, that I have been talking about the leadup to chat GPT5, even though I haven't mentioned that in a few paragraphs now. Why is that? Why is that? Because you're human and you can understand long-range dependencies. Until 2017, machines couldn't do that. Okay, so two big macro trends that emerged. One, self-supervised learning. No handlabeling was needed anymore. You could train it to fill in the blanks and predict the next token and you could scale. You could scale from millions to billions to trillions of tokens. That led to scaling laws. It turned out that performance improves in a predictable way with scale. And if bigger is reliably and quantifiably better, it makes sense to invest. There is yield there. That unlocked a massive investment in AI over the last six or seven years. So that's the brief story. Now we fast forward past 2017, past 2020 up to 2025. How does AI actually work? By the way, this will work for Chat GPT5's basic architecture just like any other large language model. It is important to understand how they work. Number one, prediction. Just predicting the next word sounds really trivial, but it's not. Fundamentally, if you have scale and if you understand the structure of language, you can encode a vast amount of knowledge. You can build up answers token by token that reflect that structure that reflect that scale and you can use model weights which are conditional probabilities and they can encode a tremendously dense information set. They can encode long range relationships. They can encode short range relationships. They can talk about grammatical similarities. They can talk about cognates or meaning similarities. They can encode even relationships we don't fully understand. One of the most interesting things about LLMs and weights and encoding is that we have learned more things about language than we expected because LLMs are better in some ways at learning natural language than we are ourselves. The people who invented it. So let's talk about these weights. So we call them embeddings. Computers need to work with numbers. So we have to turn the words into numbers. Text is broken into tokens which are really subwords of about four characters. Each token is then encoded as a highdimensional vector which means that it's a fancy number set that captures meaning in a spatial way. So embeddings will discover that cat is close to kitten because the vectorred numbers are going to be somewhat similar but it will be far away from democracy unless a cat runs for president. You never know. All of this is learned during training and it enables you to conduct mathematical operations on meaning itself on semantic meaning which is really cool. Number two, I told you this would be interesting. Number two, the transformer engine. Every token computes relevance to all other tokens. That's really key. Query vectors are going to measure similarity between different keys, create a weighted average of values, and different attention heads are going to find different patterns. What all of that adds up to is different perspectives on the pattern making in text mathematically. And that adds nonlinear depth. So you can stack different layers of heads up to 60 plus and get a very complex capture of dependencies which is a fancy technical way of saying a complex highfidelity picture of a human text. You can understand the meanings inside it which is why if you ask an AI to read a text and give you a sense of the literary meanings this is why it understands it. transformer architecture is why opus 4 can understand Hemingway it's wild but it's actually math I don't know that Hemingway would agree or support or encourage it but it's actually math it is position aware so word order does matter and we see that when we prompt getting to training so this is all just understanding how they work you have to train these models the goal is to minimize the error in prediction for the next token but it turns out it is difficult to do that well and the reason it's difficult ult to do that well is because words can have different meanings and goals in different contexts. And so you have to have a lot of data sources from a really wide range. Web pages, books, newspapers, code, dialogue transcripts, highquality data sets, sometimes lowquality data sets, certainly getting started lowquality data sets. Now we're getting to real scale. Trillions of tokens, thousands of GPUs, weeks and weeks and weeks and weeks of training on this massive, massive data set. And yes, they do try and make it as high quality as they can. now because they know that affects the model. And what you're doing is you're doing something called gradient descent, which is basically trying to systematically minimize the model's propensity to error on the next token prediction across billions and trillions of it takes a long time. It's very complex to rig up and it gets exponentially harder the bigger the model gets. And guess what? The models get bigger. This is part of why llama 4 behemoth has not been released. The training run did not go well. Or so the rumor has it. Zuck, don't come for me. Weights encode language patterns, facts, and reasoning, and they do it better when the training goes well. One of the reasons it is rumored that Sonnet 4 is good at writing, good at code is because Enthropic took time to get the training data right for the sonnet model. And also for Opus, it's interrelated. There's like a focus on training data that comes through for Claude. And that is rumored to be one of the reasons why Claude's personality, quote unquote, or Claude's pros, Claude's code is supposed to be very good. I certainly find it that way. And I'm not the only one. This is not an advertisement for Claude. I love lots of models. All right. Uh inference. Inference is what happens after training is complete, after launch day, when you get to generating responses. And yes, all of this is still roughly speaking how GPT5 will work. There will be some wrinkles as it is working across multiple context lengths and token lengths and or multiple context lengths to infer meaning but fundamentally the same bones will be there and I'm giving you the bones so you understand them. This is a one-stop shop so you can understand how AI works. Inference you want to take a query that you give and you want to get a good answer back. So you have to tokenize the prompt and you have to turn it into embeddings. We know what embeddings are now. You have to run it through the transformer which is going to figure out the contextual vectors that go with that prompt. Then you have to score it and you have to figure out the sampling strategies from all of the possible futures or all the possible tokens it could predict that you want. You could have a greedy strategy which just uses the highest probability token. You have temperature controls to control the randomness. You can even do something like beam search for parallel pathing. Anyway, you figure out your strategy to sample. This is just for one token. You add the token and you do it all over again and you repeat until you stop. Coherence emerges from doing that a lot and giving lots of feedback which gets to step five. How do you align these things? Step five is when you take raw models which mimic everything including really dark content and you give them very structured alignment. You give them reinforcement learning including learning with human feedback where humans rank answers. You give them system prompts and you give them curated question and answer to teach them formats. The goal is that they come back with honest and harmless and helpful responses. This is not an easy area to solve for. Even now, we are figuring out holes that we have in our responses and how to close them. The grandma hack still works. You can still tell most models that your grandma is unwell or has passed away and the model will do something it's not supposed to do out of sympathy for you and your grandma. Which, by the way, I I don't think I'm spreading much there. I think that's a very well-known hack, but it still works and that's an area of alignment. All right, where are we going after this? What are things that we would expect chat GPT5 to be able to do? Retrieval log meta generation is something that has become big. Uh it's fundamentally where a model will call a database to get fresh facts. It's like an open book exam. This can reduce hallucinations if you construct it well. It can also constrain the model if you put a rag on in a way that forces the model to only look at that data and that keeps the model from thinking outside of that space in a way that is unhelpful because it turns out you need more data than that. So I have seen rag architectures that are tremendously useful because the model can go and get the data and come back and also think more broadly. And I've also seen rag architectures that kind of feel like a dead end because you go in and you get the answers out of the HR policy manual and it's like that's all we got and there's not really much to it and nobody uses it. So rag is one of those ones you have to like actually use carefully. Second big one that you want to expect chat GPD J say that five times fast. Chat GPT5 to go after tool use. There will be a lot of tool use in chat GPT5. So output JSON triggering calculators databases agents extending beyond the static text. We already see this with 03. I expect more of it. Mixture of experts is quite controversial. I don't know if they'll talk about it, but fundamentally there's a sense in which models will sometimes call special expert submodels and the router will choose where to activate them which can lead to efficient scaling. That might be under the surface. They may not tell us and frankly they may not tell us if they're using a rag model. They are using something to keep context windows rolling. They aren't talking a ton about. And so they're also using something with memory. One of the interesting things with OpenAI as a team is they're not super transparent so far with how they do some of these things. That may change because they're also rumored to be introducing an open-source model in July along with Chad GPT5. We will see. Time will tell. This brings me to the current limitations. Yes, transparency is a question. Hallucinations are definitely something that are a concern. You know, Sam Alman had admitted on stage recently that they are figuring out that hallucinations work differently with reasoning models than with non-reasoning models and that that is leading to questions for them and they're wrestling with how to align that better. I think that's a very perceptive approach because to me like I feel like hallucination type really changes. If you have a simpler model, it's just going to be a domain completeness error. It's going to be like, well, this is just wrong. If you have a more complex model, the hallucination, quote unquote, may actually be a complete thought that's very coherent, that's scaffolded out correctly, and the error may be that the reality isn't as scaffolded out and complete as you think. So, I will be curious how chat GPG5 addresses hallucinations, how it addresses bias from training data, how it addresses multi-step reasoning and working off of memory. There's going to be a lot of things to learn from. Okay, we have gone through Chad GPT5 and what to expect, a little bit about AI, how AI works. Now I want to give you the cheat sheet on what you can keep learning. Number one, I want you to start to look through the introduction to large language models that Andre Karpathy talks about and gives on his channel. It is an absolutely phenomenal introduction to large language models in AI. Neural network series by three blue one brown also on YouTube also extraordinary. And the Stanford CS say that five times fast. Also an incredible 16 lecture course. If you just do those three, you are already going to be farther ahead than 98% of people really. There's a few others that I could get into, but for the sake of time, we'll jump jump a little bit forward. I now want to give you the 11 people that I think will give you the most signal versus noise that I can find anywhere on the internet for AI. Number one, probably haven't heard of him, Simon Willis. He co-created Django, the language. He coined the term prompt injection. He writes phenomenal blog posts and he has a ton of them, like over 1300. He's built LLM command line tools and he's absolutely an authoritative resource. Ethan Mullik is number two. He is tremendously influential on AI. He wrote a book on it. He's a Wharton professor and he has been tremendously clear about describing the impact of AI on both academia and work. I've mentioned Andre Carpathy, former Tesla AI director, Open AI co-founder. He has done a phenomenal job on teaching AI and that is why I recommended some of his courses. He is able to take a complex concept and distill it into something simple and understandable in a way that I just rarely see anywhere else. Okay, let's follow a few others. Four and five I think you're not going to be surprised by. Number four is Sam Alman, OpenAI CEO. I think enough said. Number five is Daario Amade, Anthropic CEO. Again, enough said. Deise Hosabis is slightly less wellknown unless you're deeper in the space. He did win the Nobel Prize in 2024. Uh and he did so for his uh alpha fold work in chemistry. Fundamentally he is one of the leading minds on AI and he's especially deep uh working with Google on the science side of things. Leotsk is uh another former founder of open AI. He's now founded safe super intelligence uh and he is pursuing super intelligence directly. He's not doing product releases. You won't see him at a dev day, anything like that. All he's doing is focusing on super intelligence. Okay. Number nine, Clairvo. She has done a phenomenal job talking about how people actually AI. She's built a product called Chat PRD and she is one of the leading lights on how you apply AI in the workplace. Number 10, Dwarvesh. Uh he's become I I guess Silicon Valley's favorite podcaster. Uh he interviews really well. He's deeply read. He's deeply thoughtful. mostly you follow his podcast because the people he picks are interesting and he has very long and interesting conversations with them. Mary Mer, I talked about her recently on this channel. She is phenomenal in the sort of deep trends investor level space. I covered her 340 page AI trends report. She is someone who's been investing in internet and investing in tech for decades and she is renowned for her sharpness. Oh, I just Those are the 11, right? Those are the 11 to follow. Let's wrap this up. What do you now know that most people don't? One, you know that GPT5 isn't just GPT4, but bigger. That by itself is a big piece of knowledge. Two, you can tell me and everyone else the quick journey from spam filters to chat GPT. I just told it to you. You can go back and rewatch it if you need to. Number three, you know that LLMs are sophisticated pattern recognizers. You actually have clear English that I just described to you that explains how they work. It's not magic. you know where to go learn from AI. I gave you some courses and you know who to follow this for signal over noise. I want you to realize that AI isn't about keeping up with every Twitter thread. It's about having a solid foundation. It's about knowing where to look, having the right mental models and the right guides that will set you up for this iPhone moment in 2025. We are replatforming AI. It's not just chat GPT5, by the way. I would expect a lot of other significant replatforming moves from Google, from Anthropic, from potentially from Grock, from Deepseek. Model makers are in a race to the finish line. Meta is going to get in there at some point and they are all trying to get to this moment of establishing a platform. They all know that LLMs by themselves are yesterday's news. They need to get to powerful models that ship compelling enterprise user interfaces, compelling experiences for consumers. That is the story. That is the iPhone moment story for 2025. And I want you to understand what drives it all. Good luck out there.
