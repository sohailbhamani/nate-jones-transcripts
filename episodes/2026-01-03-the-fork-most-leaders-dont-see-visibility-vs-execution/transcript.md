---
title: "The Fork Most Leaders Don’t See: Visibility vs. Execution"
video_id: "s1eqzfXCgXI"
youtube_url: "https://www.youtube.com/watch?v=s1eqzfXCgXI"
publish_date: "2026-01-03"
duration: "13:25"
duration_seconds: 805
view_count: 12725
author: "AI News & Strategy Daily | Nate B Jones"

yt_tags:
  - "AI strategy"
  - "AI agents"
  - "automation at work"
  - "future of work"
  - "enterprise AI"
  - "tiger teams"
  - "AI for teams"
  - "LLMs"
  - "productivity metrics"
  - "AI visibility tools"
  - "legible work"
  - "small teams"
  - "AI native startups"
  - "AI strategy for leaders"



# AI-enriched metadata
content_type: "Opinion"
primary_topic: "Career"
difficulty: "Intermediate"
audience:
  - "Engineers"
  - "Executives"
  - "Product Managers"
  - "Founders"
entities:
  companies:
    - "Amazon"
    - "Slack"
  people:
    []
  products:
    - "Make"
  models:
    []
concepts:
  - "You should measure your teams by their outcomes, by the impact that they deliver, not by just adherence to an ai generated plan"
summary:
  - "Execution

AI just made it really really cheap for companies to see what's going on inside themselves, right"
keywords:
  - "ai-strategy"
  - "ai-tools"
  - "amazon"
  - "career"
  - "coding"
  - "leadership"
  - "make"
  - "product-management"
  - "slack"
  - "workflows"
---

# The Fork Most Leaders Don’t See: Visibility vs. Execution

AI just made it really really cheap for companies to see what's going on inside themselves, right? To examine PRs, to examine Slack threads, you name it. It's easy for someone to see it. And in fact, we see companies being formed, solutions being sold that are basically the single pane of glass for enterprise see everything. This is a trap. And I want to spend time talking about why it's a trap because I think it's really really dangerous for companies to believe that AI making everything visible is what you need. It's much more useful to think about AI as a power pack for small teams that lets them do real work. Why am I contrasting these? I actually am drawing inspiration from Shan Gade's recent essay around legible and illeible work. The basic idea is that legible work is the stuff that shows up in Jira, in OKRs, in road maps. It's planned. It's trackable. It's explainable to external customers. Illeible work is the harsh reality underneath, right? It's the favors. It's the back channels. It's the shared intuition. It's the quick fixes. It's the tiger teams. It's just let me handle this. Illeible work shows up more places than you'd think. And it it's what keeps companies going. Think about this. When something really important happens in your work, who do people go to? When the database hits a limit, who do people go to? Right? When a top customer is on fire, who do people go to? The company will tell the truth when there's an emergency. The company will usually suspend whatever formal process it has and let a handful of trusted people go solve the problem. This has always been true, right? AI doesn't erase this. It just amplifies it. And the problem with amplification is that if AI makes real legibility, the reasonable amount of clarity you need to understand how the business runs, if it makes that cheap, it's going to make fake legibility, the belief that you can see everything even cheaper. That's what these vendors sell is this single pane of glass. So the old cost of legibility helped to constrain it. There was real human effort before AI in making things visible for leadership. engineers had to write tickets and then PMs had to write summaries and then managers had to write decks. AI drops the cost of all of those kinds of activities down to zero. And that's so clear that we even see cases where companies like Amazon are firing middle management whose primary job was just to coate that information, right? Because LLMs can pull a decent state of the world from a really wide range of things, right? from code diffs, from Slack threads, from docs, from meeting notes, from on call logs, from tickets, even the badly written ones. So you can ask an AI what changed in this service last week and what did we actually ship and what's blocking the road map and you don't need a weekly status meeting to answer those. So if you're looking for real visibility, there is an upside here. I don't want to I don't want to say that these companies offer no value, right? You can potentially get to a world where there's less ceremony, there's clarity, there's less pressure to stuff everything into a rigid process just to make it visible. But there's a darker side, too. And I'm seeing it show up, and I want to be honest about it. AI makes it trivial to generate the fake appearance of legibility. Put another way, AI makes it so easy to generate a Potmpkin village. Dashboards can look really empirical, but they might not be debugged because they were vibecoded. Risk scores can appear and look really good, but no one really knows what they mean because they were written by AI. Productivity metrics can be put together and they really only correlate to ticket turnurning tricks and not to meaningful outcomes in software building. So the danger is really not that leadership becomes blind. It's that leadership becomes overconfident in the wrong map, an AI generated map, AI slop that gets into company channels. And then I want to look at the other side, the real production engine of AI where the real work done when you point to important people and they're the ones that really fix things that that power is being handed to fewer and fewer people. Smaller and smaller teams are able to do more and more. And so if real progress looks like a tiger team, maybe a good company looks like a series of tiger teams with shared context, shared taste, shared trust, and the ability to move really quickly without waiting for permission because AI gives these groups not just like forget the reporting, right? AI gives them leverage. AI gives them faster coding. AI gives them exploration of options. AI gives them faster debugging. AI gives them faster synthesis, faster customer understanding. A great one table, five-ish person pod can now produce what it used to take 20 to 30 people to make in a traditional structure. And at the same time, AI is giving leadership a really seductive feeling of omniscience, right? This belief that you can see everything with AI. Don't mistake that for control or even necessarily for clarity or you're going to apply AI to the wrong part of the organization. You're going to use AI for top- down scoring for AI drafted road maps, for automated oversight rituals, and you'll end up treating this amazing tiger team as a replaceable unit instead of a real engine of value. And so really I am challenging you to think about whether you want to be a tiger team company or whether you want to be a company that is like a magnifying glass company. You know like I'm just going to stare at everything. And I have to believe that for most leaders the magnifying glass is the reality. The org by default wants work to be legible. Sean points this out correctly. This is how leaders are wired. It takes work to value tiger teams because a can make really nice strategy decks, really good OKRs, really nice productivity scores, really nice performance reviews, and what happens next is predictable, right? The more you push on this, the more Tiger teams will hide their real work, right? Because it doesn't always show up. It's sometimes messy. And I see this all the time where leaders are like, "Well, why is there a conflict?" Like, the tiger teams are doing real work. We don't need to hide it. Real work is messy and if you have a culture where messiness is not encouraged, real work is going to get hidden. And that's still true in the age of AI. In fact, I would argue that AI powered teams make a bigger mess than they used to. And so teams will hide their work. Back channels will become more covert, more political. People will optimize more for metrics instead of outcomes. Enterprise customers will hear a pretty story until the day the company can't deliver, right? They'll be on this map that doesn't exist. And I've seen it and it it looks perfect, right? The map looks perfect. You feel like you can see everything. You don't realize that the root system of your company is dying because no one is using AI to drive small teams forward. So what does a tiger team company look like? A tiger team company looks like an org that is honest about where value really comes from. These small teams are the primary production units of your company. And AI's job is just to translate that messy high velocity reality into something kind of approximately visible and trustworthy for leaders. Let that legibility, let the AI reporting follow behind the work. Don't let it dictate it. This version of the company has teams as sovereign units with clear scope outcomes, AI power to leverage them, and really clear trails of work that can be turned into reporting later. Right? You're not overnormalizing all of the schemas. You're just letting them move really quickly and you're making sure that you can back translate it effectively into the formats the rest of the company can understand. And these teams have fast lanes, right? If you have a good team, they're going to know what spiking on a problem looks like. They're going to look at like what emergency mode looks like where you put two pieces of pizza in there and they can't come out until they've eaten and they've gotten it done. you're going to be able to understand what a team that breaks down traditional job family distinctions looks like. So instead of thinking of these teams as only engineering, right? Like think of a team that might include sales and CS and legal and finance and ops all on the same mission using AI to understand each other's work and really working together to accomplish a common objective. The company can move fast without lying to itself. That's my objective here. It just needs to stay legible enough so the rest of the world can understand it. It doesn't need to suffocate the people who are doing the real build. So this is my challenge for you. If you are a builder, if you are a leader, please think of AI features you're adding as just realistic translators for work teams are already doing. Don't think of AI in a supervisory or goal oriented capacity where the the AI has to say checking on your OKRs. How are you you doing? Please don't accept AI metrics you can't trace to concrete actions. Don't accept vapor metrics. AI can make those so easily. Number three, please protect fast paths. You don't need to stick everything into a controlled pipeline. If your Tiger team has a spike mode and they're able to solve things, let them. It doesn't matter. You'll work it out and report it later. You can treat AI as a cheap historian that reconstructs meaning after the work, not as a bureaucrat that dictates it from above. And this requires leaders who understand the balance between needing to make work explainable cuz you you do need to do that and being willing to accept the mess that goes with real work, especially real work in the AI space, which as I keep saying is like two or 3x is messy because teams are generating so much stuff. Please, this means you should measure your teams by their outcomes, by the impact that they deliver, not by just adherence to an AI generated plan. So the most important shift for leaders is really mental. Stop pretending that the whole org is a production engine with perfect pipes. Recognize the reality on the ground in your org. There are a few tiger teams in your business that sustain the whole business. know them, value them, empower them with AI, and make sure the rest of the business orients around them or figures out how to adopt a tiger team model. Don't try and strangle them with your new single pane of glass AI approach. I have seen this. You can ruin an organization by trying to make everything AI perfect. Don't assume that AI is the perfect engine for squaring off the organization so that it has no weird odd corners with dust bunnies in them and your engineer in the corner and the furnace going really hard. That's where the work happens. It happens in the strange corners. I'll tell you a story as we close our time together. I had an engineer. I've actually had two of these where the work that was most valuable during my time as a product manager was not the work that the organization planned, not the work the organization put an OKR around. It was the work that the engineer literally did on the weekend because they were motivated and they cared about the role and they cared about the problem. And in both cases, the engineer just came in one Monday morning and said, "Hey, can you look at this? I hacked it together." And in one case, it was a machine learning solution for something around artwork. In another case, it was something for accessibility. But in both cases, it was a really excellent solution that we hadn't thought about, that we hadn't put time on for, that we didn't define in our work. And it was my job sitting in product to not squish it. It was my job to say, "Wow, this is in line with our overall mission as a team. I don't care if it's in the OKRs. Let's wrap it in and get it moving." And that's what good leaders do. Good leaders center their team. They preserve the messy spaces where where real work happens. And they use AI just to make it easier to translate that work to the outside world. And honestly, most of how they use AI is to leverage their teams to go faster. you would do better to work with your teams on stronger multi- aent workflows on how they can use AI to speed up their decisioning and their option exploration and spend less time worrying about AI and reporting. You can always get that later. If you chase the dream of a perfectly organized organization, you're not you really shouldn't be surprised when it keeps slowing down because that's what perfectly organized things do. Life is messy. Life will find a way to quote Jurassic Park. Let life do that. Even in the age of AI, in fact, it's going to grow faster if you let it. Because these small teams are exactly what tiny startups that are AI native look like. Incredibly messy, growing incredibly fast. I think we can take that as a lesson for the enterprise.
