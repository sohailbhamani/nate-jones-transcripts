---
title: "Google drops a new image model: Gemini 2.0 Flash Experimental"
video_id: "-yFPFEl_d3Y"
youtube_url: "https://www.youtube.com/watch?v=-yFPFEl_d3Y"
substack_url: null
publish_date: "2025-03-13"
duration: "3:51"
duration_seconds: 231
view_count: 3524
author: "AI News & Strategy Daily | Nate B Jones"

yt_tags:
  []



# AI-enriched metadata
content_type: "Framework"
primary_topic: "AI Strategy"
difficulty: "Intermediate"
audience:
  - "General"
entities:
  companies:
    - "Google"
  people:
    []
  products:
    - "Gemini"
    - "Make"
  models:
    - "Gemini"
    - "Gemini 2"
concepts:
  []
summary:
  - "0 Flash Experimental

a model from Google called Gemini 2"
keywords:
  - "ai-news"
  - "frameworks"
  - "gemini"
  - "google"
  - "make"
  - "startups"
---

# Google drops a new image model: Gemini 2.0 Flash Experimental

a model from Google called Gemini 2.0 flash experimental they really need to fix the names uh is incredible at interleaving text and images it went into wide release yesterday and you have to go to the Google AI Studio to get it I don't know that it's available anywhere else right now and if you go to the trouble and you go to Google AI studio and you hit the drop down and you get that model what you get is something that we've been dreaming of since chat GPT started talking talking about multimodal token outputs so text and images together and then they never released like Chad GPT didn't release it but Google did and Google is able to generate really really good text inside an image now so if I tell it to write a llm equation on a chalkboard in an image it's not goblook it's actually a good equation if I tell it to write text it spells the text correctly the text looks naturally written it's really good it's not perfect uh as an example um I asked it to take take a picture of me dress me in a suit and then have me hold up a handwritten sign that says today's date which is March 13th um so it dressed me in the suit well it had me holding up the sign it looked pretty natural but the paper for the sign in the image just it looked a little bit fake it was just a little bit more like a very shiny cardboard and I said hey maybe you can can make the paper wrinkled that apparently stressed out the model and we lost good quality on the text and so I don't want to convey the impression that this is perfect and it's going to take away Photoshop and designers will never work again that's not that's not what's going on here but it is a lot of progress to be able to tell an a model that you want to edit an image in a specific way and it will only touch that area as an example if you have a picture of a dragon and if it's orange right now you can say please make the dragon green and it will actually not change the outline it will not change the background it will not change anything else it will just make the dragon green that sounds really obvious that's something you could say to a human and it would work well it is not something that we've been able to do with AI to date until now so that's a really big deal it also maintains really good uh character consistency I was able to create a children's story book just this morning with a little goat and it's uh got this wonderful sort of Eastern European illustrative style that we were able to come up with and it keeps that character consistent throughout um and the goat has adventures with a bat and it's great but the point is I don't have to redescribe the character every time within the chat within the context window I can just keep talking about what that character does and Google's able to keep up in fact people are now using this as a very analog way to play video games so they'll create a character and an imaginary world and then they'll just tell Google where they want the character to go next and Google will draw the image climb a wall run through the fields go flying um and Google can do it with a consistent character so it's super interesting recommend you checking it out um I think the thing that I would expect at this point is that since Chad GPT was the one that talked about multimodal and never truly shipped it they're going to get defensive and they are going to try and ship something soon that they claim is just as multimodal or maybe as multimodal they've been sitting on but either way I would expect a share from cat GPT very soon that tries to match this capability because it is definitely pushing state-of-the-art right now so there you go new Google model Gemini 2.0 flash experimental say that five times fast
