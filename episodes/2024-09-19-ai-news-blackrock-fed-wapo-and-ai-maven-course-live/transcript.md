---
title: "AI News: Blackrock, Fed, WaPo and AI Maven Course Live!"
video_id: "rnDbLdW5wMI"
youtube_url: "https://www.youtube.com/watch?v=rnDbLdW5wMI"
substack_url: null
publish_date: "2024-09-19"
duration: "9:05"
view_count: 429
yt_tags:
  []


# AI-enriched metadata
content_type: "News Roundup"
primary_topic: "AI News"
difficulty: "Intermediate"
audience:
  - "Engineers"
  - "Founders"
entities:
  companies:
    - "Microsoft"
    - "Twitter"
    - "X"
  people:
    - "Sam Altman"
  products:
    - "Sonnet"
    - "o1"
  models:
    - "o1"
    - "SAM"
concepts:
  []
summary:
  - "# AI News: Blackrock, Fed, WaPo and AI Maven Course Live"
keywords:
  - "ai-news"
  - "anthropic"
  - "coding"
  - "frameworks"
  - "microsoft"
  - "o1"
  - "openai"
  - "prompting"
  - "sonnet"
  - "twitter"
  - "x"
---

# AI News: Blackrock, Fed, WaPo and AI Maven Course Live!

you know the last few days in AI have been absolutely wild I just want to run through a few of the things that have happened and a little bit of broader economic news and I want to talk to you about my Maven course that's coming so stay tuned there's a bunch to get through first thing is Microsoft and black rock have launched a$ 100 billion fund for AI so if you think the AI bubble is at its peak if you think it's a bubble if you think it's going to pop it's not at its peak yet if they're launching hundred billion dollar funds they're expecting to get to a super cluster or some kind of massive training center in the mid to late 2020s maybe 2027 2028 it may be in time for the training run that gets to artificial general intelligence depending on what you think about that depending on your timelines they don't know either by the way so that's why this is all very uncertain they are taking a bet they're taking a hundred billion dollar bet that it is worth getting into that market so that's number one number two the Washington Post published a big article on the energy consumption of AI and it may not be as accurate as they say uh and the reason I call that out is that there was a very widely cited uh post on X or the site formerly known as Twitter uh that basically took apart the components of a llm call and came out with a very different number it was 370 times less expensive than the number cited by Washington Post now you can say hey it's X I don't buy it this guy is a senior policy fellow in Tech and what would he know but even if you don't buy it the wo article cost actually came out to around 2 cents per call and that's cheaper than a letter and we don't complain about letters being expensive we don't now not a lot of us send letters anymore because emails are easier but still the point being if we're going to talk about the costs of AI we need to talk about them accurately in terms of the real costs involved we should not site gpt3 which is what the Washington Post article did and we need to be really clear about the opportunity cost as well what is the opportunity cost of a human writing an email versus an AI writing an email that was one of the prominent examples in the post so more to come there but I wanted to flag that because there's been a lot of comments I've seen coming in basically saying AI is really expensive and I think articles like the post need to be accurate in their report of cost so that we can have a real conversation about this um and then next I wanted to call out 01 preview so 01 preview has been in the news recently I've talked about it on this channel briefly we have now had it for a few days we are now getting apps built by 01 preview frankly I saw a weather app built by 01 preview that looks nicer than the weather app on my phone all it needed was an API to be functional and those apis for weather are ubiquitous you can just plug them in and go makes me want to build a weather app for my phone maybe I should do that but that's an example of how quickly it can sort of put together a fully fledged application in just one or two prompts one of the things I've noticed with o1 is that 01 is really really helpful at debugging code and I'm not the only one so I gave it some code written by Sonet two nights ago it took 30 seconds to think about it and it came back with a much cleaner structure it successfully pulled Sonet out of a death spiral with the code and I got the code working I heard other people uh that I know of talking about uh 01 debugging 3,000 lines of code and finding a single character out of place so that matches my anecdotal experience it's really good at debugging the other thing that I want to call out it's not just code right people are identifying it as a good editor and a good editor is different from a good composer when you write with sonnet sonnet tends to overwrite it tends to write an entire text and then if you tell it to change something it just rewrites the whole text whereas 01 can be more nuanced about the changes it can it can use a a scalpel right it can precisely adjust things so that they sound better we're still at the beginning of discovering what 01 can do but I think that the way I'll leave this the challenge I have for you is if you don't think o1 can do something if you don't think a large language model can do something why have you tried it if you say oh it's the inputs oh you know 01 won't accept images1 won't accept whatever it is there's ways around that you can take the text and you can stick it into a prompt and now you have the full text of the document and the prompt just as an example you can also switch models partway through the chat you can be talking to chat gp40 and then partway through the chat switch over to 01 and see what happens another creative idea that I saw H and came across that I really love is pick a task that you don't love record yourself doing it in a loom video and talk your way through it then take the transcript and upload that to an llm and ask it what can be automated just see what can be automated I would be really curious I bet it has some ideas and I bet it could help you automate so we're at the stage where my bias is to ask the llm and I think that's a huge difference you can actually see it in the chatbot Arena scores so chap out arena for those who don't know is a gigantic um well that's what it sounds like it's an arena where people compete against uh basically rank uh various llms against each other to see what the quality of answers are and it's crowdsourced so like no given company can really game it and the problems are crowdsourced so again nobody can really game it and I will tell you it is an absolutely jaw-dropping graph when you look at 01 and mini and 01 preview they are like 100 points better uh than any other model and by the way we're talking 100 points is a lot so everybody every model right now is within the same 50 to 70 Five Point radius somewhere around the 1250 Mark to 1200 roughly in Elo or ELO ratings which is basically a mathematical way of estimating relative strength versus another player it's used in chess a lot actually but now it's used you know to estimate chatbot competency this is for mathematics 01 and 01 pre or 0 preview and 0 mini are over 1350 they're much much better a step change better than other chatbots and I call that out because there's been a lot of talk about mathematical reasoning and the ability of a model to do reasoning this is just the preview Sam Altman has called out that reasoning is about to get better I think he described it as the g at the gpt2 stage with 01 preview he thinks reasoning can get immensely better and he says that the full 01 model is coming in just a few months so if you think well there's weaknesses in 01 I don't know well just just wait right just wait a couple months uh you'll you'll be surprised Okay so we've talked about 01 we've talked about some of the AI news I want to talk about economic news the FED cut rates by half a point that is a big deal it means that there is more likely to be capital in the system for Tech and you thought the hundred billion doll fund was Capital there's more likely to be Capital available for startups as a whole not just AI startups there's more likely to be an appetite for hiring it's good for jobs people are more likely to be confident in the economy housing prices are going to get a little boost because mortgages are cheaper to purchase it's good for everybody we've been waiting for this rate cut a long time there may be a couple more coming later this year we will see they cut point they cut the rates by more than expected by the way the expectation was just a quarter of a point so they doubled that to half a point we'll see where this lands but it's very very good news for those of us in Tech who have been waiting a long long time for rate cuts to loosen capital in the space and last but not least I want to call out that my Maven course is live folks have already enrolled I am excited to launch it if you are interested in signing up in getting on the wait list in enrolling you can check out the link I'll post below and I will post a special discount code for you in the chat underneath there you go for what it's worth uh and that's what I got please enjoy
