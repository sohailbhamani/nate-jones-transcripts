---
title: "7 Fatal Mistakes with MCP That Kill AI Projects"
video_id: "D92aDGVFcRE"
youtube_url: "https://www.youtube.com/watch?v=D92aDGVFcRE"
substack_url: null
publish_date: "2025-09-03"
duration: "16:15"
duration_seconds: 975
view_count: 6571
author: "AI News & Strategy Daily | Nate B Jones"

yt_tags:
  []



# AI-enriched metadata
content_type: "Tutorial"
primary_topic: "AI Strategy"
difficulty: "Advanced"
audience:
  - "Engineers"
  - "Executives"
  - "Product Managers"
entities:
  companies:
    - "Box"
    - "Arc"
  people:
    []
  products:
    - "Claude"
    - "Arc"
    - "Make"
    - "MCP"
    - "Model Context Protocol"
    - "Projects"
  models:
    []
concepts:
  - "External information introduces noise that can interfere with internal reasoning"
summary:
  - "# 7 Fatal Mistakes with MCP That Kill AI Projects

I want to talk about MCPs today"
keywords:
  - "ai-strategy"
  - "ai-tools"
  - "arc"
  - "box"
  - "claude"
  - "coding"
  - "frameworks"
  - "leadership"
  - "make"
  - "mcp"
  - "model-context-protocol"
  - "product-management"
  - "projects"
  - "tutorials"
  - "workflows"
---

# 7 Fatal Mistakes with MCP That Kill AI Projects

I want to talk about MCPs today. They're obviously incredibly impactful. We're all using them. But at the same time, I noticed that when the MIT study came out, when other studies have come out that talk about the failures that enterprises experience when they use AI, much of the time those failures come down to how you integrate AI into other workflows, other operations of the business. And guess what? The king of integrations right now is MCP. I would argue that getting your MCP architecture correct is a huge predictor of whether or not you can implement an AI program successfully. And I want to give you today seven different failure modes with MCP architectures that I have seen organizations fall into. And I want you to avoid those. And so we're going to go through all seven of them and we're going to talk about why they don't work and what you should do instead. The first is an assumption. the universal API router death trap. So, if you've ever worked in integrations before, you should be familiar with what I call and what others call the NXM integration problem. It's basically whenever you get into integrations, you get this combinatorial problem where the number of integrations scales much faster than the raw count of tools. So for example, if you have three tools and five endpoints, you're going to have much more than just three integrations or five integrations. It's n * n. You're going to have like 15. And so MCP provides a way out of that. And people think that that's enough, right? They think because model context protocol provides sort of a universal API. It's described as a universal API. It's described as like this USB port you plug stuff into. You can just use anything for it, right? You can stick it everywhere. It will solve your NXM integration problem space. It will take that combinatorial scaling issue away where if you've ever managed these tools and you have to build integrations, you know, you can never catch up. There's always more tools. There's always more endpoints than there's time. And people are starting to believe that MCP solves for this magically. It does not solve for it magically. Part of why is because it adds latency. You cannot just route your API calls through MCP as I've seen some people want to do and try to do because it will kill the performance of whatever you're building. It adds somewhere between 300 and 800 milliseconds of latency on each call plus the cost on top of that of inference. MCP like the correct framing for MCP is not as a transaction layer or anything in the real time operations pathway. It's not a universal fix for the end times integration problem. I wish there was a universal fix. There isn't. Instead, think of MCP as an intelligence layer for specific complex workflows. Failure number two, the idea that context is the same thing as data. MCP provides data retrieval and so people assume that they can use it for database queries. That's incorrect. It's it's more accurate to say that MCP provides contextual orchestration across multiple systems and that matters because it enables MCP to orchestrate insights about the data in the background process. But you should not assume that is the same as a SQL query to get data back. This has cost implications, right? Studies have shown anywhere and that it boggles my mind that this is an actual study. ARX published this anywhere between a 3.2 25 and a 20 increase in input tokens with MCP integrations. I don't care what number it is at that point. The the reason that you pay attention is because MCPs dramatically increase the context available to inference by a factor of up to 100 or more. It is a massive additional piece of context. And what MCP is supposed to do if you're using it right is to help you orchestrate which context you're calling for a particular task. It is not supposed to sit there and just be your universal data retrieval layer. That is a waste of money and you actually won't get better results than you would just get using SQL. So that's failure number two. Failure number three, the hot path placement disaster. I have seen developers who want MCP to be on their critical path. Like as in when a customer makes a query on a transactional site, we put MCP there so that we know how to infer and answer their question as intelligently as possible. That sounds great on a whiteboard. It is an absolute performance disaster. It is horrific. Just think about it. Let's say you have 5,000 operations a second and your your API is is capable of handling millions. That's not a problem. If you have 5,000 operations a second, you're maxing out the MCP. Your your API would be fine, but your MCP is is throttling and dying. Your MCP is in trouble because it wasn't designed to handle production traffic. Another example, let's say you're getting one meg of MCP output tokens at a bucker request. That's charged on every single follow-up message. Suddenly, you're spending thousands of dollars an hour on MCP. Are you sure you want to do that? That's if it stands up, right? That's if it doesn't fall over. That's if the latency doesn't make the customer leave. You need to separate your fast path, direct APIs, from a smart path, MCP orchestration. And you need to know when to use each of those. Failure number four, security theater instead of real security. It is it is often the case. This is not just for MCP. It's for AI projects in general. Security controls get added after the architecture is defined as if security is a gate at the end. It's not. It's not a gate at the end. You have to think about it from the beginning. As an example, you could have an architecture that allows you to forward raw user credentials that would break audit trails and create vectors for breaches. That is something that would happen inherently in a particular MCP configuration and you wouldn't be able to add a gate at the end to really address it. This is not just a theoretical risk. Donna exposed a thousand customers data to each other for 34 days through an MCP misconfiguration. It wasn't just exposed to the wider internet. It was it was like other customers could read each other's data. You need to think about security first when architecting MCP and really when architecting AI to begin with. Architectural decisions need to understand that you have different breach factors and security vectors to pay attention to with AI because language itself becomes a security risk. That's one of the challenges that we have right now just in designing secure AI smart browsers. People much smarter than me, people like Simon Willis have called out that they are not sure how we design a good smart browser because a smart browser by its nature is vulnerable to language and there's a lot of language on the internet and how on earth can you secure that? How do you actually help the LLM distinguish between the context it ingests which may contain dangerous instructions and the specific prompt that you as a user give it? It is one of the most vexing problems in security right now. That doesn't mean you shouldn't implement MCPs in production systems. None of what I'm saying says don't do it. Instead, treat security as a first class object and make sure that you are designing systems that are secure by default versus systems that are gated for security at the end. And if you want, you know, a whole video on secure patterns for MCP, we can talk about that. It's out of scope for this video, but it's a critical issue that I think companies need to start by prioritizing. Right? If you aren't doing it yet, start by having the conversation. Start by asking yourself, how could an actor misuse the path that we've diagrammed in the architecture? That will get you farther than like 90% of companies on security right now. Failure number five, the assumption of magical performance. Most people assume I have AI, I use MCP, I add external data, I'm going to get better performance. It's just going to be magical. Again, we go back to ARC papers. MCP integrations can cause a decline in tasks. In fact, the measured decline was 9 and a half% on average. And you ask yourself why. Oh, and by the way, 9 12% covers knowledge tasks 1.4% drop. Reasoning tasks a 10.2% accuracy decline. And code generation a 17% flat performance drop. This is all from the paper help or hurdle rethinking model context protocol augmented large language models which came out on the 18th of August by weang ha nan jang and a few other authors. Fundamentally external information introduces noise that can interfere with internal reasoning. That is why performance can drop. In other words, if you think about MCP as a contextual orchestration layer, you have to recognize that the context you give it can cloud its judgment rather than improving it. If your context is not clean, if your context is dirty, if the external data you add is clouding the issue, you are going to get performance drops. That doesn't mean everybody gets performance drops. When I look at this, what I say is, okay, probably most of these people were using MCP for the wrong ask and put bad context in and look what they got. Because anecdotally, people are also using MCP to and see tremendous performance gains. They complete tasks faster. Their chat experience has tools enabled. I benefit from MCPs and so do you when you use Claude and Claude calls tools. And so it's not that MCPs inherently are a problem. It's that you assume that using MCPs magically makes things better and magically adding context doesn't make things better if the context is dirty. You have to it comes back to data quality. You have to think about the data quality rather than making magical performance assumptions. Failure number six, the idea that the answer is microservices everywhere. I have seen architectures where developers will tell me look every microser will get its own MCP server for flexibility. It's going to be really beautiful. It looks great on the whiteboard. The problem is that it's really hard to maintain all those servers. One compromised MCP server can expose the entire service mesh. The network overhead is really high because each MCP call adds network hops and authentication overhead. It it doesn't have to be have to be that way. You don't have to configure your microservices that way. You can have MCP work within microservices, not as microservices. You can have a federated security gateway with centralized policy enforcement. So you're not having to enforce security on every microser separate. And so this might seem abstrous like if you haven't worked in microser architectures, you may be kind of rolling your eyes right now. But the thing to take away is that MCPs again are not a substitute for APIs. MCPs are not really built to be the front gate of microservices. And you should, if you're using a microser architecture, treat your microser architecture as core. Make sure you have federated security so that you're not dealing with it at the individual microser layer, which a lot of good architectures already have. And then where you need MCP, stick it within a particular microser for inference. Problem number seven, the idea that MCP gives you real-time everything. I think this stems from the idea that chat bots needed real time information and MCPs enabled Claude to browse the web. And so there's this developer fantasy that adding MCP will get you real-time pricing or inventory or payment processing or whatever. Don't use it that way. I've already talked about the latency issue. Please, please, please think about a binary protocol that would be faster and more secure. Think about the idea that you can use an ordinary real-time check from an API and you can get so much more in a secure manner because MCPs are also not easily debuggable. If you are on a pathway like payment processing and you need to be able to audit it, you don't want to be in a position where MCP made an inference and you have to just guess why the payment was denied. That doesn't provide auditability. You need to make sure that if it's safety critical, if it needs to be auditable, if it has to be real time, that you are not using MCP. MCP is fine for analysis and insights. It's fine for an intelligence layer, which is what I've been talking about. do not put it in the pathway of a direct protocol for an operational system. That's just not the way it works. Well, all right. So, we've gone through seven different issues with MCP. We've talked about the real-time everything delusion, microservices everywhere as a trap, the idea of magical performance as an assumption, security theater, hot path placement, context equaling data confusion, and finally, the idea of a universal API router. All of those are misconceptions. How do we start to think about MCP more correctly? MCP excels background analysis and reporting. It excels at cross-system workflow orchestration. It excels at content generation. It excels at summarizing content. It actually excels at complex multi-step processes where two to three seconds of latency is fine. But MCP is not for product catalog lookups. MCP is not for payment processing. MCP is not for real time pricing or real-time anything. MCP is not for a critical path that requires sub 200 millisecond response times. It just won't get there. MCP is not for safety critical control systems. So if you want to implement MCP successfully and in turn hit the leverage point that enables you to implement AI successfully because so much of this is around integration of data and how you understand data and LLM. Make sure that you understand that MCP is for the intelligence layer. Let MCP orchestrate insights for you. Let it use the inference you pay for to get you intelligence. Have a separate transaction layer with direct APIs that handle operations. Design controls for security before you start to design the architecture. And make sure you know your constraints, your boundaries, and your threat vectors. And know your latency requirements, your performance expectations before choosing a pathway, before choosing an architecture. The bottom line is that if, as the MIT headline says, 95% of AI projects fail due to integration bottlenecks, getting MCP architectural placement right may well be the difference for you between joining that failure rate and getting in the 5% that succeed. MCP is becoming industry standard for a reason. None of this should be read as don't use MCP. I love MCP. I appreciate it. As I've said, I use it every day. But because it's popular and because people misunderstand how LLMs work, I see these seven misconceptions cropping up all the time and they absolutely doom integrations and they poison people's thinking about LLMs and MCPs. They think, "Oh, well AI is not for me. AI is not going to be useful. AI is not going to deliver ROI." Well, no. The problem is you asked MCP to do what it was never designed to do. MCP is is designed to be a tool calling utility for an LLM chat experience. That was the original design. If you are putting it into a situation where it is outside that latency envelope, where you're not really asking it to infer, where you're giving it dirty data, where you're exposing it to customers in a way that's insecure, you can't blame MCP for the fact that it fails. That's just using the wrong tool for the job. That's using a hammer on your pipes, which I know, you know, some plumbers will do, but generally speaking is not recommended. So, use your MCP correctly. Use it as an intelligence layer. Separate it from your operations. Make sure that if you're using microservices architectures, you don't treat MCPS like a silver bullet. Thank you for listening to my soap box here. Model context protocols are something I'm super passionate about. I want you to succeed with them, but that requires most organizations unlearning one or more of those seven issues. Best of luck with your MCP.
