---
title: "AI News: Google Robots, Gemini 2.0 Reasoning, Claude Excel, The Mirror Test"
video_id: "izfgyzADwKo"
youtube_url: "https://www.youtube.com/watch?v=izfgyzADwKo"
substack_url: null
publish_date: "2024-12-20"
duration: "5:52"
duration_seconds: 352
view_count: 1553
author: "AI News & Strategy Daily | Nate B Jones"

yt_tags:
  []



# AI-enriched metadata
content_type: "News Roundup"
primary_topic: "AI Tools"
difficulty: "Intermediate"
audience:
  - "Executives"
  - "Product Managers"
entities:
  companies:
    - "Anthropic"
    - "Google"
  people:
    []
  products:
    - "Claude"
    - "Gemini"
    - "Make"
  models:
    - "Gemini"
    - "Gemini 2"
concepts:
  []
summary:
  - "0 experimental thinking it's available in the AI studio now from Google I have played with it it is amazing I gave it something that was a document that I thought was okay that uh Claude Sonet 3"
keywords:
  - "ai-news"
  - "ai-strategy"
  - "ai-tools"
  - "anthropic"
  - "career"
  - "claude"
  - "frameworks"
  - "gemini"
  - "google"
  - "leadership"
  - "make"
  - "product-management"
  - "prompting"
  - "tutorials"
---

# AI News: Google Robots, Gemini 2.0 Reasoning, Claude Excel, The Mirror Test

today December 20th is already a massive day in AI before open AI drops whatever they're dropping for the 12th day of Christmas and the rumor is it's something called 03 we will see but already we have four big developments for you number one abtronic which is a robotics company has collaborated with Google Deep Mind to release a humanoid robot powered by Google AI this is big from a long-term perspective because one of the significant bets on the ability of AI to continue to scale intelligence is that we find another big data pool so when Ilia suer talked about the internet being our biggest data pool and it's being something that is not renewable the only way around that is if you give AI access effectively to situational awareness of the real world Elon has called that out with his cars and his robots in this case Google's entering that Arena as well the idea is that when humans learn human babies take in far more data in their eyes and their ears than we give to even our largest large language models in their first three four years of life if you can give a robot that kind of data input from interacting with the real world as you would if it was a you know actual walking around robot well maybe that's a way to get through the pre-training wall and start to continue to scale intelligence so that's the Strategic reason why Google getting into the robotic space is so interesting but Google's not done yet so Google also in the last 24 hours released a model that took the top spot in the leaderboards from open AI 01 it's called Gemini 2.0 experimental thinking it's available in the AI studio now from Google I have played with it it is amazing I gave it something that was a document that I thought was okay that uh Claude Sonet 3.5 had written and I said can you make this better it was a very short prompt I did not do my best job at structuring a prompt it came back with the most detailed critique of how to make the doc better rewrote the entire Doc and described it in a way I could understand and then gave me the human intent behind it like the reason why it did what it did in a way that a human could understand and it made a ton to sense I was shocked I ended up using Claude for formatting and that's not really what you're supposed to use a large language model for but this model was so good Gemini thinking was so good that I just didn't need to touch it like we've gone from like it can be a draft to this might be a final draft and that's a big step forward and again open a may drop something even better later today we will see so that's number two Gemini 2.0 thinking check it out number three Claude released a long awaited update to excel understanding so Excel file understanding has been a huge issue for large language models Claude has been at the Forefront of using tool sets to understand these structured data sets and these tables and Claude released a update that essentially the anthropic team is going to let you handle a Excel file up to 30 Megs in size larger than the normal context window and they're not really clear quite how they do it but at the end of the day Claud is going to be able to look across that entire spreadsheet and extract meaningful insights even if it exceeds the traditional definition of the context window and that may be as simple as they're adding a special context window that they can trigger when a very large Excel file goes in but it's still significant because structured data sets increase combinatorially in complexity the bigger they get and so a 30 megga Excel file like I've worked with those Excel files they're really really hard to understand for a human and so getting the ability to like pull that into an AI is a big step forward finally uh I did not know this until today but apparently AI is getting to the point where it can pass the mirror test so one of the classic tests for intelligence in the animal kingdom is can an animal recognize that an image in the mirror is itself my Corgi cannot do this my Corgi is dumb as a sack of hammers but there are animals that can do this gorillas can do this there are other animals that can do this as well it's a well-known test in biology and so of course people are wondering can AI do this and the answer is AI is getting better and better and better at this Claude has passed the self-awareness test now the mirror test if you take a screenshot of Claude and give it to Claude that's how you do the mirror test and Claude can pass that now it doesn't mean that Claude passes it as often as humans do uh they apparently have a benchmark for self-awareness I didn't even know this and AI uh the four class models score at about 50% on self-awareness and humans score above 90% I didn't know we didn't score 100% but I guess we don't uh maybe nothing is 100% in this world but anyway the point is that the four class models are significantly better than the three class models at self-awareness and we should expect them to continue to get better and yes that imposes really deep philosophical questions and we're going to be asking a lot more philosophical questions around AI in 2025 so that's your update I will drop something else later in the day uh as open AI has their final day release party but I thought this news was too important not to share
