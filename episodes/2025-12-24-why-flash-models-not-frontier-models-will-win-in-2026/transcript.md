---
title: "Why Flash Models, Not Frontier Models, Will Win in 2026"
video_id: "RVviMEfaJUY"
youtube_url: "https://www.youtube.com/watch?v=RVviMEfaJUY"
publish_date: "2025-12-24"
duration: "15:41"
duration_seconds: 941
view_count: 14377
author: "AI News & Strategy Daily | Nate B Jones"

yt_tags:
  - "AI strategy"
  - "AI agents"
  - "agentic workflows"
  - "LLMs"
  - "large language models"
  - "future of work"
  - "AI jobs"
  - "prompt engineering"
  - "AI career advice"
  - "generative UI"
  - "AI automation"
  - "robotics"
  - "Claude"
  - "ChatGPT"
  - "OpenAI"
  - "hiring in AI"
  - "AI for teams"
  - "AI talent market"



# AI-enriched metadata
content_type: "Framework"
primary_topic: "AI Strategy"
difficulty: "Intermediate"
audience:
  - "Engineers"
  - "Executives"
  - "Product Managers"
entities:
  companies:
    - "Nvidia"
    - "Cursor"
    - "X"
    - "Figma"
    - "Arc"
  people:
    []
  products:
    - "Claude"
    - "Claude Code"
    - "Cursor"
    - "Arc"
    - "Artifacts"
    - "Nano Banana"
    - "NanoBanana Pro"
  models:
    []
concepts:
  []
summary:
  - "# Why Flash Models, Not Frontier Models, Will Win in 2026

So, I've been spending time thinking this holiday season about what I'm optimistic for for artificial intelligence and all of us in the year "
keywords:
  - "ai-agents"
  - "ai-news"
  - "ai-tools"
  - "anthropic"
  - "arc"
  - "artifacts"
  - "career"
  - "claude"
  - "claude-code"
  - "coding"
  - "cursor"
  - "figma"
  - "frameworks"
  - "nano-banana"
  - "nanobanana-pro"
  - "nvidia"
  - "product-management"
  - "prompting"
  - "tutorials"
  - "workflows"
  - "x"
---

# Why Flash Models, Not Frontier Models, Will Win in 2026

So, I've been spending time thinking this holiday season about what I'm optimistic for for artificial intelligence and all of us in the year ahead. And I think it comes down to this. I'm optimistic for 2026 and AI because we are exiting the era when AI is going to be judged by how clever the release is, how fancy the benchmark is, how exciting the demo is, and we are entering the era where it's going to be judged by whether it works. And I love that because that means we're actually getting to a point this year where we can focus on delivering results with AI. And that's hard, but it's meaningful work. And I think that there is really like the bubble of hype really burst in 2025. Felt it when chat GPT5 was disappointing to so many consumers. And I think the most instruction instructive conversations I've had over the second half of the year especially, they've not focused really on model road maps. They've not focused on benchmark charts. They've been about the critical edge casriven work that shows up when you try and ship real systems, real multi- aent systems, real tool use systems, real systems that enable a human to do much, much more than they could do before. And so I feel like now as we enter the new year, we're getting to a point where you can actually start to imagine the details needed to get an intelligence layer that we can all benefit from in the new year. Something that helps our work to go farther. And for a lot of 2025, we were coloring in those gaps with hope because we couldn't imagine it. Like if you think back over the year, Claude code is less than a year old. It was out in private beta in February. Uh we had just had reasoning models at the start of the year in 2025 and they were very new. These things are moving really quickly. Codeex didn't exist until partway through 2025. Nano Banana and Nanobanana Pro both came out in 2025. And so all of these things that feel like essentials for the new systems in 2026 came into being over the course of the year and enabled us to start, I guess I would call it seeing in 4K, right? We're starting to see in high definition what's possible with these models in a way that we had to guess at before. And so that's why a lot of my optimism for the new year is about the ecosystem around AI and not just about AI itself. And I think the optimism I have is also about the talent that goes with that ecosystem. I think one of the things I'm really excited to see is talent that can hold protocols and interfaces, technical details, verification loops, and the passion for the customer together so that the technical reality and the job to be done sit in one head, not in two or three or four or five heads at a time. And I think we're getting closer to those kinds of roles. We definitely have more development work to do on our people org side so that more of those roles are published and available etc. But I see people who can do that emerging more and more and they're incredibly valuable wherever they operate. So with that, let me get a little bit more detailed in the spirit of the season and talk about some bets that I feel optimistic about as we head toward 2026. One that I think is really interesting that we don't talk about a lot is that I feel optimistic that our protocols and our process are going to start to matter even more than our prompting. And so we've been treating prompting, we've been tempted to treat prompting as a very primary interface. And that was true in the chat era. And now I think we're going to start to treat it more as a layer in a more standardized tool chain for agentic workflows. And so the teams that win won't be the ones that necessarily have the cleverest instructions. They'll be the ones where the systems can reliably call the tools and pass the structured outputs and hand off work between components and where they can reliably recover when something goes wrong. That means that 2026, what I'm hopeful for is that we will be reinventing the wheel less. There'll be less bespoke glue holding everything together and more composable systems. Another thing I'm optimistic for is the idea that we will take constraints seriously in AI. That sounds like a funny thing to be optimistic for, but I I think it matters, right? Because the constraints are the difference between content and software. If you're just saying, "Write me 200 words or write me a story about X or Y or help me with this prompt," you're really unconstrained and you're just asking for a chat response. But as we move more into agentic workflows, we're going to be giving our LLMs very tight constraints in order to enable them to do useful, repeatable work at scale. And that's why I'm saying like I think we're moving through this transition where we're going from LLMs as content generators to LLMs as software. And that's a really cool journey to see. And I think a lot of teams that start to take constraints seriously are going to get the layouts. They're going to get the validation rules. They'll get the graceful degradation, the repair steps, the fallbacks, all of that baked in. And before they know it, their workflows are going to be in a spot where you can actually call it working software in production. And that's going to enable a new class of AI native experiences that go way beyond chat. And we really have all the building blocks for that. and the only thing standing in the way is just the discipline to start to take these LLMs and slot them in correctly. Another one that I'm excited about is really getting agentic workflows that understand where AI goes in those workflows. I think we've spent a lot of 2025 thinking that LLMs could do everything in the workflow. And I think where we're coming to at the end of the year is that more and more LLMs are useful for very high value roles that are narrowly scoped within agentic workflows that have very specific deterministic transforms and checks associated with them, very specific tool calls. Really, that's all about deciding and defining where that model is good at generating smart tokens and abstracting everything else away in the workflow so it doesn't have to do that. So, we let the code do what the code's good at. We let it count. We let it route. We let it validate. We let it retry. We let it diff. We don't ask the LLM to do that in the prompt. And some people would say that's anti-agent, but to me, that's very pro- agent. It's actually understanding what LLMs are good at and starting to build systems where they thrive. It's pro- reliability. So, I'm really excited to see teams start to pick that up. Another one that I'm really interested in, this is going to sound theoretical, but we're going to get practical here. I'm excited that teams are understanding how entropy works with LLM systems. Uh I think in 2025 a lot of teams accidentally built systems that increase entropy and chaos. They had too many unconstrained steps, too many loops, too many opportunities for the model to get creative in the wrong place. And in 2026, I think those same builders are going to be the ones who start to understand that LLMs don't have to be drivers of entropy. People sometimes look at these token generators and say they're just uncontrolled. They're probabilistic. You can't manage them. And one approach, which I talked about earlier in this video, is to say, well, let's put some business rules around it. But I actually think a higher level approach, which is sort of what I'm getting at here, is to look at LLMs as potentially entropy reducers or decreasers. If you can actually structure where the LLM lives against your business outcomes correctly, then what was magical before can be a kind of disciplined magic now. And I think we're starting to see that in the chat driven experiences we have off of chat GPT, off of Claude, in product. I think we're starting to see that in some of the AI native interfaces. TL Draw comes to mind. That's definitely one that feels like magic but is actually extremely structured. Another one is the way Figma is handling AI at the end of 2025. Capsules is a good example. These are all places where LLMs are being harnessed in ways that produce more compelling and coherent and beautifully designed experiences that on the on the whole decrease entropy. It is there's less entropy in the system when I can get the answer I need inside the interface I have and I don't have to spray tokens everywhere finding some answer that I'm looking for on the internet as a whole. There's less entropy in the system when I can talk to my Figman design and get that correctly laid out and then get it directly into cloud code. And so entropy is a very high order way of talking about what we're doing when we design agentic systems. And I think teams are starting to recognize that you can design systems that are high entropy or low entropy depending on where you harness and how you harness the LLM against a larger customer outcome. And so my encouragement, the thing I'm excited about is that teams are starting to intuitively grasp this even if they don't have the language. And that means that they are starting to recognize that LLMs need a lot of harnessing to produce beautiful experiences. But you can do that. And if you do do that, you can deliver things that are way beyond what chat GPT brings you. And that brings me to another area where I'm optimistic. I think we are just at the beginning of a post chat GPT software future. I think that one of the things I'm truly excited about is that cursor has shown that even if you are quote unquote a rapper, you can absolutely thrive in the middleware layer. And that's a really interesting insight coming out of the year. And I think there's a lot of room to run, especially in non-technical areas for middleware in 2026. And a lot of it comes down to what I've been talking about with designing good agentic systems, decreasing entropy, making it more beautiful and useful to the customer. And you know, to be honest, one of the things that I think is really critical for that that we also are starting to learn is figuring out how to answer requests as if they're not all the same. You know, chat GPT trained us to answer requests as if they're all the same. But one of the characteristics of these new systems is they recognize that users have really different needs and you can build different experiences around them. Like if we talk about generative UI, generative UI is really downstream of the core insight that you can route users to experiences that matter to them outside the chatbot in ways that are beautiful and useful. If I want to cancel my phone bill, I should be able to just get a generative UI pulled up and do that. I shouldn't have to go six clicks deep. And that's we're just at the beginning of figuring out how to map the customer intent into probably a power law distribution of user utterances so that we can start to say so you know 90% of my user utterances are very common, very usual. This is how I handle them. But then I use like a great multi- aent workflow and generative UI to handle that long tail and suddenly it becomes a really powerful experience and it acts to drive retention to drive engagement across the entire population. Another area where I'm really optimistic is uh what I would call sort of the graphical AI world is going to become really normal in 2026. I think this is a downstream breakthrough of Nano Banana Pro. We're going to see a lot more work product that is just generated entirely as artifacts rather than pros. Like one of the very specific implications I think this has is that we will see just slideware that's very normally just images now because it's so easy to edit and regenerate images. You can already edit nano banana images inside manis and just regenerate and it's very trivial to get a new deck. And so when we live in that world where images are essentially solved, I think that opens up for us a lot of really interesting build opportunities in the new year around imagerriven AI. And we're just beginning to scratch the surface with that, but I'm really excited about. I think another one that's really interesting to me is careers are really repricing around dual fluency right now. So the market is going to start to reward people who can do two things at once. One is understand how AI behaves at a high level of detail and two is understanding the underlying craft of their role and the customer. And most organizations are still split right now between like an AI person and then like a domain person that AI person pairs with. I am wondering if in 2026 we're going to start to see more roles that sort of put them in the same head because if you try and pair an AI person, even a very technical AI person with a domain person, the head has only half the answers. And I think that companies that can find those fully rounded people who understand a particular domain well and who also understand how a AI behaves in high fidelity, they are going to be highly sought after. And we're going to start to see HR systems rewrite jobs to get those people because people are starting to recognize the value and the alpha in the market and they have a year under their belts with AI and they're now training themselves and able to build things that they weren't able to build before and show their talent in a way that's really useful. I think the last thing I want to call out that I'm optimistic for is that I think robotics is going to have a huge year in 2026. Uh I'm not really talking about humanoids only. I'm talking about robotics more broadly. I think we have had a year where we started to put in a lot of groundwork on reinforcement learning. I don't know if you recall, but back in January of 2025, Nvidia announced their digital warehousing concept and this idea that you would give robots digital thousands of digital years of experience in simulated warehousing environments so that they would be safer in real warehousing environments. Imagine that. We've had a year to run on that. Toward the end of this year, we had a breakthrough where we're now able to use personal POV cameras looking at hands to allow robots to infer how hands move and learn from human hand movements. The the arc of the year is really around getting our learning in order so that in 2026 we can start to rapidly scale out LLMdriven robotic capability. It's going to look like constrained environments at first. It's going to look like cheaper compute at first for deployment in designated areas of warehouses. There is absolutely going to be a big push on home robotics in 2026. I don't know if that means we'll finally get the home robot laundry machine. We will see. But to my mind, I think what I'm most interested in is that the winners in this space are going to be the ones that have the ability to reliably ship and update the brains of the robots they're shipping so that consumers who are used to seeing these LLM updates every 2 or 3 months don't feel left behind when their household robot is shipped to them in November and there's a new software drop in January. I think that we're going to see essentially ecosystems start to develop where people will say the robot primitives are all there. Uh and people could be business owners, could be humans, uh who own robots at home, whatever it is, but I want overtheair updates that ensure that the robot's brain keeps getting smarter and it can use those fingers or it can use the pinchers or whatever the robot has more and more effectively over time. And I think that that's one of the pieces that we have all the building blocks for and I'm sort of optimistic to get there in 2026. What are you optimistic for in the spirit of the holiday season for 2020s?
