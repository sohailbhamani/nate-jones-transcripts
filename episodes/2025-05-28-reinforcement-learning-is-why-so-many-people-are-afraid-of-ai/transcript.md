---
title: "Reinforcement Learning is Why so Many People are Afraid of AI"
video_id: "NWL-dONze3U"
youtube_url: "https://www.youtube.com/watch?v=NWL-dONze3U"
substack_url: null
publish_date: "2025-05-28"
duration: "10:19"
duration_seconds: 619
view_count: 8359
author: "AI News & Strategy Daily | Nate B Jones"

yt_tags:
  []



# AI-enriched metadata
content_type: "Framework"
primary_topic: "AI Agents"
difficulty: "Intermediate"
audience:
  - "Engineers"
  - "Executives"
  - "Product Managers"
entities:
  companies:
    - "Google"
    - "Amazon"
    - "Nvidia"
    - "Tesla"
    - "Box"
    - "Netflix"
  people:
    []
  products:
    - "Gemini"
    - "Make"
  models:
    - "Gemini"
concepts:
  []
summary:
  - "# Reinforcement Learning is Why so Many People are Afraid of AI

I want to talk about reinforcement learning and the trajectory that that is changing for the human race"
keywords:
  - "ai-agents"
  - "ai-tools"
  - "amazon"
  - "box"
  - "frameworks"
  - "gemini"
  - "google"
  - "leadership"
  - "make"
  - "netflix"
  - "nvidia"
  - "tesla"
  - "tutorials"
  - "workflows"
---

# Reinforcement Learning is Why so Many People are Afraid of AI

I want to talk about reinforcement learning and the trajectory that that is changing for the human race. I'm talking partly in response to yet another open letter basically saying open AI and all the other mod major model makers should stop and not do any more AI work and unplug everything and we should just go back to the way things were. Needless to say, if you're on this channel, I don't agree. I think that that's the wrong approach. But I want to talk about how it's not even that it's incorrect. is that it's no longer something that's plausible. Reinforcement learning is why reinforcement learning is the idea that an agent, an AI agent, can be given an environment and a reward signal at its very simplest. And then it writes itself through all of the trial and error that follows and reshapes the guiding policies that make that agent what it is to actually weight itself to evolve to its environment. Essentially reinforcement learning is the principle of evolution for machine learning agents. It's just not stoppable. If you look at how Alpha Zero learned chess, learned Shogi learned Go, every single time this new game, this new problem space increasingly complex, all that happened was that a reinforcement learning agent taught itself how to navigate a new environment through clear rewards and an environment it could navigate with the option to write itself. Increasingly when we think about the future of AI we are essentially talking about this process of machinedriven evolution and it's not just software this same principle applies to how reusable rocket landings can be planned for SpaceX how Tesla's autopilot works. Anytime we have an action that influences a long horizon of consequences and we don't have a defined data set, we have almost infinite possibilities. We call it a combinatorial possibility set. Then the agent gets rewarded for taking a particular angle in that space taking a particular trajectory. You can never have enough data to know you've covered every street in the world with your training data set under every possible situation. You go to the stop sign, is it raining? You go to the same stop sign, is it dark? Is it thundering? Is it a tornado? Is there a person crossing the street? And then you multiply that by all the intersections in the world and all the streets in the world. Reinforcement learning is what enables an agent to navigate those unpredictable spaces using a world model that has been evolved through trial and error. That is why Jensen Hang is so excited about the work that his team is doing at Nvidia to give robots virtual spaces to navigate within. Because if you can navigate in virtual warehouses, virtual spaces, you can get to a point where the robot is learning very rapidly in virtual time. And it takes much less clock time, like hundreds of times less clock time to train the robot than it would if you had a physical robot navigating a physical warehouse because you can imagine if the physical robot jumps off the shelves and experiences a negative reward by crushing itself, well, that's going to take a lot of time to clean up and sort out. Whereas in the virtual world, if it just jumps off the shelf and it smashes into the floor, it's like a little reboot and it gets a negative reward and it keeps going. It's super fast. And that's the simplest possible explanation. There's a lot of other reasons why it goes faster. At the end of the day, simulation is economically explosive for us. We have figured out that if we can build moderately faithful digital twins, we can evolve so much faster. And that's true whether it's in a digital warehouse or you're simulating a power grid or you're simulating a supply chain or whether you are simulating language itself, which is kind of where large language models come in. If you were in reinforcement learning for an LLM, you are essentially simulating the human experience of language and you're doing it as a speedrun. You're doing it extra fast. It takes us humans decades to fully learn our languages. And then if we're learning multiple languages, even more time. And even at that point, we may be native speakers in only one or two or three. The LLM is speedrunning even more context than we've been able to acquire in our decades of life on Earth in more languages than most of us are able to learn and is able to respond with effectively an evolved ability to navigate that linguistic space. Language is a problem space with combinatorial possibilities. That's why reinforcement learning works for language. And that fundamental insight is also why people who stick their heads in the sand and just want to pretend this isn't happening, it's not going to work. The principle of evolution is the principle of evolution. The agents are learning. You can't actually unplug them at this point. I don't believe it's practically possible. And even if you could, I don't think it would help. I think the fears that we have are effectively the fears that come from letting go of deterministic control and enabling a probabilistic future. I personally would like to see a future that is more abundant, a future where everybody has more possibilities. But I think the key to a lot of that is actually enabling us to discover more economically beneficial solutions for everyone. And one of the most efficient ways to do that is through reinforcement learning. People can go back and forth on the effect of Amazon on the labor force. But from a consumer perspective from a inflation perspective, from a value to the customer perspective, it is literally using reinforcement learning to deliver extraordinary value to customers. You can get your medicine delivered, you can get your kitchen ingredients delivered, you can get your furniture delivered very quickly on your doorstep because of artificial intelligence. And they don't talk about it quite as bluntly outside the house as it really is. It is basically a website with a bunch of artificial intelligence behind it and then a bunch of warehouses. And the AI, these multiple AI systems are what keep the customer experience actually cash flow efficient. It's extremely inefficient to run a retail store online. And the only company I know that was able to use AI to run it so efficiently they generated a cash flow to drive the development of a cloud business was Amazon. That is the opposite of what you should do. You should use the cash flow from your cloud business to fund other bets because your cash flow from cloud has great margin. Of course, you would do that. But that's not how Amazon did it. They used AI to drive ridiculously efficient margins and actually were able to feed other bad scissor results. My point here is not to say Amazon is the greatest thing ever. I don't think it is. I think there's a lot we can discuss about Amazon and that's another day. My point is to give you a very concrete example about reinforcement learning that I happen to know well because I spent a half a decade there, right? Like it's very much tip of the tongue for me. Reinforcement learning is everywhere and reinforcement learning is how AI works. And people who say suddenly we've crossed this magical horizon on reinforcement learning, it just sounds so strange to me because we've had reinforcement learning for a long time. And none of these people have been really complaining about the positive impacts. Reinforcement learning is how airplanes actually stay in the air safely and have minimal downtime. Reinforcement learning is how we have more efficient pricing in our options markets for oil and gas which leads to smoother pricing. Reinforcement learning is how we actually understand the engineered reliability of systems at scale that keep massive applications up so all of us can just depend on them instead of them breaking all the time. Netflix depends on so much reinforcement learning to keep it up. Uh if you want to stream live television, tons of reinforcement learning and understanding how to build software that actually reliably deploys and reliably runs and is configured optimally. Now, I'm not here to say that you can just run a reinforcement learning program and deploy on 100 million boxes and not have an architect look at it. No one is saying that if you ever worked in that space. But reinforcement learning does help us discover novel solutions for difficult software problems and that happens all the time. Um, and in fact, you could argue that a lot of the story of Alpha Evolve last week was the story of using reinforcement learning in Gemini to evolve new solutions for Google's software and they just wanted to turn into a press release. We need to understand reinforcement learning better. We need to understand this idea that an agent if given only an environment and a reward signal, will write itself into a policy that maximizes long runs. That needs to be as deeply baked into children as theory of evolution is today. It's actually not all of that that different either. Um, I'll get off my soap box now. I just think it's something we need to talk about and understand because otherwise we're all going to just be extremely confused cuz this is one of the principles that's writing our
