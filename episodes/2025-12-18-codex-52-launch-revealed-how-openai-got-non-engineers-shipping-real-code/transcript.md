---
title: "Codex 5.2 Launch Revealed: How OpenAI Got Non-Engineers Shipping Real Code"
video_id: "tuLWIK1AVEM"
youtube_url: "https://www.youtube.com/watch?v=tuLWIK1AVEM"
publish_date: "2025-12-18"
duration: "1:09:17"
duration_seconds: 4157
view_count: 9014
author: "AI News & Strategy Daily | Nate B Jones"

yt_tags:
  - "OpenAI"
  - "OpenAI Codex"
  - "Codex"
  - "AI coding assistant"
  - "coding agents"
  - "AI code review"
  - "PR review"
  - "agentic AI"
  - "multi-agent systems"
  - "software engineering"
  - "developer productivity"
  - "code generation"
  - "code understanding"
  - "terminal"
  - "CLI"
  - "bash"
  - "Unix"
  - "git"
  - "IDE extension"
  - "VS Code"
  - "Cursor"
  - "web coding agent"
  - "DevOps"
  - "deployment"
  - "on-call"
  - "sysadmin"
  - "AI safety"
  - "alignment"
  - "memory compaction"
  - "context window"
  - "tool use"
  - "GPT-5.2"
  - "reasoning models"
  - "AI benchmarks"
  - "GDPval"


# AI-enriched metadata
content_type: "Tutorial"
primary_topic: "AI News"
difficulty: "Intermediate"
audience:
  - "Engineers"
  - "Executives"
  - "Product Managers"
  - "Founders"
entities:
  companies:
    - "OpenAI"
    - "Google"
    - "Slack"
    - "Box"
    - "DeepMind"
    - "Cursor"
    - "Twitter"
  people:
    []
  products:
    - "ChatGPT"
    - "GPT-5"
    - "Claude"
    - "Gemini"
    - "Cursor"
    - "Codex"
    - "Sora"
    - "Shortcuts"
    - "Make"
    - "Opus"
  models:
    - "GPT-5"
    - "Claude Opus"
    - "Opus 4.5"
    - "Gemini"
    - "Gemini 3"
    - "SAM"
concepts:
  []
summary:
  - "2 Launch Revealed: How OpenAI Got Non-Engineers Shipping Real Code

So a couple of days ago, I had the privilege of sitting down with two members of Codex's engineering team"
keywords:
  - "ai-agents"
  - "ai-news"
  - "ai-tools"
  - "box"
  - "chatgpt"
  - "claude"
  - "codex"
  - "coding"
  - "cursor"
  - "deepmind"
  - "frameworks"
  - "gemini"
  - "google"
  - "gpt-5"
  - "make"
  - "openai"
  - "opus"
  - "product-management"
  - "shortcuts"
  - "slack"
  - "sora"
  - "tutorials"
  - "twitter"
  - "workflows"
---

# Codex 5.2 Launch Revealed: How OpenAI Got Non-Engineers Shipping Real Code

So a couple of days ago, I had the privilege of sitting down with two members of Codex's engineering team. I got to talk with Thibaut, who's pretty well known as an engineering lead at Codex, and also with Ed, a design engineer. our focus really isn't the code. So if you're like not a developer, this is still going to be super interesting for you. Instead, what we focused on is how does Codex change how OpenAI works? And in particular, when you're talking to someone from a non-technical background like Ed and a technical background like Thibaut, how do our workflows shift? How does what we build change when you have Codex as effectively a teammate? What does that look like in practice? I think we often talk about AI-native organizations, but I wanted to take this chance to sit down with a truly AI-native organization with OpenAI and actually learn how they use Codex day-to-day and how it's changing everybody's workflows, not just the technical team. So jump in. This is going to be a fun one. Well, maybe first, I'd love to hear a little bit from you guys about who you are, how you came to OpenAI. I know that Everyone has their own story here, and I'd love to hear a little bit about yours. Yeah. Let me start, Ed. Yeah, I'm a designer on Codex. I've been an opening eye just over a year. I've been on Codex for about six months. Before that, I worked in the research team. And yeah, I've always worked at the intersection of design, design engineering, and research. I worked from robotics before at Google and a few other things before that. I went to Google as well, finally. I didn't know we shared a piece of history. Always figuring things out. So I Googled very briefly, moved into DeepMind, worked there for many, many years, and then decided to do the big jump and go to the US and come here and work for OpenAI. That was about a year and a half ago. That was pre-reasoning. A year and a half ago, that was pre-reasoning. Isn't that weird? Yes. And so in typical OpenAI fashion, joined just before that happened, like was part of like the 01 sprint. I was more like trying to be useful in any way possible. And then after that, like kind of stuck around, built some tooling for research, became super obsessed late last year on the, hey, like maybe models are going to continue to improve and their capabilities are, you know, going to continue to impress us. And maybe actually like we should think more about the products, the infrastructure around it to really benefit from those models. And then started like prototyping. You were working on similar things. Yeah. And we were not working together initially. And then we joined efforts earlier this year. Yeah. And that was sort of like how Codex got started. Yeah. So you guys were there from the beginning with Codex. Yeah. Yeah. I mean, it's had a long history, right? Right. Coding agents at opening. I, you know, the name Codex is a throwback to a model which was like, you know, prejudged deeply. Right. So coding agents have been around. But yeah, Codex as it is now is. Yeah. Codex is the product that was like released in April this year. Yeah. Mm hmm. Amazing. So one of the things I'll just ask you what I get asked about Codex because we get to chat and we get to find out. This is like the number one question I get asked is how do engineers at OpenAI use Codex day to day? I got two different patterns. One is everyone... just doesn't have a choice on like the code is reviewed by Codex no matter like whether you want it you know reviewed or not it's just been like so useful at catching issues and then there's a lot of casual usage by you know even like non-technical staff and then what we're also seeing is like at the complete end of the spectrum is like really power users of Codex that deploy all a lot of compute a lot more than you know we saw even like a couple of months ago and this continues to increase and increase and increase and um with increasingly uh complex workflows yeah some of them multi-agent you know running like for many many hours and so it's a highly personal thing uh still feel like it's very evolving that makes a lot of sense yeah go ahead Yeah, so as I say, I'm a designer on the team, so work very closely with engineers, but I'm very much in the code base a lot myself. And, you know, I think the cool thing about Codex and these recent models over the past few months is they really have been a step change. And what you've seen, I think, even since we launched our most recent product suite is... Basically everyone at OpenAI, you know, there's one engineer that I know who uses it for everything, for note taking, for like, it's basically his like primary interface to his computer. As a designer, you know, I'm seeing more and more in our like work in progress channel on Slack, people posting these demos online. And then I DM someone, I was like, I didn't, I didn't think it could. And he's like, I couldn't until a few months ago. So you've got kind of, you know, design engineers like myself hopping in more, submitting more PRs and kind of getting closer to the, you know, closer to the details. And then even, even new people, non-technical people go to market stuff, even, you know, people are really like hopping in and it's just like this kind of force multiplier. Yeah, that's exactly where I kind of wanted to chat, because I think that for a lot of organizations, that remains the dream. But maybe it's something about the command line and the terminal sort of scariness that comes with that. But for whatever reason, people find themselves sort of hard limiting a lot of these technical tools to engineering teams. Sometimes that is literally at the level of the IT policy. I've been in organizations where the IT policy only allows engineers to use tools like this. And if they catch you doing this as a non-technical person, that's a violation of policy. And I think some of these older ways of working and thinking are having to evolve. Yeah, I think the lines are, what we're seeing is like the lines are blurring. Like Ed, I mean, you're sort of like everywhere, like ideating about the future, but then also like very much like using Codex every day and then feeling, you know, does it feel right? Like, pulling up like you know prs and little fixes yeah there's like how you know that's sort of evolved very quickly right totally yeah yeah yeah and i think yeah you know to your point there's there's there's kind of one half of it which is like how do you how do you bring organizations along and you have you know particularly some of these larger organizations might have some more like institutional challenges but um but you know once you get access i feel like it's kind of getting easier as easy as possible um so you know you mentioned that it it might feel like a bit of a step up for people to get in the terminal. I think the cool thing with some of our products recently is, you know, we've shipped an ID extension. So we're not just in the terminal. We have a CLI product, which we've had for a little bit. Right. But, you know, we meet people with a code. So they might be in VS code. They might be in cursor. Doesn't matter. These are all kind of IDs. And we also have a web product. So, you know, you can, you know, once you kind of connect all the enterprise, you know, kind of puzzle pieces you can just go in a web product type in a prompt and create a fix so for example you know say you're you want to change some ux copy you're a copywriter you know maybe you don't even need to look at the code you just want to change some strings you can just do that yourself right you can go in and you can type this prompt if you're kind of enterprises set up so um yeah i think like the number of surfaces that people working across and just like yeah just makes it kind of easy and easier to get involved yeah i i think that there's that That ease of access piece you guys have done a nice job solving for over the last few months. I think the other piece that I heard as you were talking is that there's a little bit of a healthy constraint in something like having Codex review every PR. Like, it doesn't matter. It's getting reviewed. You have to engage with it. And I think that's also going to be new for a lot of organizations I talk with. And the thing we've been very careful about is also optimizing for signal to noise ratio and making sure that the hit rate is very good so that people don't actually complain and want to turn it off. And overall, as an organization, we're getting way more value out of it than potentially sometimes the misses. And then we keep improving the system and the model over time so that it's capable of finding more and more gnarly and subtle issues over time. And people are generally impressed. It's like, I hear it all the time. Like, it's like, oh, this thing is superhuman. It's like it's doing reviews I would never have done because I don't have the time to dig like four layers deep into the stack. And it's just having that always on. You don't have to think about it. You have that safety net that's just there. Yeah, super interesting. Like, I think particularly something like Code of You as a designer is thinking through the user experience, right? It's like, oh, no, is everyone just going to get loads of emails? Yeah. And, you know, it turns out that like, it's like one of the most loved features that I think we've shipped. And that one of the things that changed for me was seeing some of our top contributors across OpenAI, not just our team, you know, commenting in our Slack saying like, this is, as you say, superhuman. And, And I look forward to those notifications now. It really just adds so much value. I think there are two things that are emerging, right? So this ambient intelligence and code review is one example of that where it just happens. You don't have to tweak it. You don't have to think about it. And you just benefit from that intelligence being deployed. And then the other thing is people starting to use it as a little assistant in their computer. Like, it's not really about code. It's like, it does like, you know, sysadmin tasks, you know, pulls like context and, you know, maybe the latest news for you. And it's just like, or craft like some new designs and new ideas. And then like for that, the current way that we're doing it in the CLI and the extension, it's like your institute, it wants to be more. And so like the current interfaces are maybe like holding things back a little bit. You feel it? Yeah, it's kind of like, it's kind of both ways, really. Like in some ways, you know, there's this throwback to the terminal that people are getting nostalgic about. And, you know, from a design perspective, there are these kind of two counts. One is this, it's this kind of pilot trick. It's this like transitory, you know, kind of like form factor. And actually, you know, there's this like, perhaps there are some like new interaction paradigms that we're like pushing towards, but perhaps aren't there yet. On the other hand, I think like the constraint of the prompt box is, You know, the terminal, like it's kind of perfect as well for a way, right? It means you where you are. And it's very cool to see the workflows that people have built around that. So you can literally, you can just spin up your terminal and you can, yeah, as you say, right, you can write notes. You can do all of these different things from just like such a simple form factor. Yeah, I think one of the things that has surprised me, like if I go back to that idea of a non-technical use case for Codex, I find that Codex is an extraordinarily logical model. And when I'm using it for a non-technical use case, I find that there's a sharpness and a conciseness about how it evaluates a particular set of inputs that feels like I can see where it came from. It feels like, of course, you would get this from a model designed for code. But it turns out that there's a There's an extensibility to that emergent property that helps with a lot of other things. And so, like, I did a business case analysis, and it wasn't technical, right? Like, you're analyzing business inputs like revenue, and you're analyzing sales figures, etc., But it applies that same rigor, and it turns out that you get a response that's really coherent, it's really clear, it's cogent, it makes sense, it's easy to read, and it's, as a result, very, very useful. And I just, I love the idea that these models end up having extensible properties that perhaps spin off of what they were originally designed for and allow us to do lots of other things. There's that element of, hey, this model is trained to be precise and correct about things and diligent and double check, maybe triple check its work sometimes and not do all the math in its head or in its context and maybe write a little Python script to help itself out. I use it for data analysis all the time. And it's not about the code anymore. It's about the result and trusting the steps as you put it. It's like a very cogent, like legible explanation. You can like see step by step, like what, you know, why it's doing things. And then there's a question of like, at what point, you know, for these kinds of tasks, do you still need to look at the code? Is the code just a tool that you don't really care about? And then you're using that as a stepping stone. So then you have like a coding agent that's maybe evolving into like, you know, a more general kind of assistant. I guess it's an interesting thing to think about. Yeah. Yeah. In terms of the use case, you know, you mentioned about kind of like, you know, design showing up in different places. And I, you know, I think the same way about some of the use cases for designers. So like on the one hand, there's like fixing the paper cuts of, you know, because we're in these tools all day, every day, like literally eight hours a day, you know, any small, any small paper cut that you get, you just see and you can fix it. And obviously, you know, you're submitting a PR, it needs to, you know, you need to look at the code that you're generating and, you know, we can go through the review process. But if I'm in like a very different mindset and I'm in like design, you know, ideating mindset, like, yeah, maybe I can just make my terminal really small. Don't worry too much about the code. just have a local host open and basically, you know, just like narrow this gap from like kind of, you know, thought to product and really just focus on the interactions. You know, you can move it, you can think about responsiveness and that kind of stuff becomes more important and it becomes more like a canvas. So, you know, similar to if you're writing a very different use case, but, you know, also like a very different way of designing. Yeah, because for so long, design has been effectively disintermediated from engineering. And like coming from a product perspective, so much of the role traditionally was translate design into something that has requirements that engineers can build against. And so there was always this tension between PMs and engineers and designers when I was coming up where it's like everyone has different incentives. And really, it's all just a function of disintermediation. Like if you take away the gap and you give everyone access to the code, it's a different world. Yeah. Like often it's like, hey, Ed, it's like you're just like an engineer on the team, right? It's like writing PRs and just fixing things. You don't need to go and talk to anyone. You just do it. Yeah. Yeah, yeah. And I think some of these boundaries as well, as you say, they're kind of slightly artificial. You know, they've grown up, you know, first we had the terminal. And then with, you know, Mac, we then were like, started to think about the GUI and these kind of new disciplines emerged. And they kind of just converging and diverging over time. Yeah. You don't like being an engineer. Oh, no, no. I mean, I, I, yeah, I don't know what I call myself. I think that's the cool thing. There's an identity crisis. It's just like, what am I? Yeah. I think that we're getting into a world where job titles matter less and skill sets matter more. And it's really, it's exciting to see what happens when people can wear those hats lightly and just focus on what problems they can solve. Yeah. It's, it's, it's really a lot. It, brings a lot of clarity it's like it's all about the problems figuring out what problems to solve figuring out what questions to ask yourself so much more is possible and it's much more cheaper to ideate and build and then you find yourself like being like wow you know I really need to be crisp about what I want to go and do yeah it's like It's exciting, but it's also nerve-wracking at the same time. Good ideas matter more. They do. And correctly aimed ideas matter more, I think. Yeah, the speed and velocity, right? Like which direction you're going in. How fast you learn. Like, you know, the most successful teams that we see emerge at OpenAI are really small teams that set themselves up as well to learn and iterate super fast. And then there's like a general sense of like, oh, we're building towards this. But then like also changing things, I guess, cheaper. Yeah, I mean, there's the phrase, right, which has gone around in engineering for a long time, which is kind of code wins. And, you know, you can write as many PRDs as you like until you have the product in your hands. And I think that's the very, the cool thing that I've seen from like product teams broadly defined, whether it's, you know, designers, engineers, it's like, you know, if there's a hackathon, like at the end of a hackathon, like you'll have like a fully working product. Like you won't just have like a kind of throwaway React demo like you had before, which I think is like super exciting. And then, yeah, the hard decision is then what do you build? Like, you know, which, you know, which company do you know down? Yeah. Oftentimes, I mean, you come up with like a new idea, feature, like an entire product. And, I have to do it like a double take because it's not like a static thing. It's just I'm like, this thing is fully functional. It's almost chippable. How did you cook this? Yeah, the cool thing I think about... I think this is another fun angle, which probably hasn't been explored that much a little bit in design engineering, which is the old world is you're a designer, you work in, or a product manager for that matter, you work in a document, you work in a file, and it's this throwaway piece, and then you throw it to the engineer, and the engineer productionize it. But now, some of the demos that Thibaut was mentioning, I'll just create a fork of the repo, and it's And it's like, it's not just a demo. It's like a fully functioning thing. And like, obviously to move fast, I've, you know, taken some shortcuts and like, there's going to be a, you know, it's going to be a little rough around the edges. But, but yeah, the fidelity that you can get to is amazing. Yeah, there's one of the pieces you just used as a throwaway line that I want to dig into a little bit. You talked about this idea that you like come up with an idea and that a team forms around the idea to get that idea to fruition. And I feel like that's a little bit the story of Codex, but I think it's also a story of a new way of working. And so I'd be curious for you guys to share a little bit more about what that feels like on the inside. It feels like we are co-evolving Codex and the way of working. And so Codex is evolving as fast as we have to adapt to, you know, the new possibilities that it creates. And it's quite the challenge. But fortunately, one thing that's become very clear is like humans are still like the very best at adapting quickly to things. And isn't it? Quite insane to think, like, earlier this year, none of this really existed. And, like, now, like, it's very rare to find someone who still codes, like, without, like, a little agent by their side. So I think, you know, we're going to continue to see that. It's pretty clear to me, small, nimble teams tend to, like, produce incredible results. And I think that's going to continue to be true. Yeah, no, I'd agree. I think, yeah, I think that the really interesting thing observation that I've seen is just I've been so surprised at how fast people get used to used to these new step changes you know to people's point I also joined just before our reasoning models and I remember at the time we were talking about it's like oh that you know gonna ship this reasoning model it's it's obviously you know the kind of sits on top of all of this research and it's been this you know really huge research project you know for the company but again it was this low-key research preview and And it's just such a step change, you know, in so many areas. And if you think about where we are now, and I just look at how fast the different teams I've worked in over just the past six months, and it does just feel that kind of every few weeks or every model release, you know, we kind of like push this frontier even more. And then a week later, you know, you'll be in some agent loop and you'll get a bug and you'll be like, ah, this model, you know, like getting frustrated. And then you're like, you forget, forget that it's like, you know, this is insane. So it's just, it's one of those, you know, it's just like, you know, you could apply the same to image generation or video, right? You know, we shipped Sora and it's like mind blowing. And then you see this tiny, you know, this tiny fragment and you're kind of like, oh, you know, but you forget. you know, you zoom out and you just become used to these things so fast. But to see this one, I think the cool thing is it's just super empowering for small teams. And, you know, even some of the junior engineers that, that, that we work with who, you know, perhaps are only a few years out of university, they, you know, the kind of the breadth of work that they can do and the kind of big swings that they can take, you know, I think just even within the past few years has really kind of accelerated their work as well. Yeah, we've got Ahmed on the team. He joined as a new grad. Didn't know Rust, learned Rust super quickly. I've never really seen one like pick up like a new language like as fast as that and like, you know, get productive. And then it's the way that he manages to, like accept the technology and the potential and like discover the true potential of agents is like, I think faster than most people on the team. And so there's sort of like that superpower of like, how quickly are you willing to try and adopt new ways of working as well? I've seen also like veterans, like, you know, 10 years in industry, like, you know, kind of stick to their, you know, more traditional ways of like developing and it's tough. I'm not sure which one, you know, is more effective. Yeah. But it's pretty clear to me, like, you know, jump like three months, six months from now. It's like, you know, it's going to be very clear which one is more effective. Yeah. I think, honestly, it'll be a surprise to a lot of folks to hear that there are junior engineers at OpenAI simply because there's been a widespread perception over the last 12 months that these tools are can dramatically accelerate people who know enough of the business context and have the experience to utilize them. And then juniors coming in, like I hear from juniors directly saying, I can't for the life of me get a role anywhere because I don't have experience. And now you also need to have the ability to have that experience and leverage it with AI. And it's even harder and higher. But you, you guys have juniors and they're apparently doing very well. So what's that been like? It's been awesome. I think it brings such a joy to work as well and like fresh perspective and then it keeps like us grounded. And I have been delightfully surprised about like, you know, how well that's been working for us. And it's changed my perception as well of like, you know, what is important, like, you know, this adaptability and then, Like a lot of it was as well, like Ahmed, I'm just going to take Ahmed as an example, but, uh, sorry. Um, um, He was sort of like he grew up almost with this. So it's like he it's not quite true, but, you know, it will be true at some point where it's like life before coding agents, you know, background, ambient intelligence, like, you know, having a little assistant like in your terminal, like that was not a thing. And so it's just super natural to them. Like, whereas Like for me and others, sometimes I'm just like, oh, you know, it's like, I'm going to go back to Vim and like, you know, just like cast it out. And like, I don't necessarily like resort to like using it in the right way. And I'm like, slowing myself down in a way. And then you look at the way that, you know, they are using AI today and you get inspired. And so it's been actually really interesting how they've been able to level up the rest of the team who is like on paper more senior, right? And a combination that I've seen work very well is where we do spend a lot of time on the general architecture of a code base. You know, it's like the principle of software engineering still remain. And then once you have the right scaffolding, then you can just go and like and run and be extremely fast and proficient because the agent will also like respect the general scaffolding and the boundaries that you've set. So reading between the lines a little bit, it sounds like the quality of, of character that is most important that you guys are seeing on the ground as you work with these models? And to your point, evolve teamwork with these models. Is it around openness to experience and learning new things and the ability to adapt quickly? And that's something that really, whether you're junior, whether you're senior, whether you're technical, whether you're not technical, that's what you got to have in the AI age, or is there something else? I mean, it's interesting. I mean, you know, I interviewed a lot of designers. They're definitely qualities that I look for. you know, when hiring. But, you know, it's, I mean, we're just, we're going through, you know, a bit of a step change technology wise. And I think it's just, you know, being open to those new ideas, being open to using those new tools is, you know, is definitely helpful. You know, if I think back to, I'm a child of the internet, you know, I kind of grew up pre-internet and post-internet. I kind of feel like we're at the same, you know, the same point now for like software engineers, creatives, designers, kind of, you know, pre-AI, post-AI. And I'm seeing more and more people who are like, you know, maybe skeptical or like, you know, learning about a little, as you know, as Tiva says, kind of set in their ways, perhaps they have their workflows, you know, dipping their toes in and just seeing the crazy benefits and from there, like moving forward. I think curiosity and willingness to engage is the one most important thing right now. And it's clear that we're only at the very beginning of what's going to continue to evolve. Model capabilities are going to continue to increase. We are not seeing really a sign of a slowdown, like 5.2 that just came out. you know, it's a very strong model, but it's also, you know, one of, you know, many more to come. And like, we have like a very clear research roadmap there that a lot of the team and the rest of OpenAI is excited about, but it's just to set the reality is like, this will continue to revolutionize how we do software engineering. So if you're not If you're not willing to accept that, it's going to be tough. And people who are curious and are focused on solving problems that are out there in the world and are like, hey, how can I help people's lives? How can I do this thing faster? They're the ones that are having a great time right now. That's really been true. The stories that I know that are positive, hopeful, exciting, tend to be correlated really closely to people who have like a nose for interesting problems and who have a curiosity to solve them and just look at AI as this really cool super tool that they can use to solve those problems. Like I know someone who, I think he started out as a music major in college and now he's a technical founder because he felt like being one, right? And so now you can do that. And he just went and solved problems for customers. And I think that that's one of the things that I find most interesting about the trajectory that we're on is that those stories become more and more plausible, right? Yeah, I think it's maybe one of the underrated parts of it in that I think there are a lot of, you know, really valid concerns that people have. But I think the thing that people, you know, don't focus on as much is that it is an equalizer. Like, you know, if I think of, you know, when I got into design as a kind of teenager, you know, I was I was doing a lot of animation. I was going to hand drawing things. I was like doing a lot of creative stuff, making movies with my friends and my, you know, in the garage, you had to build a green screen. You had to buy the camera, which was expensive. You had to get this. And now with like kind of $20 charge of a decent subscription, you can, as a creative, make like basically anything, right? You get access to codecs, you get access to all these other things. So in many ways, it's an equalizer, but it does require a, leaping in as you say kind of having that curiosity and really like throwing yourself in and learning all about it but you know if you're curious then yeah you still have complaints that usage limits and rate limits are too low but when you think about it like $20 a month for like a prolific software engineer that can help you get stuff done it's crazy yeah it's like this equalizer thing it's there is like so many problems that were not that were left unsolved before this and now that will get solved and that's that's what gets me excited yeah i guess that brings me to another question i had like you referenced earlier this idea that it's about choosing what you're going to focus on in this world because the tools are so powerful. And I think that's definitely been something I've observed. And then you just mentioned another big piece I've seen, which is that there's a whole host of problems that, for lack of a better term, are SEV3 and SEV4 type problems that are now accessible and legible and solvable because we have a tool that can do them. And so on the one hand, you have like more volume you can attack that's perhaps lower urgency. And on the other hand, you have a lot more value on picking your overall direction correctly. And I'd be curious to hear like in practice for you guys, what is that balance like? How do you guys tackle sort of those two points on the on the scale? I think there are two things that matter to us is general conviction that we have based on information, you know, around like, hey, our models are going to continue to improve along, you know, this set of capabilities. Like, let's build ahead of that so that we continue to scale and like, you know, bring more benefit to our users. And then the second part is like, what are people asking for? And they're deploying intelligence like Hender helps us as well. Like I was on Twitter the other day, like just I started to tread like, oh, like, hey, you know, it's like, what should we build? Like, you know, what's holding you back? Like what's not delightful on Codex right now? And then got, you know, somewhere around like 250. Yeah. Oh, that's right. Yeah. It was a good thread. It's like 600 like unique ideas, but Codex helped me sift through it all and, you know, bring it back then. And, and based on my own priorities and my own notes, I, actually section it and then I was able to discuss it with the team but so yeah conviction and feedback are like two good ways that we go about it you have others yeah no I think that's I think that's that's a good framework um I think just to mention a few other areas where we've been building. So we have this kind of CLI product, we have this web product, we have the ID extension. We also have some cool integrations. So you can add codecs in Slack and you can add codecs in Linear. And with a lot of these smaller issues that you spoke about, one really cool trend that I've been seeing is there are a lot of small tickets that... you know, the end of the year or the end of the course, you kind of, the team might struggle to get around to, or they're like always there and they're kind of coming up at the end of the meetings. And now, right. So like, you know, after you've triaged a bunch of these things, you know, maybe there are a bunch of small ones that you could just put into one of these, one of these integrations and you can just be like, you know, codex fix this, or you can literally assign it now in, in, in linear and other products. So I think like some of the small stuff, we are starting to get to these like really kind of end to end workflows of, you know, tracking a small problem, meaning like literally writing it down in some short descriptive way. And then having a PR that you can review and choose to merge or not. And I think like being able to free up a lot of time, you know, from focusing on a lot of that low level work, like just frees up short. pure resources and capacity to focus on some of those big issues. So that's been a cool trend as well, which, you know, obviously you always have to prioritize things. You always have to, you know, filter signals through noise and make some kind of hard decisions. But I do think that we've been able to get a lot of that low-level work kind of, you know, almost kind of enter and automated so that the team can like really focus on those big issues. It also moves bottlenecks around, right? So like, as we're solving, almost solving code generation, and you can implement any feature, you know, like, faster and faster, like, suddenly you're left with deploying and maintaining the services and, you know, whenever, like, your hardware breaks or, like, networking has an issue or, like, whatever, like, million things that can happen. Now suddenly you get paged a little bit more and you're building ahead of the automation that we're able to deploy and the intelligence is not yet capable of doing all these things. We're not able to yet have Codex deploy the service and be on call. And this is an area where currently we're feeling that load from having almost solved code generation. Yeah. Yeah, I was going to go there. So I'm glad you did. Because to me, it's like you've 100 extra code generation or whatever you want to use the multiple for. But now you've just shifted all of that down the pipe. Yes. Yeah, I mean, it opens up some cool, interesting interface possibilities. Like if you think about ChatGPT, right, you're conversing back and forth with a model and you're asking for some piece of information and it kind of presents something back to you. With a coding agent, it's taking some action in the world and it's coming back, you know, most often in a code base. And the kind of artifact and result of that is some code that you have to review if you want to do something useful with it. So, yeah, yeah. that at the moment, I think we're in this kind of like transition period where the meme is that kind of like, you know, a lot of like software engineering is reviewing agent code. So I think like as a, you know, as an interface and as a problem to solve, I think that's a really interesting one to, to think through. It's one that we're thinking through and it's one that I think, you know, many people in the industry are, which is like, how do you, how do you not kind of shift the burden as you say from like, um, you know, kind of like writing code to basically reviewing code and how can you make that as smooth as possible. And I think we're doing some cool stuff in that space with the code review, you know, agents and other things. But I think that's like one emerging, you know, emerging problem that we'll have to solve soon. One of the things that's special about code generation is that you can make it safe. So you're going to have all the code generated in a sandbox. Yeah. And you have no side effects. And so therefore, you know, I think also like just because all the context is there it's textual like it's like for code like you have you know you have git you have reboot like a lot of the automation already exists a lot of the tooling already exists so it was solved first i think primarily due to a combination of reasons but that's a big one and you can make it safe like a lot of the work that we do is like we view coding agents under the lens of like you know safety and alignment and the alignment is not a solved problem which means that whenever you go into the world of deployment and being on call and actually having real world consequences of an agent taking actions into the world, that is like a whole other game where you cannot make it yet. You cannot guarantee that the agent will not go and like, delete your service or just like, you know, snoop at like, you know, user logs and there's a whole security aspect and figuring out, you know, how to restrict the set of actions through like a safe space or you have to solve, you know, the alignment problem, you know, whichever will come first. But we're sort of like inching towards that and finding more and more creative ways so that our agents can act upon the world safely and that, you know, you're able to steer and supervise that. I think that's like the next frontier is, of what we're going to unlock in 2026. It's like, could Generation consider mostly solved? Could we do what we've been investing a lot in? And then where are the bottlenecks now? Yeah. Yeah, that's kind of where my head goes as I look at the next year as well. I think one of the things that people tend to get curious about, and I think that will come up more and more as a conversation in 2026, is how do engineers stay engaged fluent and able to read code structures in ways that are meaningful in a world where code generation is, to your point, mostly a solved problem? How do we keep the fingertippy skills that are relevant so that you can understand what you're deploying? So this part that we didn't discuss on the code understanding and planning as well like how quickly can you figure out like how your system is actually functions today and then you know maybe use that knowledge in order to plan like your changes and then after you have your change like how do you have them like you know actually deployed and have an effect upon the world like you know be it a product or something else yeah that whole like it's not just that but like I am more productive. You're more productive. Everyone on the team is more productive. And it's also keeping up with all of that. It's like, you know, what the hell is everyone doing? It's just like, you know, there are new features minted every day. It's like the world is changing so quickly around just like in teams, even small teams. Keeping up with it all is a challenge. And with you saying that, I just want to be clear. Everyone's going to be like very discouraged to hear you say that because we're all trying to keep up with it all. We're building towards that, right? I know. You want to have fast ways to understand what's going on in the code base, synthesize things. Is text the right way to do that? Do you want a little report every day? How fast should your agent be in order to help you understand the state of the code? And to your point about staying on top of... you know, staying on top, I guess, kind of programming as well. So not kind of like delegating everything and, and still deeply understanding things like, you know, I've seen some cool examples, some people internally, like occasionally kind of turn off their internet. And they like, I forget the term that they use, but they're like, basically kind of like, you know, old school coding. And they're like, there's no tab complete, there's no agent, you know, there's no codex next to them. And, you know, human curiosity doesn't go away. Like people still need to learn. Like, you know, the engineers on the team still read engineering books. I still read, you know, engineering books. So I don't think that like curiosity is going away. And I don't think like it will become this kind of like, you know, thing that you hand it off to and you lose all the knowledge yourself. And as you say, you know, like models can help you stay up to date as well. Like if, you know, if I'm trying to get to know a code base, I can talk to the model about it. I can, you know, ask like, you know, How does the backend integrate here? Like, oh, like where does this component come from? Can you just explain the dependencies? Like the model itself is also like a, you know, an amazing teacher. So I think that's, that's a cool angle as well. When was the last time you were really surprised by an emergent property in a model? This morning. So, so yeah, I just saw someone build scaffolding around a model to enable it to work properly. on a problem that I thought was out of reach of the current capabilities of models and solve it successfully. And I was really surprised. I thought we would need to train the model specifically to be able to do this. But turns out it generalized fairly well and worked for almost 13 hours on this one. Yeah, just by being more creative on the tools and the setup around it, I hadn't seen this done before. So that was like really surprising to me. Yeah, I mean, like most days, you know, there are some things that I probably can't say, but I think there's one that actually stuck out to me, which we, you know, as we released it. But if you go in the web product and, you know, you ask the model a question and it can kind of send you some front and back. It like takes a photo of it and it like sends it back with it. And like when I first saw that, I thought that was magical, right? You know, it's kind of using a bunch of tools, but... there is something like very interesting about thinking about coding agents, you know, being able to code, but being able to see, being able to generate these assets and like at a conceptual level, I just found that really interesting as like a, as a creative that, you know, this, this model can like do so much more than I thought. Yeah. I think that one of the things that's been my, one of my biggest takeaways as I reflect on 2025 is that I probably, um, As much as I was excited about tool use for models, and I was, I don't think I realized the combinatorial power that gets unlocked when you start to give a model a good set of tools. And there is something there about what is a good set of tools and what approach that we've taken with... Codex is just give it access to your computer through good old Unix tools. It's like, give it a shell and let's see how far it can get by giving it a shell. And then in order to do this safely, have it run in a sandbox. And then what emerges from there is... To us, like surprising, because we don't necessarily care about, you know, how the model is going to be able to achieve its task. And so we don't necessarily have a specific bias there. Like other than like, you know, you should probably use the shell a bunch of times. But other than that, it's like it's a very general tool. And that's something that we've done consciously because we believe it's one of the more scalable ways of doing things as it scales with like the model capabilities. And it's super general. Yeah. Go ahead. Yeah. Surprising things as well on the creative side as well is like, you know, I mentioned that there's someone that, you know, use it to write documents and things like that. And it turns out that you don't need to give it a document writing tool. You can just use RegEx and, you know, like through bash commands, edit documents, you know, kind of do anything. I think that was... Yeah, like perhaps not surprising, but pretty amazing capability. The other day I was just like playing with something and then we have like a Codex SDK and then I just told Codex about it and then it was able to just write code and like use the SDK, write a bunch of TypeScript and then invoke, basically invoke itself in order to achieve more. Like we don't have native multi-agent in Codex, but this is a form of it. that is just completely emerging because it's just read the documentation. It was like, oh, you know, I can probably get this tool to do something for me. And it was like, wrote that code, invoked it, and it just worked. Codex is very good at like figuring out ways to solve its problems. So Codex essentially read the SDK docs, instantiated another Codex instance, and used that as a tool to get a job done. That's right. A bunch of them, actually. Yeah. Yeah, effectively it bootstrapped multi-agent. Yes. Like without us like, you know, thinking about it. Yeah. And so there's this thing of like throwaway code is interesting to think about it. It is like code as a tool. It's obviously extremely powerful, but maybe, you know, there's just like, this whole category of things where the agent is just, you know, writing code as it's not a piece of code that you should ever review as a human or like, you know, that you necessarily care about. It's just a very general tool. Yeah. It's, it's code as a means, not code as an output. Yes. So sort of riffing off the tool piece, I've also seen sort of models with fewer but more powerful tools that are more general in nature doing better overall. So that doesn't surprise me. I'm going to the other side now, looking at the memory side of things and how long-running agentic tasks handle memory problems, both maybe sort of stateful memory you have outside the system and also in-context memory management approaches. How do you guys think about that for the 20-hour task or whatever that you're running? How does memory work? So memory is still an open research topic. It's clear something there exists. will emerge that is better than you know whatever short-term approaches you know we're thinking like right now as a form of memories that you know you can have the model like the model can write to a file and then you know keep track of like a lot of its state like you know through like just markdown files for example another thing that you know we're doing is like for very long running sessions, like the model that goes beyond its context window. And so the model is forced to like summarize like what it's achieved so far and then reboot itself through like a process that we call a compaction where at the end it's just like, okay, like let's just erase like all of the content of the context window and then summarize it And then, you know, you reboot and then you restart and then you can do this many, many times. And essentially then you're able to have the model, you know, the agent work forever. You know, if the task like required to work forever, it would work forever. In addition to that, because it has access to just like grab and is able to like search through things, it can also dump additional context that it doesn't really need to have always in its context window, not just two files. And that's like a form of memory. With skills as well, you know, you might have skills in programming. a file somewhere and it's like a form of memory that is shared between the user and the agent. And you're co-evolving some common knowledge there where it allows you to have an agent that, you know, performs hopefully better over time. There is a problem with staleness there where it's just like, it's sort of like a poor version and a hockey version of memory. And it does feel like this will get disrupted at some point, but that's mostly how we've seen like, you know, it tackled and, you know, it's a very simple way of achieving it. Yeah, that's one of the themes that I think is emerging as we chat a little bit more is that you are seeing surprisingly simple primitives be surprisingly successful at solving larger generalized problems. Yeah, I think that's the thing that... A lot of people in the field have learned a long time ago. And I think it's sort of like being internalized. And it's not necessarily like common general knowledge of like, hey, keeping things simple with models that are evolving in capabilities month after month after month is probably the right thing to do. Because otherwise, you end up with a pile of complexity that you have to continue to adapt to the ever evolving capabilities. So that's why we decide to keep things very simple as well. That makes a ton of sense. Yeah. The other big question I want to get to, this gets back to the whole idea of like technical and non-technical folks using codecs. I get asked a lot, how do I think about my career? How do I think about career progression in a world where job titles are increasingly sort of optional hats that you can take off and put on? And it's about the problems you solve. What is the career conversation inside OpenAI? And how does co-evolving with the model shape that? Yeah, how do you feel about this? Yeah, it's a good question. I mean, I think like, you know, I think one kind of emerging trend that I'm seeing among designers and to an extent some engineers as well, which I personally think is the positive, um, you know, positive direction, which is kind of what I spoke to earlier with this kind of idea of kind of equalization is there's less of a focus on kind of credentials and going through certain routes, right, to get to kind of, you know, ascend certain kind of peaks of credentials and more a kind of focus on kind of what you've done and what you can show and kind of like, you know, code wins. So particularly in the design community, you know, what I'm seeing is a lot of people are kind of building really exciting things, putting them out there, And from a career perspective, you know, building up, profiles and, you know, kind of like work through what they've done and what they show and no one cares where they went to school, you know, and all of those other things perhaps of the past, which sometimes good, you know, sometimes, you know, bad from like a, from kind of a credential point of view. So I do think there is definitely a kind of like learning through doing and kind of, you know, kind of proving through, you know, what you've done, which I think is, is an exciting trend. And I, you know, I think also, you know, a lot of like creator economy and, you know, the rise of, you know, podcasts and personal media is, it's kind of similar, right? It's just like anyone can kind of do, you know, you can just do things as the internal phrase. Um, but you can just kind of, you know, do things and show you and show your, you know, show your skills through that direction. So I think like that's personally one trend that I've seen, um, you know, to broader, broader trends, you know, I didn't know if I have as much of a perspective there, but yeah. Yeah. Yeah, I think you can just do things is very much a mantra. The second mantra we have is like, I am also curious about this. This is sort of like the two things that people, you know, exhibit at OpenAI. I would say it's less a challenge on career progression at OpenAI. It's, you know, we look at impact and that's sort of like, you know, how you progress. It's been a challenge on, you know, interviewing and finding the right people, but because the traits that you're looking for and how you can succeed has sort of broadened before it was like, do you program well? It's like, oh, let's give you a series of programming tasks and really hard ones, and we're going to pick the best talent there. But now it's not that easy anymore. It's like you can actually be very successful if you're like, not going to traditionally be like a top performer at like, you know, hard programming like tasks. And so like being able to find a talent and be more creative here has been a challenge for us. And like, we're sort of like evolving our thinking there, but it's been very interesting. Do you guys have a silver bullet for the persistent issue we see with interviewing where people will have chat GPT up on the side and we'll just be kind of reading responses back in the interview? Yeah. Yeah, I mean, we bring people on site for a lot of the interviews. And then it's also just a reality of like, hey, in the job, you know, you're going to use AI all the time. So it's more of a, the interview itself needs to evolve and maybe not, you know, limiting, like, you know, the tools that people can use. Yeah, I think it's like one way of thinking is like, how are you using AI to get around some constraint? And then another is thinking of it in an empowering way. And, you know, you need to hit certain baselines. You need to, you know, you need to have certain skills in place, but also kind of are you open to using tools and how can you understand how those can give you leverage? Yeah, it reminds me a little bit of one of Jeff B's favorite interview questions where he asks people, Um, how do you solve, uh, a problem that has sort of two obvious solutions? Like I want to, I want to, uh, have a higher quality car that goes faster, right? How do you do that? Uh, and you have to pick which one to optimize for. And the trick is you're supposed to invent your way to both. Um, you're supposed to think outside the box. You're supposed to think around the constraint and you're supposed to push on both. And that part of it is just measuring the willingness to break the mental box. Yeah. And, Is the point there that, you know, if you were using AI on the side, like, you know, you wouldn't get, you wouldn't come up with like a creative concept? I don't know that it's necessarily that. I think sometimes I've seen that. I think, The best way I've seen to push people off script, let's assume a remote, right? Because I think onsites are critical, but we'll take that as read. If it's a remote interview, I think the most effective tool I've seen is really to push off the standard behavioral interview script pretty fast and push people into... a really honest conversation that demands some higher level trade-off thinking. And they don't really have time to feed it into a model and get a response in real time. And you see pretty quickly what their thinking tool set is in their head. And that gives you a sense of like what they're going to bring as a partner with AI when they start to work. We have this problem now, right? Like, not sure if you're reading the questions off the screen on the right. Actually, I'm not. I have no questions up. I'm staring at myself and you guys, and I'm just kind of... So are we, so are we. Delightfully simple. Yeah. I think it's more fun that way. Like, we get to kind of take the conversation where I want to go. Now, I did prep with ChatGPT. I absolutely prepped with questions, but then I was like, eh, you know, they're okay, and I'm just going to riff it. So, yeah. Yeah. Interesting. You know, another question I have, I know we only have, you know, a few minutes left here. I think one of the things that we haven't dug into yet that I hear a lot is, and maybe this is like half a design question, half an engineering question. So for the two of you together, like it's going to be perfect. Yeah. I hear a lot of talk, especially when, um, I put out videos talking about new models. I'm going to do that for Chad GPT 5.2 here. People will say, what's the difference? I see the same chat bot. I see the same terminal. I see a different label. Uh, How do I know that this is actually better? And like we've even had like comments from I think Sam and others that say chat is essentially a saturated use case. And I kind of agree. Like I think it's mostly saturated out. How do you convey the significant, not significant is the wrong word, the step change that you get in capabilities over a six month or year period to someone who is seeing the same you are? It's a good question. I mean, I think like it depends on the use case, right? Like, you know, I think like what, you know, like as a designer or design engineer, I kind of work with, you know, different models and for some tasks I like one, you know, for others I like the other, just like, you know, many other products. Or if I'm in ChaiGPT, if I'm asking like a super quick question, right, I'll just like leave it on auto or kind of, you know, some low reasoning model. And if I'm really wanted to think maybe I'll use pro or something like that. So I think it's one of these things where you kind of like, you know, you test it and it depends on the situation. You know, that being said, like we also, we have a bunch of research evals, you know, so I think there are certain parameters that you can use, but we've kind of talked through this interview about, um, you know, the different capabilities that different model steps unlock. And I think we have consistently seen that, right? Like models today, at least for coding are like substantively different from where they are when I joined this team. Um, so it, I think it's a case of just try them, try and try many different ones. Like, you know, see what you like. Some things are good for different use cases. Um, But yeah, I think like maybe one good mental model, perhaps that people don't think about is, you know, when thinking about these things, they think with a snapshot of where we are currently with how you interact with Chachaputia models. And I think in five years time, it's going to be very different, right? Like if you think about what models these new capabilities can unlock, different products will have very different experiences. You know, you might, you know, is chat always the best interface? Like, you know, you might not be interacting with a model at all, but it's still doing work for you in the background. And in that case, right, model quality and the model that you're using is very different. So, yeah. Cool. come back to that. CodeReview is, again, an example of that where it just happens in the background. The model improves and we know either it got faster or it's able to spot more things. It's like, yay, you just got an upgrade for free. You don't have to think about it. And you just benefit from it every day. And then Codex itself is a different product from Chat. Agents benefit still like from a lot of improvements on like we definitely see like whenever we improve on reliability like frontier intelligence how long it can it can go but then it feels like we will need another product at some point as well where you're not going to run Codex for like three days in your terminal. Yeah. Maybe people will, maybe people will. Right. But it's like, at what point do we have agents that just run forever? Yeah. In that, you know, you interact with it. It's like, that's going to feel like very different. Maybe you text it from time to time. Maybe you were going to call it. And it's just like, we yet have to invent like the right product around this. Like the models are not there yet, but they will be. Yeah. And then that's going to be like, oh, wow, you know, it's just like we're like GPT-7, right? And it's like, it'll be like obvious. And in the meantime, it sort of feels like, oh, okay, it's like it feels incremental at times. But then when you look back like six months ago, you're like, heck, like, you know, none of this was possible. Exactly. Like I did a video this morning about this idea that straight line extrapolation is surprisingly hard to experience in real time. Like you're sitting there and like, like you said, like people get used to the products so fast and people get disappointed and frustrated by the products. I vividly remember how excited I was working with Chad GPT-5 thinking and how it felt like a step change. And then I immediately within two days found a bunch of things that I didn't like about it, wanted to fix. And like, that's just how it goes because that's how humans sort of scale our tastes, I guess. And I think one of the things that I've been thinking about is how do we take our human default where we seem to assume a static world and start to transition to a human default where we assume a dynamic world where we're living on the slopey part of an S curve. And like, we have to think about rapid gains in capability as a default base case. Yeah. All right. For our last couple of minutes, do you have a question for me or the audience? Like, I know you guys are always hungry for voice of customers. There's something that's been bugging you that you would want to ask. What are you doing? I mean, I'm always curious, like how people use coding agents outside of coding. Like, you know, you mentioned that maybe you use it, you know, you use chat to get ready for the interview, but like, how do you use it in your, in your day to day? I love that. Yeah. So I am a relentless omnivore when it comes to AI models, and I tend to jump around really quickly. But I have settled task groups that once I decide where I want them to live, I tend to put them there. And so right now I am using chat GPT, Well, it was 5.1. Now it's going to be 5.2 for a lot of the structuring and brainstorming and researching and thinking that I do as I start to think about pieces that I write and what the stories are kind of and how it kind of comes together. Yeah. I'll use Codex when I want, I call it like hard thinking mode. I think that it's been marketed, like I think chat GBT 5.2 pro or 5.1 pro, like people talk about it and I've tried it out and I like it, but I think it is sometimes overexpressive. for what I need. And that's why I mentioned conciseness as a value I appreciate in Codex is that Codex comes back and it doesn't give me, you know, a thousand tokens. It just comes back with a really concise answer. And I, I love the legibility of that and I kind of get addicted to it. And so when I need something that is a very clear, concise analysis, I, and it can be a financial analysis. It can be a project analysis. It can be an M&A analysis. It can be a doc analysis. It can be a response to something that is really complicated that I need to think through and I want to draft it out. Codex is great for all of that because it just, it boils really cleanly, right? You get exactly what it boils down to and it's really dependable that way. I get a lot of mileage right now out of The document tool creation or the tools used to create documents from cloud. I know they're the other guys, but they are definitely shipping well there. And just Opus 4.5 really, really, really does well on that. When I want a PowerPoint, when I want an Excel, it does well. I've been, both amazed and also frustrated by using Notebook LM and Nano Banana 2 to, or really it's, is it three or is it not two? It's Gemini 3. Anyway, using it to ship PowerPoints because I don't get editability and I hate that, but I get all of these lovely graphics from Nano Banana and that's fantastic. And so I think we're in this place where people are, we're tool omnivores because we're desperate to get the best thing in the moment for the particular task. And we all tend to have like that list of paper cuts. Like I was like, I don't like the PowerPoint piece. I think Claude Opus 4.5 has good tool use. But at the same time, the ability to create decorated PowerPoints is not really there. I think you guys have a ways to go on PowerPoint creation right now. But the completeness that I'm seeing, like I'm doing some early work on Shad GPT 5.2 and like it spits out a very complete document. Like it is a complete answer that thoroughly answers the question. And so. One of the things I preach a lot is like you must get really fingertippy with your models to actually be able to use them to solve problems in a way that's differentiated from just type something into a chat bot. So it's a long way of saying I have about half a dozen models and I use them all every single day, including like a bunch of open eyes. Yeah. Yeah. And then you have this like mental model of like, you know, what is this model good for? What is this model good for? That's right. And there isn't yet this like, you know, perfect model that like answers all your needs and your needs changing. Yeah. Because they keep changing. And that's the thing that you've emphasized that I really strongly agree with is that if I were to try and boil this into a table, it would look incorrect because I have a, um, an evolving sense map of where these models are good and not good. And it's very, it's very fine grained. Like I have learned which models read handwritten tally marks well and which ones don't. Because when you refresh that thinking, like, you know, that knowledge, like when you, when you allow yourself to say like, Hey, Let me try this other one. All the time. And that's, I think, one of the things that people lean into with my channel is that I am extremely open to new models and new experiences changing my priors. Because I think that you have to be at all helpful to people in evolving this landscape. Because you have to assume that any given new model release from any major model maker could upend a key part of your workflow because it's just better. And you should not sit there and say, well, Chad GPT before didn't do this, so I'm not going to pay attention to this tool use capability. It's like, no, you should. You should assume that the model is fully capable of surprising you and test it carefully. So I think one of the things I've been thinking about is what, what we mean when we talk about useful work and what useful work looks like. And we've talked a ton about codex and obviously with codex useful work is poll reviews, PR reviews. It's, it's coding. It's, it's work that you can define in terms of the, you know, bits and bytes that the model outputs. It gets a little bit more complicated with other knowledge work. And so I'd be curious how you guys think about that, maybe beyond Codex, maybe looking at GPT 5.2. I would say it's like, it's, Similar question and difficulty, like even just for coding, there are certain benchmarks like SweetBench. They're like super saturated by now. Like, do they really measure how much use you're getting out of the model, like in day-to-day use? And also like, you know, we talked about like how we're going beyond just like code generation and then it's like helping you understand things, helping you like review, like deploy, like doing sysadmin tasks and like in more and more things. So, you know, helping you build like design prototypes. So it's all about like this expertise economical value that you're able to create and you know OpenAS like really worked hard to like on GDP value like 5.2 so down GDP value is I think it's like interesting to go in from really hyper-specific saturated evals to a better understanding of how is this impacting the real world. Obviously, no eval is perfect, but I think whenever a model puts a new soda on something that measures economical value, it's worth taking a look at it. Yeah, I appreciate that you called that out because I think it gets at this idea that People get suspicious of benchmarks when they get reported on and you get close to 100%. It's like, okay, but what's another 2%? Whereas I think there's something around maybe an implicit measure of generalizability that you get when you get to some of these measures of economic impact. So GDP value, I think, is a good one. Isn't there one around vending machines? That's another one that's sort of in that vein as well. Yeah, it's a fun one. Yeah, it's a fun one. Is it vending bench or vending? Yeah. But with GTP-VAL, it's clearly not saturated yet. And then that's usually the cycle that you see with evals is eval gets published, it gets traction, you know, gets saturated. Like it did measure something useful at some point. And then maybe after a couple of months or years, like it's not really measuring anything very meaningful anymore because, you know, every model is performing more or less like the same on it. And then you have a new one like GTP-VAL is like measuring something more interesting again. Yeah. And given it's not Saturday, it's always interesting to pay attention to it. Fending bench is also a fun one. Yeah, it sort of underlines the story that we've been sort of telling through this whole hour together where we've talked about this idea that progress just keeps happening relentlessly with these models and that there isn't a wall. And, you know, contrary to popular reports, right, there isn't a wall. We've continued to see progress. And it's something that allows us to continue to publish new benchmarks because we keep knocking down the old ones. Yeah, an interesting thing there is sort of like, what are the benchmarks of the future? That would be pointless to have now because every model would just score like zero. Like, Being able to be the CEO of a multi-billion dollar company, for example, that would be a useful benchmark. Do we allow models yet to run multi-billion dollar corporations? Not quite, but I'm pretty sure at some point we're going to have these guys of crazy benchmark. They seem crazy now, but they're not going to be crazy in a couple of years. That's a really interesting sort of brain teaser is what are the evals of 2026 and 2027 that we're going to turn to as measures of value? Thanks for having us, Nate. Yeah, thank you. That was a good one to end on. This has been lots of fun, guys. Thanks so much. Next time.
