---
title: "AI Interviews are Crap: Here's How to Use AI to get Hired (and Hire) in 2025"
video_id: "qVufzX_8bqE"
youtube_url: "https://www.youtube.com/watch?v=qVufzX_8bqE"
substack_url: null
publish_date: "2025-09-22"
duration: "18:11"
duration_seconds: 1091
view_count: 4141
author: "AI News & Strategy Daily | Nate B Jones"

yt_tags:
  - "AI strategy"
  - "AI jobs"
  - "LLMs"
  - "prompt engineering"
  - "future of work"
  - "AI career advice"
  - "hiring in AI"
  - "artifact strategy"
  - "STAR-C method"
  - "AI fluency levels"
  - "technical interviews"
  - "Final Round AI"
  - "Google Interview Warm Up"
  - "Claude"
  - "Llama by Meta"
  - "AI interview best practices"
  - "AI strategy for teams"
  - "interview guide"



# AI-enriched metadata
content_type: "Tutorial"
primary_topic: "Career"
difficulty: "Intermediate"
audience:
  - "Engineers"
  - "Executives"
  - "Product Managers"
entities:
  companies:
    - "Google"
    - "Meta"
    - "X"
    - "Intel"
  people:
    []
  products:
    - "Claude"
    - "Make"
    - "Artifacts"
    - "Projects"
  models:
    - "Llama"
concepts:
  []
summary:
  - "# AI Interviews are Crap: Here's How to Use AI to get Hired (and Hire) in 2025

If you are hiring or if you are interviewing, this is your interview guide"
keywords:
  - "ai-strategy"
  - "ai-tools"
  - "artifacts"
  - "career"
  - "claude"
  - "coding"
  - "google"
  - "intel"
  - "make"
  - "meta"
  - "product-management"
  - "projects"
  - "prompting"
  - "tutorials"
  - "workflows"
  - "x"
---

# AI Interviews are Crap: Here's How to Use AI to get Hired (and Hire) in 2025

If you are hiring or if you are interviewing, this is your interview guide. I'm making it for both because both sides are responsible for using AI better. And I want to talk about it because everybody's using AI and most of us are using it badly. That includes hiring folks and candidates. 83% of companies admit to screening with AI. I bet the others do anyway. 65% of candidates admit to applying with AI. I bet the others do anyway. Everyone sounds the same. Let's say you get past the application process. Now you have candidates using tools to interview. And you know what? Interviewers catch them. And candidates have a terrible experience because they're not even talking to humans anymore. I know a senior engineer who has over a decade of experience who recently got rejected because the AI interviewer talking to him talked over him wouldn't let him finish his sentence asked him confusing questions and it's not even clear it recorded it correctly and this is passing for efficiency. I'm seeing case studies here where companies are celebrating the efficiencies they get with AI hiring when people are all over Reddit and all over X talking about how terrible the experience is for candidates. This is not how you get your next champion if you are hiring. It doesn't work that way. We need an interview process that prioritizes human signal amidst the AI noise. And I want to give you specific strategies both if you're an applicant, which we'll do first, and also if you are hiring, which we'll do second. And I want to go into both because I think both sides have a responsibility to get better here. So number one, if you're an applicant, these are my top tips for how you interview better. Number one, fix your tool strategy. There are a lot of very expensive tools out there. Final Round AI runs over a hundred bucks a month. I think it's 148 or something. ridiculously expensive, but they're preying on the fact that you need a job. You don't have to use the most expensive tool. In fact, there are reports from the employer side of detecting final round AI interview responses because they sound so generic. Whereas, candidates are saying that a much cheaper alternative like Bay YZ AI is working better because the answers are fast and feel fluent and natural. The point is not to pick a cheating AI that helps you cheat undetectably. The point is to find something that you can partner with that helps you to structure your thinking. I actually think the most useful tool may be free. Google interview warm-up lets you practice and get better with AI answers. It helps you understand what you did right and what you did wrong. It helps you to go back and forth and spar in a way that's low stakes. You don't have to pay a lot to get help. Before we go further, I want to underline something like three or four times. The right tool will not get you the job. And the right tool will not get you the career. And the tool people are selling you lies if they say so. That is not what gets you a sustainable career. Figuring out how to showcase who you are, your passion, your genuine skills, your insights, that's what helps you win. And AI is only there to help you do that well. And the prompts that I'm writing for candidates in this piece are prompts that I am designing so that you can prepare better than anyone else prior to the interview with the help of AI. Let's get into your artifact strategy next. Almost no one has an artifact strategy. So tip number one, get an artifact strategy. What's an artifact? An artifact is a proof of work. It's it's a packet. It helps you to show your thinking around real problems. And by the way, that is going to help you prepare for interviews. As an example, you would want to look at a project you've done and not just do what so many people do, which is throw up a nice little website, put up a bar chart, say you made it go up and to the right. Instead, you want to build a proofof work packet that shows how you actually think, the constraints that you faced, the decisions you made, the trade-offs that you considered. Traditionally in product management, we've been doing this for a while because we were always told you have to show your thinking as a PM. I would now say looking at how people are actually interviewing, that is more and more the case for every role in tech. If you're in design, you're going to need to do this. If you're in engineering, you'll need to do this in your own way on the technical side. Even in roles like customer service and sales, you are increasingly going to be asked to show solid evidence of human judgment. Especially as you get into more senior roles, you want to be in a place where you can show that thinking clearly. And it doesn't necessarily mean that you just email this packet off and hope that that works well. I'm not saying that. It's in the interview. You have the option to pull it up if it's interesting and moves the conversation forward. It acts as an after interview additional packet of information if the interviewer is interested. And it helps you most of all to get prepared without sounding like a parrot. And so many of the issues with these AIs that assist you in interviews is that they make you sound like a parrot and you are so desperate to answer the question right, you don't realize you sound like everybody else. You should also include ugly artifacts, not just the pretty ones. I actually look when I get resumes, when I look at the websites people send me, I want to see is everything super polished or are you courageous enough to show things you've worked on, scratch notes, iteration history, failed experiments. The most compelling story I have ever seen on a personal website for a job was this lengthy single page post. And it showed a 5-year history in a role. And it went through meticulously what the person had done to add value at each stage in that role. And it had pictures and visuals and designed elements. And it read really fluently. And you could see how the person had negotiated setbacks and obstacles along the way to get the company to where it was. It was incredibly compelling. It showed iteration. It unquestionably proved authenticity. The last thing I want to call out is that the artifact strategy extends into how you interview. I I call it the star C method. If you've ever done STAR, you know it's situation task and then you go from there into the assignment and your response. And I'm adding constraints. And so star C is all about showing that you can work within constraints because AI answers classically are not very constraintheavy. And so what I recommend that you do is that you take your star situation and you want to make sure that you layer in the constraints that enabled you to make hard tradeoffs along the way because good constraints, if properly told in the STAR format so people can follow along, help you show good judgment. Good constraints help you show good judgment. And I think that that's increasingly important because if you're just giving a standard response and the interviewer has heard star before and all the AIs have heard star and you tell star, it feels very stale. You need something that helps you to add that human element. And if you remember star C, it can help. So situation, task, action, results, and make sure you layer in those constraints. That's the C. I want to go beyond just the toolkit and the artifacts and interview strategy for a minute with candidates. If you are using AI, please be transparent in 2025. It actually increases your authenticity. Let me give you an example of some talk tracks that would impress me. I use Claude for research. I went back to primary sources. I looked through what actually worked and what didn't work. The analysis that I'm putting in front of you is mine and I made sure that I can own it and stand behind it. Fantastic. Show the AI stack that you're using in the verification process you use. This is going to be true in technical roles and non-technical roles, too. Make sure you mention places where you disagreed with AI. May make sure you mention where you caught AI in hallucination. Make sure you mentioned what tools you wanted AI to use versus not. That conversation is important. And that actually is a nice segue brings me to the second part of this video where we're going to talk to hiring managers. Hiring managers, you need to evaluate better. And it starts with not penalizing people for exactly what I described. If your candidate talks about using AI, don't you dare penalize them. Especially if they're being transparent. That is the kind of culture you want to have in your company. You want AI champions who can talk about their successes with AI and also their failures with AI. Make sure that you don't penalize candidates who are showing that behavior. And so this brings me to the next piece. If you actually want candidates who work with AI, you need to stop running interview processes that are designed to have zero AI. So, I'm suggesting that you stop with your AI detection practices and start with AI assessment practices. Give candidates AI tools during interviews. Meta actually does with this with their engineers. They give them a llama install and they tell them to work with AI and assess their ability to do so. Evaluate how the candidate actually collaborates with AI. evaluate not just if they use it, but how they use it to add value, whether they just do what AI says or whether they're actually able to exercise some agency over the AI and direct it in ways that are useful to get the overall job done. Make sure that you also test how they handle really messy problems that require conflicting requirements, high thinking quality, and the ability to negotiate multiple constraints. Those are classical areas where AI breaks down. I just advised candidates who are interviewing to call out constraints with the star C method. I am suggesting to hiring managers that you fish for those constraints. Look for messy problems because the candidates will have to show they are good at what they're doing with their human brains to answer messier data problems. Don't just give a candidate a really clean data problem as a take-home exercise and expect to get useful value. In fact, take-home exercises are on the decline precisely because AI can get them done. What I'm advocating is that you give them exercises that are kind of a mess because you're testing their ability to use human judgment. And candidates, if you're still listening, I'm sorry, you're going to get some exercises that are a bit of a mess. But on the plus side, it gives you the chance to show your human skill sets. And that's what we're here to demonstrate. I want to give you also a framework as a hiring manager to assess candidates for AI fluency. It's one of the hottest topics in 2025. I'll probably do more on it soon, but as a quick rule of thumb, you want to be checking for three levels. One is AI literacy. I guess zero is no AI, but one is AI literacy where you are able to see that the candidate can choose between different tools intelligently. The candidate can verify outputs for hallucinations. The candidate has awareness of AI limitations. The candidate can tell you the difference between claude and chat GPT and why. Number two is AI integration, which can be technical or non-technical depending on the role. But you're looking for the candidate who can talk about their workflow design or how they would design workflows in your role with AI at the heart of those workflows, what tools they would select, why, how they would handle data. You want to check for error handling and have the candidate bring that up proactively. Talk about their evaluation and metrics philosophy. Talk about systematic collaboration. If you want someone who can actually help you be the 5% in the MIT study, that's someone who can help you with workflows. That infamous study with execs that said only 5% of projects deliver ROI. The key was good integration. Level two candidates on AI are going to be able to talk integration fluently. And yes, you want to be asking interview questions that test for that. You don't want to just ask your traditional role interview questions. Level three AI leadership. This is going to be for senior roles. You need someone who can do one and two. So they can do tool selection, output verification with their eyes closed. They can walk through workflow design, error handling, but they can do more. They can talk to you about strategic adoption. They can talk to you about AI governance. They can talk to you about team development with AI very fluently. They can architect systems that allow others to design workflows and ensure and be accountable for outputs against multiple workflows that are designed. These are the kinds of people that you're looking for in leadership roles where they understand the domain, but they also have a very high level understanding of AI that allows them to truly lead their team. Because these days, most people hiring for leadership roles need a leader coming into the space that doesn't need their handheld on AI. They need to be a champion for AI from day one and potentially be a champion in a room full of people where some of them are deep domain experts but may not be deeper on AI. And so every hire you make as a hiring manager needs to move the ball forward on your AI transformation strategy and that includes senior leadership roles. Expect your senior leaders to know how to develop their teams on AI from day one. Don't tolerate ramp time. Ask the questions you need to ask to ensure that they can do so. As an example of a good question, why don't you give them the actual stack you have? Not the ideal stack, the actual stack that you have. give them an example of the kinds of resistance you're seeing across your organization with AI and then say how would you solve this? How would you bring your team along? Let's say we needed the team to get to strong integration fluency within 2 months. What would you do? Why? Cuz you're then testing multiple things, right? You're testing domain expertise. You're testing their uh fluency with AI and how they would handle that. And you're also assessing leadership and change management. And you can break down that answer and see where they stumble, see where they're weak, see where they're strong. There's other questions, but you get the idea. When you are interviewing, and by the way, if you're still listening, this is like free intel for the candidates. There are red flags and green flags. And we've always had that, right? The AI red flags look a little different. And the AI green flags look a little different. And I want to spend some time for AI. A red flag looks like not just generic responses which I talked about at the top where you're overrelying on tools and like you're just reading the response which yes people can read body language they can read when you're like sliding your eyes to the side they can read the weird pauses people notice. Okay, candidates, if your candidate can't explain AI limitations, if your candidate can't go off script, if your candidate doesn't have the ability to break down a problem from a different angle on fairly short notice, that is a big red flag. It's also a great tell because AI tends to take some time to break down problems from different angles and is actually even the most cutting edge models are not super good at that right now. they tend to get stuck in the middle of a chat on a certain angle and anchor to that because of the context window. And so if you are suspecting that your candidate is just reading answers, if you shift the angle of the problem quickly, their AI may not catch up. It's a way to push them off script. On the other hand, in the AI world, we have new kinds of green flags. If your candidate volunteers, how they're catching AI errors, if your candidate volunteers to talk about how they do a systematic verification process for work they get done so that they take ownership and accountability for it and they're not just paring what AI says. If your candidate can quantify AI impact and talk both at the individual level and the team level and the organizational level about what AI can do for the business, what AI has done in their role, that's a huge green flag. If your if your candidate has a philosophy of the role that says this is how this role is evolving in the age of AI that they can explain coherently they can act as a peer champion for AI for their role. It's really compelling. So there's lots of green flags too. It's not just red flags here for both parties. Right? We're bringing this to a close here for candidates for hiring managers. I want to give you three principles to stick with that I think will help you. Three principles to unlock what feels like a stuck market right now. Number one, enhancement beats replacement. AI is there to make human judgment clearer, not to substitute for it. Candidates, that means if you're reading answers and not using your brains, you're losing. Hiring managers, that means if you're using AI to evaluate interview transcripts and you're not actually thinking about what the candidate is saying and taking the candidate seriously as a person, if you're just using AI to interview, you are also losing. You're also losing. You're contributing to the problem. Both sides win with transparency. That's number two. Candidates need to show better judgment when they admit to using AI. And managers must find better talent when they have to talk about how they actually use AI at work. So bring AI to the table. Don't hide it. Candidates don't hide it. Hiring managers don't pretend it's not there. Both sides need to talk about their AI strategy to actually move the ball forward. Third, last but not least, make sure that you know how to use your prompts well. I've included a bunch of I think nine s prompts that like dig deep on interview prep. But you need to have prompts that actually help you move the ball forward. If you're assessing résumés with prompts as an aid, not as a substitute, you need to have prompts that actually help you to do that. If you are preparing as a candidate, you need to have prompts that help you to research a JD and go way beyond the surface level in order to stand out as a candidate. I they have written prompts where you can get three or four pages of really strong interview prep material out of one job description because you're telling the AI very specifically what to look for that helps you to prepare. It's all about intent. It's not like my words are not magic. It's about telling the AI how to effectively assess what is in front of it, what is between the lines, and what you need as an interview prepper to get ready for a big conversation. Hiring is broken, kind of broken. I want it to get better. And I think the only way it can get better is if we admit that AI is at the table now. If we're transparent about it, and if we use AI to support human judgment rather than to replace it. Best of luck out there, and let me know how you're doing. Cheers.
