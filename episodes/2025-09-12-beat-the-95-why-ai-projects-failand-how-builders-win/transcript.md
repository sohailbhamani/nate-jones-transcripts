---
title: "Beat the 95%: Why AI Projects Fail—And How Builders Win"
video_id: "zw39KBZkPeA"
youtube_url: "https://www.youtube.com/watch?v=zw39KBZkPeA"
substack_url: null
publish_date: "2025-09-12"
duration: "19:19"
duration_seconds: 1159
view_count: 9701
author: "AI News & Strategy Daily | Nate B Jones"

yt_tags:
  []



# AI-enriched metadata
content_type: "News Roundup"
primary_topic: "AI Strategy"
difficulty: "Intermediate"
audience:
  - "Engineers"
  - "Executives"
  - "Product Managers"
  - "Founders"
entities:
  companies:
    - "Google"
    - "Perplexity"
    - "LinkedIn"
  people:
    []
  products:
    - "Claude"
    - "Claude Code"
    - "Perplexity"
    - "Make"
    - "Artifacts"
    - "Projects"
  models:
    []
concepts:
  []
summary:
  - "# Beat the 95%: Why AI Projects Fail—And How Builders Win

In the next few minutes, I'm going to save you at least six hours of work"
keywords:
  - "ai-news"
  - "ai-strategy"
  - "ai-tools"
  - "anthropic"
  - "artifacts"
  - "career"
  - "claude"
  - "claude-code"
  - "coding"
  - "frameworks"
  - "google"
  - "leadership"
  - "linkedin"
  - "make"
  - "perplexity"
  - "product-management"
  - "projects"
  - "prompting"
  - "startups"
  - "tutorials"
  - "workflows"
---

# Beat the 95%: Why AI Projects Fail—And How Builders Win

In the next few minutes, I'm going to save you at least six hours of work. I'm going to help you turn your prompt mastery, let's say you've been following my videos, you feel like you know prompting into a recipe for organizational AI success. What does it take to go from being a prompt ninja perfecting chat GPT prompts, Claude workflows, cloud artifacts, whatever it is, chasing every new feature announcement. Claude code interpreter came out this week. At the same time, you're in a world where your company or your team around you are not on the same page. Even in AI first businesses, there is a wide range of adoption patterns of AI. There are some people who are still using those manual workflows. And so, you see that your company's AI pilot stalls out. Budgets, they might get slashed. Executives will say AI is a fad or say that things aren't working or that they aren't seeing return on investment. Here's the secret that isn't getting told enough. The individual prompt mastery practice you're doing doesn't scale. But the secret is not just get your leaders on board with AI. To be in the 5% who succeed, you need to figure out as a builder, as someone who may not even be a director or a VP, how to level up your personal AI hacks into something that is a system of learning, something that can help your team deliver business value. And that's what we're about today. Why am I talking about this now? Because the number one study circulating on the internet right now is the infamous 95% fail study. It is a study published in August 2025 by MIT reporting that 95% of enterprise AI initiatives deliver zero measurable ROI within six months. 95% that's based on 150 plus executive interviews and 30 to40 billion dollars in represented AI spending. It sparked global headlines. I can tell you that the Google first search page is like all disaster headlines. It's just all everything is bad. LinkedIn doom loops people sharing the headlines, not reading it. Very few people have actually read this study. This is part of how I'm saving you time. All of this surface level narrative overlooks some of the key nuances that separated the winners and the losers. And I did the digging so that you don't have to. Number one, nobody is talking about this. The frame for this study is mostly incorrect. This study is asking executives what builders are doing. And anyone who has worked in a business will tell you executive pictures of AI adoption and AI fluency differ dramatically are not the same as what builders on the ground are doing. And that's why I am talking in this video to you. If you are building, if you are prompting, if you are excited about prompting, if you're a founder, a solo builder, whatever it is, you have a chance to change this narrative. And I'm going to give you specific principles that popped out from hours of study looking at the MIT study, the people talking about it, everything else. First, what did the internet get wrong about this reaction? Then we'll get into how we dig in further. Number one, the executive panic is incorrect. We got executives saying, "Is AI a bubble?" We got stock crashes. We got boardroom jitters. It's just it's not the right focus. It misses the nuance and the detail. We got methodology debunking. I don't want to go into it. There are entire subreddits dedicated to debunking this particular study and saying you can't draw big conclusions because it's such a small study and interviews and this and that. Look, I understand statistics. I could go there. You don't have time for it. I don't have time for it. We're going to save the time. Let's just say maybe the study is flawed, but there's a lot we can learn and we don't have to worry about it. There's a lot of copypaste journalism. We're not going to waste time on that. And there's a lot of really binary conclusions. One of the things that they came out with is a opinion on the binary buy versus build where the MIT study basically said you were much more likely to succeed in your AI pilot if you bought versus if you built. It's kind of convenient that they're saying that because the people running the study are selling something. So yeah, I'm shocked that they came out with the buy. But but wave that aside, let's say they have good intentions and they got that and they're honestly sort of presenting what they see. It's still oversimplified advice that misses the realities I see diving into organizations daily and so it's still wrong. So let's dive in and let's figure out what the real takeaways are so you don't have to spend 6 hours staring at all this stuff. Number one, the MIT study actually measures only profit and loss focus over a 12 to 18month period. That is it. It is a very narrow measure of success. It's the first thing to be aware of. Number two, as I said, it only talks to execs. Number three, it only gives execs a buy or build. It's sort of a very binary conversation. We talked about that. Number four, it talks a lot about workflows, but is too high up because they're talking with execs to have specific guidance on how to build those workflows in ways that actually work. This is where we're going to start to close the gap and give you takeaways that matter. So, what actually drives success? Let's turn around and say, what if you want to be in the 5%. and you don't have the power of a vice president and you're you're a prompt expert, you're a team influencer for AI, maybe you're uh a leader on your team, how do you actually start to drive success? I want to suggest to you that we builders know technical patterns that come up again and again and again as success indicators that did not show up in the MIT conversations because execs aren't aware of them. So, let me name them here and let me share them because so many of us are discovering them by running into them. We're like, we've got our eyes closed and we're feeling around in the dark and we're discovering these principles. Let me just name them so that we all are talking off the same page. Hybrid architectures matter. We didn't have that choice in the MIT conversation. They didn't write it up. Every single time I have talked to businesses who are actually implementing AI, they have hybrid architectures. They are combining best-in-class models with custom workflow logic. They're not just doing a roll your own versus a buy. They're actually taking the best of both worlds and they are recognizing the work it takes to do that. That there is no such thing as a free lunch. One of the things that the MIT study missed is that even if you buy, you are buying work. And again, executives don't see that. Number two, learning systems is how you should think about installing AI. You want to build feedback loops. You want to retrain your pipelines. You want to have context persistence. It's builders that understand this and that are stumbling into it. When I wrote my guide on rag, when I wrote my guide on chunking data, it's all about how you start to take the data you have in the business and surface it and make it available so that AI workflows can actually use it in feedback loops that allow the business to learn and get better. next time at completing tasks that matter. This is one of the key findings from the study, but it was never pulled through. They never figured out how to pull it through because again, they were talking to execs. So, the generic conclusion of the study was, "Oh, yeah, it would be good if AI was able to adapt to enterprise workflow realities." Yeah, I mean, you know, sliced bread is cool, too. Isn't that great? The the reality is the only way you get that done is by actually building feedback loops with persistent context and being willing to retrain your pipelines until it works. This is hard work. When I talk about even at an individual level, let alone a team level, what it takes to have an agentic workflow, people get this big heavy site. They're like, "That's a lot of work." And I'm like, "Yeah, that's why you should pick problems that matter because you're going to have a lot of work. you're going to have to put your shoulder to it and you're going to harvest the value disproportionate disproportionate ratio if you have a better goal. And so if you have a goal that's big that's audacious and you want to learn a lot and you want to break through for the business, let's say that your goal your your choice is between a rag system for an HR policy manual and a rag system that allows you to maintain context across deals for the sales team. Pick the sales team option. You put in the same amount of work either way and you get so much more value off the sales one. Build learning systems that matter and that are aligned to your goals. Number three, this one almost didn't get talked about, but the study did mention it. It said that building intelligent friction mattered for successful organizations. People think of these systems as like you want to make AI as easeful as possible. That's not true. You want to embed smart friction. And I'm going to give you specifics and the study didn't. You want to embed confidence thresholds. What if you were able to show in a printed out response from an LLM in red or green or yellow, what is the confidence the LLM has in the token it's presenting? So you can see low confidence tokens that might indicate hallucinations. What if you had human review gates where humans could go back and retune and they could say, you know what, I want a more aggressive LLM pass. I want a less aggressive LM pass. I have sliders to tell it how to adjust. I don't just have a yes or no. Is it more friction? Yes. Is it something that's actually going to help you build a more useful system long term because that friction is smart and reinforces your learning system? Also, yes. Again, not something the MIT study jumped into because they did not talk to builders. Instrumentation. You want to be looking really carefully at your accuracy, at your latency, at your error rates, at your override metrics. The reason I am saying this is not because I want you to invest in metrics. If you haven't built a system, I want you to invest in making sure that you know whether the model is solving a meaningful problem and what is the quality of the solution it is proposing. And the reason I think this matters is that if you let execs determine ROI as a measure, that's fine. It's down the road and you have no leading indicators. Instrumentation is a way to get actionable leading indicators that let builders actually drive success for AI projects in a way that you guys can then report up to leadership. And if we don't talk about that a lot, if we don't talk about instrumenting these projects, we're going to let leadership dictate what success looks like and we actually have a chance to influence that. Now, if you're wondering what does instrumentation look like besides like the technical ones, I will say it is more useful to be able to agree with leadership on a general goal and problem you want to solve. Show the problem is being solved well and then show the direction for how to extend the solution. than it is to talk about vanity metrics. And I think one of the most persistent vanity metrics is adoption and time saved. You'll notice I didn't mention those ar those aren't technical metrics. And what I find is when execs see that, they think that builders like you and me are trying to position success outside of ROI. Whereas if they start to see technical metrics, you have to explain them so they understand what they are. But once you explain them, no one mistakes them for the end goal. And that matters. Another principle that really matters is that this one doesn't get talked about at all. MIT didn't get to it. I think it's really important to actually be in that successful AI category. Shadow AI mining. You need to be the one that formalizes the gorilla AI use cases your team depends on. Is there like a GPT you're passing around that works? Is there a use of perplexity that works? Whatever it is, if you can mine the shadow AI for behaviors that work, and by the way, product managers, this is a hint for you. If you're in the B2B space, your customers have shadow AI use cases. If you can get that out of them and build for it, that is gold. That is gold. So, do some shadow AI. Formalize those use cases and see if you can build them into actual workflows that work. You're going to make it happy. you're going to make if if you're building a product for B2B, you're going to make the business happy because it's going to drive value. Look for the AI that's happening in the shadows that again execs aren't going to be aware of. So, you've you've seen some of these things. You've seen some of the principles, the technical elements that drive success. I want to transition now to skills. If you want to translate individual contributor skill sets, the things that make you successful as an AI builder with AI into influence, these skills actually map back to some of the principles I just talked about. They're par. This is not a whole new set of things to remember. You can do the shadow AI detective work and then you become someone who's known for systematizing workflows in a way that brings AI out of the shadows and into the business. That's influence. You can be known as someone who can engineer guard rails that build trust through transparency. Doesn't that sound good? Well, guess what you're doing? That's friction design, right? We just talked about that. You can become known as someone that designs AI products that improve with each interaction. That's learning system architecture. Again, a way to develop influence from those same sets of principles I just gave you. You can learn how to show the connection between engineering KPIs like accuracy and business ROI. Suddenly, you're known for technical health monitoring of AI systems. That sounds like influence, too. You can learn to develop prompt libraries and templates that are tailored to diverse team needs and architect those libraries in ways that enable other people to jump onto them. That's an example of context translation and it is part of the hybrid architecture that shapes that shapes good AI systems. Let me give you just some examples of how you can go forward. How you can be the one that takes this 95% study, turns it on on its head and says, you know what, this is a study for builders and no one said so and we can actually be much more influential. Product managers, you can run shadow AI surveys. You can build features that are better with guerilla workarounds. You can figure out where to put intelligent friction in your products. You can figure out how to communicate instrumentation to execs in ways that they can understand that give you leading edge indicators so they won't just go to an MIT study and say, "Well, there's no ROI." Solo founders, entrepreneurs, you can focus on narrow workflows that allow you to customize to the business. If there's anything you're hearing here, hybrid architectures work. Businesses that buy AI solution are taking a tremendous amount of burden. If you focus narrowly on workflows you can tailor, you can deliver deep value and you can help lift the load for those businesses and you will earn trust and that will enable you to go after adjacencies over time. Engineers, you can get good at instrumenting. And I realize by the way that this is a new skill set. There is a degree to which instrumenting in AI is different than any other kind of instrumentation. Arguably one of the biggest skill sets engineers need to pick up is data science. Like how can they start to bring more data science into their instrumentation because these are non-deterministic models and it's complicated to measure them. You can learn, you can scale up, you can do your best to instrument, you can do your best to automate. And in particular, this is an area where I think engineers can lead the way in the company. You can lead the way on context management and what it means for the business. You can lead the way on explaining why the difference between a bad work result and a good work result can be as simple as clean context. Is not putting the kitchen sink of the wiki into the prompt and wondering why it doesn't work. UX designers, there is so much here for you if you're anywhere in the design space. surfacing confidence scores, figuring out how to help people who are doing QA loops do so intelligently, offering people great override options, figuring out how to take guerilla workflows and formalize them without losing the value. Security and compliance, like if you're working in that space, you definitely want to be auditing shadow usage. And you can only do that if you earn trust. You definitely want to be on the forefront of explaining how hybrid architectures can actually be more secure by speeding value and like pushing the shadow IT footprint to the edges and speeding the value of the business getting the install done. You can figure out where to embed friction for sensitive approvals. There's so much here. I'm just giving you a few examples. You can fill in the rest. Your competitive advantage is that you know the prompts. You may be digging into the APIs as a builder. you know the hidden workflows on your team that work that really work the exacts don't this playbook I'm giving you here this this open door into this MIT study what went wrong with it where we need to actually build this is going to help you bridge the gap between your personal mastery your sense of achievement and how businesses actually get done I guarantee you if you start to think about how to build hybrid architectures how to build systems that learn how to have intelligent friction how to think about buy versus build not as a binary tradeoff. How to think about instrumentation that leads to good ROI outcomes without just measuring the dollar and without just cheapening out and measuring adoption. You are going to be so far ahead of most of the individual contributors like 99% of them and it's going to give you options to drive good outcomes for the business. I don't know what your career goals are. Maybe you're looking for a promotion. This sure seems like a pathway there. Maybe you're looking to just extend your influence and you want to avoid a promotion. You can probably dictate your terms if you do something like this. This is a skill set. What the MIT study missed is that the people with the skill sets to do this are developing it on their own and reinventing the wheel time after time after time. And I see this and I want to lay it out in the open. These are principles I see being redeveloped over time that the MIT study missed. They are reasons for success. So learn from these principles. Don't reinvent the wheel. Know that other people are struggling with you and that if you see a headline like that, you have a surprising amount of influence if you are not in leadership to change the outcome of the business that you work with. You are not powerless. You can build in ways that avoid that 95% headline failure outcome, which by the way, I don't even know that I believe 95% is correct. It's another story. I hope this has been helpful. I hope you see some of the pathway forward to go from individual prompt mastery to something more to something that enables you to influence the business. Let me know what you think. Pop it in the comments.
