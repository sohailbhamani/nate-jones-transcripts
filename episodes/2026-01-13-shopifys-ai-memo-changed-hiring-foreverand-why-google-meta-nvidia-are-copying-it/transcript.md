---
title: "Shopify's AI Memo Changed Hiring Forever—And Why Google, Meta & Nvidia Are Copying It"
video_id: "dzp0OQbElpU"
youtube_url: "https://www.youtube.com/watch?v=dzp0OQbElpU"
publish_date: "2026-01-13"
duration: "25:36"
duration_seconds: 1536
view_count: 29856
author: "AI News & Strategy Daily | Nate B Jones"

yt_tags:
  - "AI jobs"
  - "AI labor market"
  - "AI strategy"
  - "future of work"
  - "Shopify"
  - "Toby Lutke"
  - "hiring in AI"
  - "upskilling with AI"
  - "Claude Code"
  - "AI fluency"
  - "entry level jobs"
  - "AI career advice"
  - "talent market"
  - "AI native"
  - "Red Queen memo"


# AI-enriched metadata
content_type: "News Roundup"
primary_topic: "Career"
difficulty: "Intermediate"
audience:
  - "Engineers"
  - "Executives"
  - "Product Managers"
  - "Founders"
entities:
  companies:
    - "OpenAI"
    - "Google"
    - "Meta"
    - "Amazon"
    - "Nvidia"
    - "Shopify"
    - "Salesforce"
    - "Slack"
    - "GitHub"
    - "Box"
  people:
    - "Josh Miller"
    - "Toby Look"
    - "Aaron Levy"
  products:
    - "Claude"
    - "Claude Code"
    - "Copilot"
    - "GitHub Copilot"
    - "Cursor"
    - "Arc"
    - "Make"
    - "MCP"
    - "Projects"
  models:
    []
concepts:
  - "What he meant by it because this this affects every single person in tech"
  - "Restructuring how work gets done"
summary:
  - "# Shopify's AI Memo Changed Hiring Forever—And Why Google, Meta & Nvidia Are Copying It

Eight months ago, Toby Look posted a memo that most people dismissed as typical tech CEO posturing"
keywords:
  - "ai-news"
  - "ai-tools"
  - "amazon"
  - "anthropic"
  - "arc"
  - "box"
  - "career"
  - "claude"
  - "claude-code"
  - "coding"
  - "copilot"
  - "cursor"
  - "frameworks"
  - "github"
  - "github-copilot"
  - "google"
  - "leadership"
  - "make"
  - "mcp"
  - "meta"
  - "nvidia"
  - "openai"
  - "product-management"
  - "projects"
  - "salesforce"
  - "shopify"
  - "slack"
  - "workflows"
---

# Shopify's AI Memo Changed Hiring Forever—And Why Google, Meta & Nvidia Are Copying It

Eight months ago, Toby Look posted a memo that most people dismissed as typical tech CEO posturing. AI is mandatory. Prove the robots can't do it before you hire a human. Put AI usage into performance reviews. And the reactions were predictable. Some called it visionary. Others called it a smokeokc screen for layoffs at Shopify. And most assumed it would quietly fade into the graveyard of executive pronouncements that sound radical, but really changed nothing. They were wrong. What Liy actually did was fire the starting gun on a talent market restructuring that is now in January 2026 accelerating faster than anybody anticipated. And we're not at the end of this story. We're watching it unfold in real time with new signals emerging every single week. Just this week, Josh Miller at the browser company mentioned that they're paying premiums for people who are native to the claude code way of building. That's one company one announcement, but it's symptomatic of something much much larger. The job market itself is being rewritten and the changes that seemed speculative 8 months ago are now showing up in actual hiring criteria, compensation structures, role definitions across the industry. Every week brings another data point and every month the pattern gets clearer. We're not close to the end of this guys. So to understand where we're going, you have to understand what look actually said back in last April and more importantly what he meant by it because this this affects every single person in tech. The memo was not a new philosophy just for Shopify. I want to be really clear. It was the application of an existing philosophy to a net new capability artificial intelligence. Ludge has long operated under what he calls the red queen framework borrowed from Louisis Carol's Through the Looking Glass where the red queen tells Alice that in her kingdom it takes all the running you can do to stay in the same place. At Shopify this translates into a stark reality in a company growing 20 to 40% yearonear you have to improve by at least that much every single year just to re-qualify for your own role. This applies to Lkey himself as well as everyone else. You're not competing against your past self. You're competing against the theoretical version of yourself that kept pace with the company's growth. So stagnation, it's not just failure, it's slow motion termination. The April 2025 AI memo wasn't a new philosophy. It was the Red Queen logic applied to a new capability multiplier. What the April memo did was identify AI as the new mechanism for that improvement. The specific mandates were really clear. Reflexive AI usage is now a baseline expectation, not a suggestion, not encouraged, but expected. AI must dominate the prototype phase of all get stuff done projects. Performance reviews will include AI usage questions. Managers and peers are rating each other on how AI native and how AI reflexive they are. Teams must prove AI cannot do the work before requesting headcount. And everyone means everyone including the bosses including Lutkkey and his executive team. The critical shift from Lutky's earlier encouragement was explicit. As he put it, the call to tinker with it, which is what he did in 2024, was the right one, but it was too much of a suggestion. This is what I want to change today. Direct quote from the essay. Now, when pressed, he went on to clarify that he'd seen people achieve x the work that they've done just in responding to this challenge. And frankly, that aligns with what I have seen as well. The top developers in the world now, top 1% if you want to use that phrase. They put out 10 billion tokens last year, 100 million lines of code. You don't get to that level of productivity without committing yourself to an AI native way of working. And the reaction to Toby's original claim in April split along ideological lines, as it so often does, unfortunately. Supporters saw it as the right path for the company and any company serious about competing and critics saw it as a smokeokc screen for staff reduction. But here's what most people missed in all of that debate. The memo isn't about productivity. I know I just mentioned all of those lines of code, 10 billion tokens. It's actually about selection pressure. By making AI usage a performance metric, LGI was not trying to make Shopify more efficient per se. He was reshaping who would want to work there and who would thrive once they got to Shopify. The memo was effectively a filter on hiring as much it was a was a talent message. Now to be fair, part of what made Shopify different, part of what made that memo work at that company was because Shopify has had a similar culture for a long time. I talked earlier about how the red queen race has been a theme at Shopify for a while. And in a first round interview with VP and head of engineering Farwan Tawir from July, you see the mechanics behind the memo that persists at Shopify in late 2021 before all of this AI stuff really hit the mainstream. To brought GitHub Copilot to Shopify so early that he wasn't even able to pay for the product yet. It was it was pre-alpha alpha a year before the release of Chat GPT at Shopify. They were already using co-pilot across engineering. That's how early that company was. By early 2023 years ago, they had an 80% adoption rate. And the infrastructure Shopify built is what made the mandate that Toby issued possible. They created an internal LLM proxy, a centralized system that allows employees to access multiple AI models through a single interface. Users could switch between models seamlessly. And the proxy handles the scaling, the tracking, the failover in production. They built dozens of MCP servers connecting to Slack, to Salesforce, to G Suite. Essentially, as Tower called it, they're MCPing everything, right? Making every single piece of internal data available for AI interrogation. And once someone creates an MCP connector, of course, anyone can use it. They also open sourced roast, which is an AI orchestration framework, not a coffee bean, built with clawed code that roasts code contributions with constructive criticism. The key insight from building is, and I'm quoting Tawar here, AI agents need help staying on track. That is true. And work much better when you break down complicated prompts into discrete steps. So allowing AI to roam free across our millions of lines of code didn't work very well. And so ROST helps to provide some needed structure there. Now, unlike companies that gate advanced models for technical teams, Shopify gives everybody access to everything. No spending quotas. Tawar tracks who's spending the most on cursor tokens as a proxy for employee val value actually uh and recently the CTO of Shopify topped the list which shows that even these seuite folks are individual contributors as well and tool adoption exploded so fast in response to this permissive environment that tower had to order 1500 cursor licenses and immediately get 1500 more and ironically this is going to make you sit down the fastest growing user groups were not in engineering this is what I'm The talent market is changing. They're in support and revenue teams. They're getting cursor licenses. The legal team helped make this possible because when Tower wanted to adopt C-Pilot in 2021, the conversation with legal opened with, "We're going to do this. How can we do it safely?" And so, Legal was put in a position of figuring out a way as opposed to saying, "Hey, might we be able to do this? Could we ask permission?" because then legal is going to default to some of the specific examples of how Shopify employees use these tools reveal a little bit about the way AI augmented work actually looks like in practice. So a sales engineer brought MCPs of his most frequently used tools G Suite, Slack, Salesforce into a cursorbuilt dashboard and then he could just ask what do I do today and the system looks at Salesforce opportunities notices missing email responses and prompts action as Tower describes it. He can literally work in cursor as his homepage because he's not using the tools. He's disintermediating these things that we thought were core to work. And by the way, cursor comes up a lot in the Shopify story, but you can do something very similar with claude code right now. So, it's not the tool I want you to get excited about. It's the role change. Meanwhile, the revenue tooling team deployed an request for proposal agent that answers RFP questions while learning from winning responses actively. And so it improves through accumulated knowledge of what wins deals and sales reps can build automated site audit tools on their own to discover information they'll need for the RFP. I think Tower had coined a good term when he talked about this. He calls this process power because effectively we're not just accelerating the stream of work through existing flows. We're fundamentally restructuring how work gets done. We use process power to relever work. Shopify's internal AI chat tool originated as a prototype by a senior engineer experimenting with open-source tools. It became so widely adopted that a dedicated engineering team now runs it. And this pattern individual experimentation becoming organizational infrastructure, it's the mechanism by which AI native workflows tend to propagate in organizations where you're allowed to experiment widely. The numbers tell a story that complicates any simple narrative about AI and jobs. And I do want to emphasize that because the assumption is usually any narrative like this means brutal job cuts. Shopify had roughly 11,600 employees at the end of 2022 and that was at the peak. I want to emphasize of the zero interest rate era which is a whole complicating factor in this whole jobs conversation after layoffs that year when interest rates rose nothing to do with AI they were down to around 10,000 after May 2023 layoffs and before AI can plausibly be said to have accelerated productivity they were down to 8,300 by December 2024 at 8100 remember this is all before Toby put out the AI narrative and so yes they are continuing to get leaner But you have to understand that headcount can be roughly flat on a normalized interest rate basis and you can still see skyrocketing productivity with AI. Now some observers theorize that the Toby Loki memo was a smokeokc screen to cover continued cost cutting without alarming investors. Given the depth of involvement in the company on AI over the years, I disagree. I think they've been investing in AI really passionately and I think if you're in a red queen race culture and I've been in something like that when I was at Amazon. You have to commit to growing and it is one of those cultures where if you're not growing you're out and so they do tend to have high turnover and frankly it wouldn't take much more than not backfilling every other position to get to a point where you start to level out your talent where you see the AI productivity gains. One of the most interesting developments of the past eight months though is that there's some real strategic logic around the roles that Shopify is choosing to save and emphasize. Months after the Prove AI can't do it memo, which is what we've been discussing, Shopify announced a massive expansion, an expansion of their internship program from 75 to over a thousand engineering interns. Yes, you heard me right. More than a 10x increase. And you might wonder why. But we've just gotten done talking about the complicated story around interest rate cuts and normalizing those and talking about how you leverage more productivity and the red queen race culture. How does any of this translate into more hiring? If AI can do the work, why hire a thousand interns? But the logic becomes clear when you understand what Shopify is hungry for talent-wise. Shopify is looking for what Tower calls AI centaurs. I love that phrase. They're naturally comfortable with AI tools because they've grown up with them. AI native is another way of putting it and they push existing talent to stay current. We actually see the same hiring principle at work at OpenAI these days where you'll have interns or junior engineers coming in and they are AI native and that's part of what they bring to the table. The program comes out as a win across multiple dimensions. Interns bring AI native skills. They bring fresh perspective. So, Shopify gets a huge pool of candidates to look at for full-time roles and the interns leave with real skills from Shopify that they can take back into the ecosystem. What I'm seeing here is a pattern that is almost U-shaped in the talent market where you have very senior folks who are incredibly leveraged. We just got done talking in this video about how the CTO at Shopify is in some in some months the number one outputter of tokens and at the same time a passion for juniors and hiring juniors in who are AI native. This is this is what a U-shaped talent market look. Now Shopify takes the AI reflexiveness seriously enough that as you'd expect it gets into the review cycle. Managers and peers as I've been saying rate how AI native and reflexive you are. But the company also checks to make sure that that's a reasonable rating because they analyzed AI tool usage and correlated it to the reviews from peers and found positive correlations. In other words, when your peers tell if you're AI native, they actually kind of know and the vibes are correct. Now, there is a risk that you can game this system. Goodart's law holds true. Anytime you make something a goal, people find a way to game it. And so it's critical to make sure if you are managing and driving AI reviews that you're able to distinguish between deep and powerful AI usage and shallow usage. Now Shopify will say they've seen something 30-ish% higher employee productivity across departments, but as they themselves call out, they've been doing the AI work for years. And so getting to the point where you see employee productivity really rise takes deep investment. Not everybody figured that out. In fact, there was a copycat wave that exploded across the ecosystem in the rest of 2025. Box, Fiverr, Duolingo all jumped on the bandwagon and it did not all work well, which I think is another part of the story that's worth calling out. If you start an AI revolution and you don't have your troops ready and you don't have your weapons ready, to use a metaphor, you're not going to win the war. Dual Lingo's version has become a case study in how not to do an AI revolution because on April 28, 2025, very near the time of Toby's original memo, CEO Lewis van shared a memo outlining their version of the AI first transformation where they're going to phase out contractors if AI can do the work making AI part of performance reviews. It sounds very similar to Toby, right? Well, the response was a disaster. People started cancing their subscriptions to Dualingo. AI first means people last, people said. And eventually the CEO of Dolingo had to walk it back and admitted when he released the memo, I did not do that well. I do not see AI as replacing what our employees do. Eventually he acknowledged that the backlash dampened customer growth and had to go back to initially laying the groundwork for AI transformation by just teaching existing employees about it. Box's Aaron Levy found a path that may prove more durable. His approach focuses on eliminating busy work with a twist. Teams that automate get to keep the savings for strategic projects. So AI savings don't return to the CFO at Box. AI savings return to the team and help the team fund their own choice of their next strategic breakthrough. And so this framing converts AI adoption from a threat into an opportunity for entrepreneurial teams and changes the incentive structure entirely. Ultimately, what the copycat wave revealed is that there's this tremendous underlying selection pressure at the company level and every CEO has felt it. But their execution varied wildly based on how well leaders understood their own organizations and their audiences. Looks version I think worked at Shopify because Shopify had spent years building the infrastructure and culture to support that choice. When the memo dropped, it was formalizing a lot of what was already happening. That wasn't true at a lot of the copycats. The impact of the LUTKI memo went all the way up to big tech. Jensen Hang in November 2025 responded to reports of managers telling employees to use less AI with this quote. I want every task that is possible to be automated with artificial intelligence to be automated with artificial intelligence. He called resistance insane on job security. He added, I promise you, you will have work to do. And and honestly, Nvidia has grown from 29,000 to 36,000 employees in one year, and Jensen says they're probably still about 10,000 employees short. So, he's putting his money where his mouth is as far as hiring goes. The pattern across these announcement is consistent. AI usage is moving from encouraged to expected to measured. So, what gets measured gets managed and what gets managed shapes ultimately all of our behavior. And the companies that were early to this now have years of data correlating AI tool usage with how employees are performing. Whether that correlation reflects genuine productivity remains something that is a bit of a secret sauce, but the selection pressure is real regardless of the mechanism. Meanwhile, the data on the job market itself is that that the job market itself is changing is now concrete enough to track. So job posting requiring AI skills doubled from roughly 5% in 2024 to 9% in 2025. workers in occupations requiring AI fluency grew from around 1 million in 2023 to 7 million in 2025. The fastest growing skill category in US job postings and the entry-level squeeze despite Shopify's investment in entry level is visible. 66% of enterprises are reducing entry-level hiring as they adopt AI. 91% report automationdriven role changes. Postings for seven plus years of experience have increased while entry-level roles have shrunk. Some companies now require prior projects even for nominally junior positions which is absolutely in line with what I hear from folks who are entering the job market. And the skills gap is widening along with those job market changes. 84% of companies report significant skill gaps within their talent base. AIM ML roles take 89 days to fill which is longer than average. And nearly 90% of organizations use AI in operations while only 9% would grade themselves as AI mature which frankly sounds about real. And so this week's announcement from the browser company is really one of many, right? When Miller talks about designers submitting pull requests directly, non-engineers prototyping their own ideas and code, engineers running experimental side projects, they're talking about cloud code, but I hear echoes of Toby's memo. I hear an ongoing pattern that is showing us that fundamentally we're moving to a world where skills matter more than jobs. The restructuring lit triggered in April is propagating through a much broader market and showing up in job descriptions that are being rewritten, interview processes that are adding AI fluency assessments, and even compensation models are being recalibrated. And Topi's insight around junior employees continues to hold up in research, which is why I find it interesting that so many other companies are choosing not to go in for junior talent. It's easier for juniors to bring AI into their daily workflows and senior with seniors with more than 10 years of experience have more to unlearn about their old patterns. Ironically, a lot of the research academically shows that AI helps folks who are earlier in the talent tree more even than it helps seniors. And so there's a lot of debate about that. Certainly, you can see an incredible amount of leverage from multi-threading and agent workflows for very senior people who know their domains well. I think academic research tends to trail technology by several months to a year. My own expectation anecdotally is that you are going to see outliers on the senior and experience side that dwarf anything you see for junior talent because of their domain expertise and ability to quickly deploy tools. You will see a large average of senior employees that do have a lot of unlearning to do. And you will see um a good number of hungry hungry new employees that are early in the workforce that will be AI native from the get. So, where is all of this heading in 2026? We're 8 months into a transformation that is going to take years and years to play out and the and the pace is accelerating. AI fluency is moving from a differentiator to a baseline expectation. By the end of 2026, expect AI fluency requirements to appear on the majority of knowledge work postings, not as a specialized skill, but as something like email or spreadsheets. The companies that were early to this are establishing expectations that are going to become an industry standard, like Shopify. Role boundaries, and this is a big one, are going to continue to be under threat and dissolving. The pattern of designers submitting PRs, of non-engineers prototyping, of engineers running side experiments, that's going to keep spreading. Job titles will become less descriptive of what people actually do because the jobs themselves are changing so fast. Ironically, the cost of crossing into adjacent domains is now dropping rapidly, which means the traditional org chart assumption of clean division between roles and ladders, it's becoming obsolete. New coordination roles are also going to emerge. When everyone can build, someone has to ensure coherence. Expect more positions like the browser company's design producer, which is an orchestration role that manages the increased volume of output from AI augmented teams. These are not traditional management roles. They're synthesis and curation roles for a world with dramatically more creative output per person. Compensation is going to polarize. If one AI fluent worker can do what previously required two or three, the math on salaries changes. Companies will pay premiums for workers that can demonstrate genuine AI leverage, not just usage. Meanwhile, workers whose productivity does not scale will face huge wage pressures even if their absolute output remains constant. This is the red queen race coming back. Unfortunately, I do think the entry- level squeeze will intensify. The traditional entry-level job where companies invest in training workers is becoming harder to justify. And the paradox is at the same time companies are looking for AI native talent that is early career. And so there's a huge switch in the expectations set for junior and entry-level employees that everybody is grappling with at once and no one has good answers on. As we move forward, the training gap for everyone else is becoming a strategic liability. Companies that invested early in AI infrastructure like the MCP servers and the LLM proxy at Shopify have a compounding advantage and late adopters kind of face a chicken and egg problem. They can't hire the AI fluent workers without the infrastructure to support AI fluent workflows, but they kind of can't build the infrastructure without the workers. And so there's going to be a lot of companies that are bidding for that AI fluent talent as we head into 2026. So where does this leave us? The Red Queen memo that Loki wrote is ultimately about selection pressure. It's it's his CEO understanding that firms themselves face a critical extinction level risk from AI if they don't act. And that is I think a more useful frame to understand some of these CEO pronouncements than looking at them primarily from an effect on their internal systems. Companies as a whole are at risk from AI if they don't change. We saw most recently a reflection from the CEO at Tailwind. Tailwind is one of the foundational CSS frameworks of the entire internet and yet they are struggling to stay afloat. Versel is talking about bailing them out and this is not because their product isn't being used. CSS frameworks like Tailwind are being used more and more and more by AI agents. It's because the business model hasn't stayed competitive. And I share that to highlight how everybody needs to think about AI as an existential risk. And when you challenge your teams or if you're on a team that's being challenged, it's not about bringing out the last possible dollar. It's about figuring out how the company needs to rapidly evolve through an enormous selection pressure event into a company that can be AI competitive. As Luki wrote eight months ago, stagnation is almost certain. He meant if we do nothing. And stagnation is slow motion failure. If you're not climbing, you're sliding. and the rest of the industry has really come along and figured this out. Every so often you see a memo that shapes the rest of the industry. And I do think the Red Queen memo is one of those we're going to look back on in 10 years and realize this kicked off a new arc in talent restructuring that we're all living with. And I am anticipating we will continue to see roles changing, roles dissolving, shifts in how junior talent is treated, shifts in how we define responsibilities and expectation of AI fluency as a baseline, dramatic polarization of compensation. These are all things that were predictable coming out of Toby's note in early 2025. And what we're seeing in 2026 is the volume is at 11 and this is happening faster and faster and faster. And so this affects all of us. anyone who's looking for a role, anyone who's in a current job, just know that you're not alone. Know that the company is not alone. Everyone's going through this process together. And there are tools out there to help you to scale up. In fact, most of my videos are about that. So, as much as I wanted to take you through the larger picture, understand I don't want to leave you without that tidbit. If you are looking for guidance and structure and training guides, I do a lot of them. I put them here uh on in video form. I also put them on the Substack and writing form. This is the biggest training event in all of our lifetimes. And so it's not it's not about me. You don't have to listen to me. You can go find somebody else if you want. That's totally fine. That's great. There's a lot of other great AI creators out there. Just find people who can help you skill up and start practicing. That's the most important thing you can do. Cheers.
