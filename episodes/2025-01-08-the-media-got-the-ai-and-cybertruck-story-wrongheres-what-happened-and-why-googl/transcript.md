---
title: "The Media got the AI and Cybertruck Story Wrong—Here's What Happened and Why Google Should Worry"
video_id: "aqiAlXWs4Uc"
youtube_url: "https://www.youtube.com/watch?v=aqiAlXWs4Uc"
substack_url: null
publish_date: "2025-01-08"
duration: "6:26"
duration_seconds: 386
view_count: 2215
author: "AI News & Strategy Daily | Nate B Jones"

yt_tags:
  []



# AI-enriched metadata
content_type: "News Roundup"
primary_topic: "AI Strategy"
difficulty: "Intermediate"
audience:
  - "Engineers"
  - "Executives"
entities:
  companies:
    - "Google"
  people:
    []
  products:
    - "Make"
  models:
    []
concepts:
  []
summary:
  []
keywords:
  - "ai-news"
  - "coding"
  - "frameworks"
  - "google"
  - "leadership"
  - "make"
---

# The Media got the AI and Cybertruck Story Wrong—Here's What Happened and Why Google Should Worry

so this obviously got my attention and I want to talk about it because I think there's some things that people who know AI will call out that the media is not AI is reported in about half a dozen headlines as of yesterday evening as being a factor in the planning of the Cyber truck explosion that took place in Las Vegas on New Year's Day so this is a case where if you didn't read the headlines a active duty the military officer exploded his cyber truck in Las Vegas he was the only casualty and for whatever reason the sheriff decided to focus on AI as a factor in planning the explosion and I'm not going to repeat the queries here but I went and looked at the queries that are publicly available and something stood out to me that nobody in the media is talking about because it was very very obvious from a tech perspective what was going on this person was not socially engineering the AI to answer his technical questions about the explosion which concerns me this person was also not asking long questions to chat GPT it was Chad GPT these were Google searches effectively asked to chat GPT like if you look at these uh strings they're effectively the length of a typical Google search they're the content of a typical Google search we would call them um just uh domain completeness answers like hey I don't I understand about this I don't understand the specific aspect can Google go find it for me where is this thing what what is this thing's relation ship to this thing and if those were on Google I guarantee you we would not be talking about Google as a factor in the cybertruck explosion because Google has been around for 20 years at this point it's not news to hear that people Google everybody Googles but if you're looking for something Sensational you can say as the sheriff chat GPT helped with this it's like it really says more about behavior for search shifting to cat GPT and the erosion of Google search dominance then it says about something that is unique to large language models because the answers that we're being asked for by and large are things that Google search would also give you these are not like specifically large language model related queries llms excel at long complex queries they excel at providing lengthy text responses none of that was needed here these were very short like six-word queries with short answers and I think what's interesting is even for someone who was outside the tech Community as this person was it was easier to use chat GPT for that than search that is the real story it was easier to use chat GPT the answers were more useful than search and for people who worry about hallucinations I got to say that this is the the best evidence I've seen that hallucinations are not a factor with Chad GPT anymore if you're using them for tasks like this which by the way if you run across these queries on the internet which you can find relatively easily I highly suggest you do not repeat them into jet GPT they're known they will be locked down cat gpt's team will be keeping an eye out for similar queries do not do that don't do it but but the point here is that at the end of the day chat GPT became a way to get ordinary information in little bits and pieces it was not a full one full query for an entire like complete answer to everything he asked for it was little bits and pieces just like we would use on Google it was just more useful it was easier to read there were no search ads the answer was right in front of you it's the worst kind of ad for chat GPT but it does show the utility so you can let me know in the comment what you thought but to me nobody in the media is talking about the fact that this is effectively Google replacement Behavior but we're using a double standard we're saying AI helped when really Google search behavior is eroding and we're actually seeing that behavior shift because this kind of answer is more useful it's just a direct answer it's like a sentence back which is more useful than just scanning through a page of search results that's the story that's the story it's not that AI has magic powers that helped because the queries don't require the kind of magic powers the long large complex responses that AI is good at it's it's a tragedy it's not that we we ever want to have the answer of AI helped with anything it's not like I'm saying now that makes it better it it doesn't make it better it's terrible that it happened we clearly need better safeguards there was no social engineering going on here and I think part of it was that these were bit bits and pieces queries and like right now I don't think the guard rails are very good for bits and pieces queries that aren't like a full complex query that shows malicious intent and that needs to change and I think that's something that open AI is working on other other labs are working on too but at the end of the day it's not about AI the way the media is portraying it and that needs to be called out cheers
