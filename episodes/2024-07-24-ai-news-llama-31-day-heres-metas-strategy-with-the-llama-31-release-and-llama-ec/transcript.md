---
title: "AI News: Llama 3.1 Day! Here's Meta's strategy with the Llama 3.1 release and Llama ecosystem"
video_id: "rksBKKzAiOU"
youtube_url: "https://www.youtube.com/watch?v=rksBKKzAiOU"
substack_url: null
publish_date: "2024-07-24"
duration: "11:38"
duration_seconds: 698
view_count: 269
author: "AI News & Strategy Daily | Nate B Jones"

yt_tags:
  []



# AI-enriched metadata
content_type: "Framework"
primary_topic: "AI News"
difficulty: "Intermediate"
audience:
  - "Engineers"
  - "Executives"
  - "Product Managers"
  - "Founders"
entities:
  companies:
    - "Anthropic"
    - "Google"
    - "Meta"
    - "Microsoft"
    - "Amazon"
    - "Apple"
    - "Salesforce"
    - "Azure"
  people:
    - "Mark Zuckerberg"
  products:
    - "Make"
  models:
    - "Llama"
    - "Llama 3"
    - "Llama 3.1"
    - "SAM"
concepts:
  []
summary:
  []
keywords:
  - "ai-news"
  - "ai-strategy"
  - "ai-tools"
  - "amazon"
  - "anthropic"
  - "apple"
  - "azure"
  - "frameworks"
  - "google"
  - "leadership"
  - "make"
  - "meta"
  - "microsoft"
  - "prompting"
  - "salesforce"
  - "startups"
---

# AI News: Llama 3.1 Day! Here's Meta's strategy with the Llama 3.1 release and Llama ecosystem

So Yesterday July 23rd meta released the first open weights model that's at the frontier that we've ever had and I'm going to explain what that means so large language models are fundamentally either Frontier models or not and Frontier models are Cutting Edge it's what it sounds like it's on the edge of innovation they're the largest models they have the best context Windows now an open weight model is something where you're not trying to hide the secret sauce or the recipe that enables you to generate a token when someone gives you a prompt as I I've talked about on this channel before and many others have discussed large language models are fundamentally about token prediction so when they're they're sentence completers when you give them an utterance when you give them inputs as you enter questions or statements into the chatbot they are going to then predict the correct response from their training data set and the way they do that the recipe they use to do that to select the exact next token has to do with waiting you're waiting the model's ability to choose a particular token from the vast array of possible options that derive from the training set and so weights are sort of like a recipe it's like saying we're going to take three eggs for the omelet instead of two and what happened was everyone else anthropic and open Ai and everyone else in the game basically has said we don't want to release the recipe here's the omelet we're not telling you how many eggs are in The Omelette we're not telling you whether we added a dash of cumin we're just going to cook The Omelette serve it to you and say please enjoy The Omelette and meta's not saying that meta is saying no here's the whole recipe and you can build your own omelette right open your own restaurant and what's interesting is not only is this as good as the Frontier Model so there's really no quality degradation in using an open source model it's also something that meta is explicitly committed to maintaining so Mark Zuckerberg the founder of Facebook that's now meta has said he wants to build an ecosystem he wants an ecosystem built around open large language models because he thinks that's what best for Facebook and that's what's best for Society at large long term that is a huge philosophical difference and how that debate plays out how the debate between Mark Zuckerberg and Sam Alman plays out over time is going to shape our future fundamentally if you are in the open AI Camp you think that large language models should be closed and they should be something where the exact weights are not revealed there are people who who argue there are security implications to revealing the open weights because these models are so powerful on the other hand if you're Mark you say no that's actually not how it works I want to have an open ecosystem where everyone can build software because I think we all benefit from that and that includes meta by the way meta will benefit he thinks if everyone is building in the same ecosystem and if meta controls that ecosystem even if the weights are open meta still drives and anchors that ecosystem and enables utility across Facebook with that ecosystem and ends up becoming an anchor in the space the way Apple has become an anchor in the Mac hardware space like everyone can build uh apps for iPhone everyone can build apps for Mac but Mac still runs and drives a lot of value out of that ecosystem so I want to think about that right I want to talk about takeaways we can have in a world where you have a Frontier Model that actually has open weights I think there's a few here number one models and intelligence are a commodity the fact that this exists at all means that intelligence costs are going to keep coming down now what that means is that the people who are putting a lot of money into training the Next Generation model are going to need to find other ways to recoup their investment if it just keeps getting cheaper to use these models because the Frontier Model is free you're going to have to find other use cases that you can monetize that are based on intelligence to get return on investment for the billions and billions and billions of dollars you're spending and that's a great question for Microsoft CTO this morning I'm not sure how they're going to answer it but that's a long-term question is basically if you have closed models you have to monetize them if you have open models long term you want to monetize them but you believe you have a play there why is it different why is the monetization strategy between Microsoft and meta so distinct at the end of the day meta does not make money off of cloud it's one of the only major players that doesn't it makes money off the attention and eyeballs of consumers it does not make money when someone purchases cloud services Microsoft makes money off Azure when that happens Google has a cloud product Amazon has a cloud product and when you have a cloud product what you're incentivizing is consumption in the cloud you want people to move to the cloud you want people to use your AI services in the cloud it makes a lot of sense for Microsoft if people are using open AI services in the Azure cloud and that's what they would like you to do and they're building to that effect and so part of the monetization play that they want you to have as an Enterprise is they want you to think the closed models more secure the closed models on a cloud install and I actually don't think that's a terrible play even in a world where we have freely available Frontier open white models corporations may still want the security and Sh that comes from having another Corporation committed to providing a secure environment for computing that by itself may be the monetization play but if that's the case fundamentally it means that compute and Cloud are continuing to be what these big players are selling and AI is just a use case that gets you to use more compute whereas for meta what they're work really working on is how do we build an ecosystem where we can build the kinds of apps that we want to build where others can build the kinds of apps they want to build and ultimately we can get an AI driven future that has meta at the heart of it and so it's about attention look I'm not a future prognosticator I'm not saying which one is going to win because I don't think anybody knows and I think the future probably looks like both but I think for individual people or entrepreneurs who are building in this space there are some takeaways that we can derive and I think the first is if intelligence is getting cheaper then cheap software is going to become the norm so we used to be in a space where like when Mark benof founded sales force it took a lot to compete with what he built because it took took many many developers to build the equivalent of Salesforce at the time that's not true anymore it is really really easy to replicate software with minimal developers it's getting easier all the time and that's partly because the expertise to build that software has spread widely across a widening pool of engineering talent and it's also partly because large language models have really accelerated coding there are stories that are proliferating across the internet of individuals who hadn't coded before or coded just a little bit who have now built fully functioning apps that is happening now it may not be Enterprise grade apps but there are apps that they can sell and it's happening now it will happen more in the future software is going to get really really cheap to build that means unprecedented opportunity to build but it also means unprecedented availability of software so it's going to be noisier and noisier in the space and so what that means is that distribution and utility are what's going to matter most at the end of the day if you have the ability to distribute your software if you have the ability to drive usage with that software because of where you're positioned in the ecosystem you have a play that nobody else has you have an ace up your sleeve that people who are just building the software without the distribution Advantage don't don't have now second time Founders have done this for a really long time that distribution beats everything having the ability to move the product beats everything it's just going to be more true now because it's so easy and cheap to build software that you're going to have competitors you don't even have to Google for them they're everywhere you can assume that the work that you put in to build a particular feature will be copied really really fast and so what sustains you is your distribution advantage and that brings me to sort of the last point I want to make here the thing that we are missing in AI today and the thing that meta is trying to build with llama 3.1 is building where everyone wants to be now for llama that's a play for an ecosystem they want to build an ecosystem where Builders want to be for others who are founding or building in the AI space it's about building what people want to use it's about building where people want to be spending their time one of the things that distinguished Instagram during the 2010's explosion in software is that they built a product where people wanted to be people wanted to scroll there people wanted to create there and we don't really have that equivalent in the consumer application space and I would argue we also don't have it in the B2B space for AI there is a big opportunity for a suite of applications for business There's an opportunity for new consumer applications that basically build where people want to spend their time and that requires using the ease with which we can build AI to build polished delightful experiences where people really want to spend their time I do think that the value of Polish is going to continue to go up and that comes back to sort of this idea that linear has championed in the last year or so where they really Advocate that software in the 2020s is about polish because a lot of the other spaces in the market have been taken the MVP idea may be going way because it's simply so cheap to produce much better software than an MVP we will see but all of this all of these conclusions around intelligence flattening around software getting cheaper to build around distribution around how we build delightful experiences where people want to be that shakes out of Mark Zuckerberg's commitment to open-source Frontier weight models so it was a huge day yesterday for llama 31's release it's absolutely massive so we won't really see it play out for a few months but that's the direction we're all headed and it's going to be very interesting to watch Good Luck building
