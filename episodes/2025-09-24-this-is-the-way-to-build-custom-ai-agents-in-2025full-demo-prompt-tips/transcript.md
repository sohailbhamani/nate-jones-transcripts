---
title: "This is THE Way to Build Custom AI Agents in 2025—Full Demo + Prompt Tips"
video_id: "BP-N7xjz-vM"
youtube_url: "https://www.youtube.com/watch?v=BP-N7xjz-vM"
substack_url: null
publish_date: "2025-09-24"
duration: "22:11"
duration_seconds: 1331
view_count: 8687
author: "AI News & Strategy Daily | Nate B Jones"

yt_tags:
  - "AI strategy"
  - "AI agents"
  - "prompt engineering"
  - "automation at work"
  - "future of work"
  - "LLMs"
  - "GPT-5"
  - "Claude"
  - "Anthropic"
  - "OpenAI"
  - "Notion AI"
  - "Model Context Protocol"
  - "custom connectors"
  - "product management tools"
  - "meeting notes automation"
  - "PRD backlog"
  - "interview coach"
  - "AI artifacts"
  - "AI jobs for teams"
  - "AI strategy for operators"



# AI-enriched metadata
content_type: "News Roundup"
primary_topic: "AI Agents"
difficulty: "Intermediate"
audience:
  - "Engineers"
  - "Executives"
  - "Product Managers"
entities:
  companies:
    - "OpenAI"
    - "Anthropic"
    - "Google"
    - "Amazon"
    - "Notion"
    - "GitHub"
    - "Box"
    - "Perplexity"
  people:
    []
  products:
    - "Claude"
    - "Perplexity"
    - "Notion AI"
    - "Make"
    - "MCP"
    - "Model Context Protocol"
    - "Artifacts"
    - "Projects"
  models:
    []
concepts:
  []
summary:
  - "# This is THE Way to Build Custom AI Agents in 2025—Full Demo + Prompt Tips

I'm here to tell you about the very very easiest custom AI agent automation software out there today"
keywords:
  - "ai-agents"
  - "ai-news"
  - "ai-tools"
  - "amazon"
  - "anthropic"
  - "artifacts"
  - "box"
  - "career"
  - "claude"
  - "coding"
  - "frameworks"
  - "github"
  - "google"
  - "leadership"
  - "make"
  - "mcp"
  - "model-context-protocol"
  - "notion"
  - "notion-ai"
  - "openai"
  - "perplexity"
  - "product-management"
  - "projects"
  - "prompting"
  - "tutorials"
  - "workflows"
---

# This is THE Way to Build Custom AI Agents in 2025—Full Demo + Prompt Tips

I'm here to tell you about the very very easiest custom AI agent automation software out there today. And not a lot of people are talking about it as if that's what it is, but that's what it really is. And we're going to talk about it. It's Notion AI. They just released this week. And the reason why I'm calling it custom AI agents is because of the way Notion has been able to marry together databases and custom connectors to other tools that you use throughout your daily life. and also of course the power of AI. So we're going to do this in a couple of sections in this video. Number one, I want to tell you what notion released. Number two, I want to give you my live actual notes using it, including things that don't work well and things that do work well, tips for prompting, all that stuff. And number three, I want to actually show you what Notion can do with specific examples. And so we're going to get into Notion as an interview coach. We're going to get into notion uh getting your meeting notes into a product requirement document into a backlog. We're going to get into notion helping you with your prompts as a prompt evaluation harness. There's a lot of really cool stuff in here and it underscores how flexible this tool is, which is why I'm calling it a custom AI agent builder, even though spoiler alert, Notion did not call it that. Okay, so what's in the box? What did Notion claim that they released? So what notion called this is really an AI powered agentic future. They talked about it really as AI agents across your notion portfolio rather than AI agents powering your whole workflow. And I think that there's a really big difference there. What they want you to see is that notion's AI agents can perform autonomous work across multiple steps. They claim up to 20 minutes. When I was testing it, I got five or 10 minutes pretty easily. and they are adding tools to make that more useful. So it's not just notion. So they're trying to add other connectors as well including Google Drive, including Gmail, including your linear, including the GitHub tool stack, including a bunch of others. It's like they're trying to add as many tools as they can. They also say very shortly they're going to give you the ability to have customizable agents that act like teammates and take specific work flows for specific projects across departments. So imagine you want to always take a contract from sales and move that contract into technical requirements for your engineering team. They're trying to build custom agents to solve for that use case. And of course notion benefits because you're pulling more of your data into notion. And in fact, this is a really interesting value proposition because when you hit their landing page, what they say is that notion saves you money. You want to spend your money here because notion saves you money on a bunch of other things. That has been one of their larger value props in the age of AI. And I think it's going to resonate because everybody knows that you're not going to pay 100 bucks here and 100 bucks there and 200 bucks the other place just for AI. You want a single home and notion is trying to be that home by making your data at home in notion with AI. We shall see. But I want to show you some use cases that make it pretty tempting. One of the things that they have enabled AI to do that I think we don't really easily see other places is granular database row permissions. So notion now has page level permissions for databases. And so you can actually have notion AI make granular uh database controls and database changes per row. So, for example, if you are trying to do cold outreach to a contact for a B2B business, you can have Notion look at the response in Gmail, look at meeting notes in a transcript, and then come back and update a database row in Notion in your CRM. That helps you understand where that prospect is at in their journey, and maybe you move them along in the sales pipeline. That's the kind of thing that they're envisioning and it does work well for that. They are also strongly advocating a universe of model context protocol connectors. And so remember how I've talked in the past about MCP as sort of something anthropic seedated into the ecosystem and engineers have now picked up and used across all of AI. That is true at notion as well. Notion is using MCP servers and bragging about it and they are implying quick scale as a result. They want to add more MCP connectors. I would strongly expect a 3.1 or 3.2 2 release to allow businesses to add custom connectors with their own MCPs to pull in yet more data because that's very much what Notion wants to do. If you centralize more data here, you'll be stickier. You'll use our AI. You'll pay. You'll stay. Let's get into the actual experience that I had in part two of this video. What did it actually look like? Did it actually work? So, spoiler alert, it worked, but it is more prompt dependent than I think you or I would want. And so, I tried multiple ways of prompting the system. I tried the more casual just make it where it was like a one or twoline pass and I was like, just make a database for this. It did not work as well. The ability of the system to understand what I wanted seems to be somewhat dependent on really strongly typed prompting or really strongly structured prompting. I came up with eight prompting rules as I ran through these experiments that I want to share with you here that I think are highly correlated to successful notion prompting. And I'm going to go a little bit farther. Even if you're not in Notion, these are going to be useful prompting tips for a future where we are building digital artifacts with AI. I talked in a previous post about this idea that work is changing. We are going from a world of work where we handwrote our artifacts like docs to a world where artifacts are more interactive where we can sort of produce something and we can interact with it like an applet or we can ask people to contribute or maybe automatic actions are taken. Notion is really at the forefront of this trend especially with the idea that agents can take action against a page and update database rows as it goes and I'll sort of show you how that works. But to do that you have to apply these prompting principles. Number one, be really clear about where you want this tool to work. You need to say work only on this page and its subpages or something like that because you don't want notion to be broadly scoped and surpriseed elsewhere because that is equivalent in many people's notion wikis to an unwanted code change. You don't want that. So specify where it works. Number two, tell it what done looks like. Ask for a receipt at the end. it will listen and say, "When finished, please add a line at the bottom of the page, either okay or if you're blocked, add blocked and a reason why." This will let you know right away in the page text itself what it did and why. And so getting receipts helps you to be more auditable and to track what actually happened. I've actually developed a prompt that shows audit logs of previous runs right on the page itself, which I think is important if you're starting to make serious changes. And I'll show you sort of how that works. Number three, you want to be thinking in terms of tables and databases rather than text. If you're creating things in databases in Notion, you're leaning into Notion's strengths. You're leaning into the strengths of a lot of compute. Frankly, a lot of other systems depend on databases, too. Tables are much easier to sort, to operate against, to review, to fix later, to adjust. Whereas raw text can be difficult to format and engage with. I did try both with notion. I really felt like a tables first approach was much more useful for the kind of tasks I was doing and I think that this is something that we're going to see change the way artifacts are formatted. I'm used to a world out of Amazon with product requirement documents that were narratives and yes you have some tables but you also have a lot of narrative about the customer experience. We are moving to a world that is videoheavy and that also has tables. And it's a really interesting change for someone who came up sort of before all of that happened in the traditional six-pager era. But here we are. Make tables first, text second. Principle number four, you need to use quality checks. One of the things that you will really thank yourself for is if you are explicit with the agent about the conditions under which it can mark a task accomplished or done. So you can have it check the length of a particular piece of text. Is it 180 tokens? Right? Is it 180 letters? You can have it check if it includes every piece of data that's relevant for the task. So if you're writing a cover letter and you tell notion to do that, which by the way it can have it include the company and the role. That seems like a reasonable requirement. If you are writing a justification for why you should work somewhere, make sure it includes at least one number from your resume. And you can give it the resume and it will do that. And the specificity that you can use here around quality checks is something that people forget about, but it's a critical part of learning to work with agents. They need that degree of clarity in order to know they did a good job for you. Otherwise, they'll just guess and they may hallucinate or they may not do anything at all or they may default to token efficiency and do less than expected. So use quality checks and also be really clear what the model should do if it doesn't have that item. And so you can write if info is missing please insert TK confirm which is a traditional editorial slogan. Or you can pick whatever you want. You can say insert in brackets please check this and ask you for it and it will do that. This helps the model not just depend on vibes but actually get to a past fail mindset. Principle number five don't create duplicates. If something similar already exists, you want the model to update it instead of creating new copy and dirtying up your context window because you're starting to think of notion and really we're starting to think of agentic tools as context windows themselves. Like even if you can't absorb all of it in the context window, notion itself is becoming a place where you always have that in mind because of the way AI operates on it. And if it's a context window, it needs to be clean, which means you don't want duplicates. And so you can actually specify when you touch a page, if you updated it, please include a little table where it has version and last run to describe your edit and describe the last time you touched it. This enables you to see what happened and see how pages changed. It's one of the things that's going to be increasingly important as humans and agents work together in wikileike environments. Number six, I want you to create a run log. I want you to think about each change you're making as if it's something that needs to be undone. One of the hallmarks of good agent architectures is the ability to hit undo. And I appreciate that notion has put a literal undo button in the chat interface. I haven't seen that a lot. I think people are going to appreciate that. But if you print a tiny run log, it's going to help you to go farther. And so you can stick that into the prompt. It's one of those things that sort of extends the idea of a page update note into a full run log that actually has links to what happened, warnings for when things go wrong, etc. The more you invest on the validation and audit side, the more you can keep your context window happy. And by the way, if you think this is overkill, this is just not so hard if you have the right prompt. like I did not actually have to suffer that hard creating the pages I made because I was able to work with chat GPT5 in thinking mode to create the prompts. And so I'm going to go through the sort of some of the sort of conversations, the prompts, what I got. You'll get the idea. You'll get how I was able to use these eight principles without too much blood, sweat, and tears on my part. Principle number seven, write in really plain strict language. So, say create six questions instead of create a few questions. Use one metric instead of use a metric. Please, wherever you can, you want to avoid open-ended phrases that will encourage the model to hallucinate unless you are happy with hallucination. So, as an example, be inspiring is not a helpful frame for a cover letter. Asking it for a specific metric, asking it to include the name and the company, asking it to include a specific reason from your resume. This ensures the agent stays consistent. So write as plainly and strictly as you can. And GPT5 is actually very helpful in this. You're working with its default language preferences. Principle number eight, please don't let it make things up. I know I said unless you want hallucination, but really wherever you can, you want to be underlining to the model. If you cannot find a claim in the input data that I give you, please use check this and do not mark it as done and come back to me because you don't want to get into a situation where you're making up dirty data and then the model is basing future actions on that dirty data. So with that in mind, let's put it all together and let's first look at a sample prompt in GPT5 that helps us understand how notion works and then look at some notion pages that I was able to create with that kind of a okay here we are. We have obviously the role you are a notion agent you want to specify and limit the page and the subpages here and you want to make it clear what done looks like. This is where I include showing receipts. what I where I include showing what blocked is and why. You also want to make sure that you define the scope. I do not want it touching things that were sort of created or edited a long time ago. Again, I'm trying to keep this context window as clean as possible. Um, please do not overwrite unless you are updating a newer version. And so, it's very precise about when overwrites happen and why. Uh, this is a table and I give it the choice to create or not. So, I could have this table already here or not. If it's not here, I tell it to create it. And I'm literally giving it the columns and I'm showing it what I want and what the format is of each column. It's very specific. Name, which is a title. You have notes, which are text, a version, which is a number, etc. Then I get to the tasks the model should do. Find up to five items that need work. You can see we're starting to build a to-do list here. For each item, draft the content in the table fields. Run quality checks. See below. And you tell it to look down. If all the checks pass, set the status to ready. If the checks fail, set the status to needs fixed. Quality checks then include length is within limits, company enroll if relevant, at least one number, avoids banned words, if info is missing, insert. By the way, avoids banned words will help you. If you are writing for a quote unquote AI detecting uh tool, like there are some tools now that companies use that others use that claim to detect AI wording. you can pretty easily game them if you come up with a list of words that AI tends to use like delve and make sure that it doesn't right and so there's ways you can start to even game the writing style here. Then it gets into duplicates and versions how you handle update what the requirement is. It's last 10 minutes in this case. Uh it gives me a version number and then finally please add a row in the run log with the times and the items changed and the warnings. And so as complicated as those eight principles sounded, I got all of that fixed into about a 20line prompt and it's relatively easy to run. Let's see what it looks like in practice on a few actual pages. All right, here we are. We are looking at the meeting notes to PRD backlog. I constructed this in just a couple of minutes. As long as you have the data, you can do that, too. Uh you might be wondering, how did I do this? This looks really complicated. There's multiple tables here. They scroll along. You can see that these tables have statuses that have now changed. You have PRDs. If I click the PRD, I'm actually going to see a real page here. So, let me just click that. Um, and I can click it and kind of look in and see where the PRD is. Oh, here we go. Um, so it gives me an acceptance test, a goal, a problem. It's actually writing the PRD as a table, which is really cool because then it can do operations against individual components of that PRD. This is a great example actually of an artifact that is created to be agent readable first and human readable second because it's very easy for me to look and say what is the what is the TLDDR of notion agents reliability and I can get a nice summary from notion. Um and so if I go here and if I like copy and paste this um let me just pull up the actual notion you can see where I actually did this. uh please give me a 20word summary of this PRD and it will just come back and it will work on on doing that as we chat here it's looking at it thinking about it and there you go that's what's in the box uh what is the highest risk element of this build right I can actually then start to inquire into how it works and so that's one of the powerful things here right like you can start to actually ask it to exercise judgment ask it to think through is talking about schema drift here you may or may not agree But the point is you can have that conversation with it very easily. Now if we go down here, it can actually go and automatically fill out to-dos associated with these PRDs. And so these are all associated with particular PRDS. And these are basically to-dos for the data team, for the email team, the backend team, all automatically created. All I did to add to this was to input some data from meetings. And you can actually even automate that because notion now has meeting notes that you can take by audio. And so I'll share the the original prompt that I got for this um and you can sort of see how you can make it your own. But it illustrates to me that it's increasingly possible to move from a world where you consider these artifacts as static to one where they are truly dynamic and you can actually like evaluate how the overall projects break out in a matter of a couple of minutes rather than a couple of days or even longer. I remember when I was doing PRD work as a product person, what I'm showing you here would take days. It took about 2 minutes and I think that's really compelling. Let me show you another cool example that I found. So, this is the notion interview coach. It may not look like a lot, but it gives you a rubric and it gives you everything you need to actually run your own notion interview scorecard. And so this is actually it's simulated data, but what you see here is an entire database where it can take a notes transcript. Let's say you interview yourself and you're practicing your answers. It can take a notes transcript with questions, feedback, interviews, and it can put it into a database like this and it can actually run against a rubric for clarity, impact, specific specificity, structure, whatever you want. score it and deliver an overall scorecard to you of how you did. Um, and I think that's really cool. It was relatively easy to spin up. There's a lot more we could do, but it shows you that you can actually build an entire system with multiple databases off of a single prompt and start to actually work to populate it with real data and get it going from there. Let me show you one more and I think you'll find that really sort of an overall picture of what notion can do. My goal here is not to give you the complete picture of notion because I don't think I can do that. I want to give you a sense of how I think notion undersold this. This is actually an agentic artifacts factory. There's a lot more to this and I think that with proper prompting you can go a long way. So let's do one more. So this is a prompt and eval harness. This is going to be more technical and you can actually look at particular experiments that were run. You can look at a uh date for those experiments. You can look at inputs. You can look at versioning essentially. And then you can look at results that were scored pass or fail based on a rubric, right? Um and you can get into eval rules. What must the prompt include? Did the prompt work? Did it not work? A run log on updates. Um, at the end of the day, I think what you should be taking away from this is that you can do things as nerdy as self-improving your notion prompts by using Notion AI. You can do things as detailed as getting into particular prompt structures for different tools, say your perplexity prompts, your OpenAI prompts, your Claude prompts, and start to track them in a thoughtful way in a database. I've been, you know, told by a lot of people that they are looking for great prompt tooling. And there's lots of answers to that question depending on your workflow. But one of the answers is notion. One of the answers is actually building out a prompt database in notion. And I'll share this prompt in the in the post and starting to track and score how your prompts do. Now, if you're one of those people who says, "I don't care about prompts." That's fine. But you're probably going to be getting better results if you take your prompts this seriously and actually start to score them. And of course you can adjust them to score how you want. This is just a sample score. Uh and you can see how the sample score works. Um yeah, so this is one of those things that I think is getting slept on and I'm sharing about notion because I think that we need to get past an assumption that work is a series of individual things that we create with the help of AI and we need to move to a to an idea of an agentpowered work factory where the agents are processing through these artifacts often autonomously and it's our job to prepare the environment and to shape the direction for these agents. And that sounds super fancy and it sounds like a big company thing, but Notion is making that possible for anybody. Notion is making that possible at a price of like 20 bucks a month. Like it it's really very affordable to have this kind of a thing. And I think that's really really cool. And so I hope you've enjoyed this breakdown of notion. I hope you see why I think it's really interesting. We are headed to this future where agents are powering artifacts. I hope these prompts that I'm going to share are helpful to you as well. Cheers.
