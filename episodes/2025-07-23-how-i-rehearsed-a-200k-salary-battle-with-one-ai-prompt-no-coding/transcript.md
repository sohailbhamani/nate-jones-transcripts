---
title: "How I Rehearsed a $200K Salary Battle with One AI Prompt (No Coding)"
video_id: "pebgrFQ-C7M"
youtube_url: "https://www.youtube.com/watch?v=pebgrFQ-C7M"
substack_url: null
publish_date: "2025-07-23"
duration: "26:41"
duration_seconds: 1601
view_count: 7621
author: "AI News & Strategy Daily | Nate B Jones"

yt_tags:
  []



# AI-enriched metadata
content_type: "Tutorial"
primary_topic: "Prompting"
difficulty: "Intermediate"
audience:
  - "Engineers"
  - "Executives"
  - "Product Managers"
entities:
  companies:
    - "Perplexity"
  people:
    []
  products:
    - "Perplexity"
    - "Make"
  models:
    []
concepts:
  []
summary:
  - "# How I Rehearsed a $200K Salary Battle with One AI Prompt (No Coding)

You know, a few days ago I did an entire piece on setting up digital twins"
keywords:
  - "ai-news"
  - "ai-strategy"
  - "career"
  - "coding"
  - "frameworks"
  - "make"
  - "perplexity"
  - "product-management"
  - "prompting"
  - "tutorials"
  - "workflows"
---

# How I Rehearsed a $200K Salary Battle with One AI Prompt (No Coding)

You know, a few days ago I did an entire piece on setting up digital twins. It was very large. I think I wrote a hundred some page guide for it. The point is people took it and said, "This looks really hard. You wrote all these pages for it. Help me figure out how to do it simply. I don't have an enterprise setup. I'm not making robots learn to walk in a warehouse. This is not a Fortune 500 company. I want to use digital twins without having to write code." And I took that as a personal challenge. And so what we are going to work through today is an actual prompt to set up your own digital twin simulation. We have a couple of goals as we work through this prompt. We want to understand first how the prompt functions. It's another one of those system level prompts. So it actually walks through an entire process or flow. It creates a scenario and then it walks you directly through it all in one prompt. And we'll see how it works. The second thing I want to do is I want to show you some of how it works with actual real conversations that I had using that prompt and we'll walk through them. You'll get both a salary negotiation conversation because sometimes they want to game those in advance and you'll also get a classic like product approval conversation to give you a sense of office politics and how it simulates office politics. It's interesting to see how different models affect this simulation. And for just one more wrinkle, I'm going to give you a sense of how chat GPT40 compares to chat GPT 03 handling this prompt and running the simulation. This is actually one of the clearest examples I've seen of the practical realworld differences between those two models. So with that, let's get to the prompt. Okay, here we have the digital twin stakeholder prompt that I constructed. I helpfully named it V2 because it took multiple iterations to get this prompt working and I want to walk through how it functions. As before, I am running this in the web browser comet with the handy assistant pulled up. I had a few questions when I did this last time. So, just so you know, this is the Perplexity web browser and that's an AI assistant that Perplexity launches with the browser. I find it useful. I did a write up on it. Uh, and I find it really helpful in situations like this where I'm trying to understand what is going on with a complicated page. So, as you can see, the prompt as a whole is quite large. I will just scroll to the end of the prompt and you'll sort of start to see, wow, there's a lot here. So, let's get into it piece by piece. First, we set the role. This is not surprising. I think I've talked before about the idea that you're setting the role as a way of invoking a particular semantic space. And next, you define the mission. In this case, we have a four-part mission. This is part of why you'll see better performance out of 03 than 40 when we get later into this video. Number one, get the information out of me to figure out what what is needed for a realistic multistakeholder negotiation in my situation because this is not a specific prompt for compensation negotiation. It is a super prompt that actually helps you to set up whatever simulation you want to run. Second, ask only one question at a time. I find it so overwhelming when LLM's ask too many questions. So I I tend to include that. Third, confirm the answer. And then fourth, when the answers are gathered, and now we get into the heart of it. You need to generate a runnable simulation prompt that embeds every confirmed detail, contains inline data tables if the user has not provided external files, but you can, and includes clear output rules, and a begin delimter. And then five, write the prompt out as plain text and immediately transition into simulation mode. One of this was actually one of the reasons that I went to V2 is because I found when I was playing with this prompt and working with it, it is difficult to get the AI to reliably go from I'm learning about you and gathering information to okay, we've got the information. Now, it's time to actually run the simulation and be a digital twin. In this case, multiple digital twins. So far so good. And what's interesting is when you get to the the end of the prompt, it immediately invokes it immediately invokes the twins. And so we'll get down here and see what this means. But I want you to see the connection between five where we talk about what we want the twins to be and the end here where we talk about each twin's opening statement. And that's the way you begin. because this ties this ties the tokens back when the LLM is reading this prompt so that it knows okay we have to remain in character opening statements of every twin I see that back here it's like we're doing this memory management across a larger prompt and this is a great example of how that can work okay now the LLM at this point would still not have all that it needs to run so let's get to the question script because we need something that gets information out of you one at a time. The obvious first one, what situation are we negotiating? List the participants. None of these are super surprising. List the success metrics or how you characterize a win. What twin will you play? And by the way, this works even if you don't want to play a twin. So, if you just want to see the LLM game it out and read the script, you can say, "I won't play any of the twins. You're playing them all." And it will. How many turns before timeout? So, this is framed as a multi-turn conversation. And so you can say three, you can say six, you can say whatever number you want. Please provide key numbers or attach a file for deals or comp. Otherwise, give ballpark figures. If you're salary negotiating, it's obviously comp. But when I was doing it for my uh product sample that I'll show you in a moment, I ignored the comp part and it said deal. So I put in like deal data and like where our pipeline was at and all of that. These are all madeup numbers. Um, and I felt really free to add the data I wanted. I will also call out that this is a somewhat flexible user response prompt. It is designed to be a place where you can put a lot of information and you'll see in one of the sample chats how I'm able to pack in like 300 words of information which is really more than I designed the prompt to take and the prompt is able to handle that. Okay, constraints and policies that's always important in any negotiation and then your output preferences, transcript style, word limit, etc. So at that point uh I actually define a confirmation phrase. Now why do I define a confirmation phrase? Why do I say after the user answers each question, this is what you should say? Well, number one, I define a confirmation phrase because it is critical to actually understand what the user said to get this world building right. With a lot of prompts, if you write the prompt, you can do a second turn and kind of figure it out if you're trying to refine. But with a world building or digital twin kind of prompt, the world has to be right from the get-go. And so I need to make sure that it understands, right? And so I have it come back and actively listen and summarize on purpose. Okay, so it's actively listened. It's collected all the information. We now get to the runnable prompt template. When all the answers are confirmed, please fill the placeholders and output you are the digital twin negotiation arena host. So, in a sense, you might be wondering, why the heck is this here? Purpose, mode, instructions, reference. Haven't we been talking long enough? Why does this go on, Nate? Well, I'll tell you why it goes on. It goes on because we are trying to bake in some degree of consistency in this prompt and giving it a purpose, a mode, an effort level, which by the way, you can set differently. Like I set it at high, but if you want to change this prop before running and set it at low, you can. Uh you can also set the scenario and hardcode it here if you want or it will fill in the scenario for you based on your answers. It will then output all the rest of this based on your answers and the reference. And as it does this, it is literally encoding into the stream of conversation everything it needs to know to keep it going. This little piece here does the important job of acting as a conversational anchor. It acts as a conversational anchor so that the rest of the world building will work. Right? If you have ever tried to do digital twin stuff, you know that the personality is drifting can be a problem. This is part of how we control for that. Having this clear reiteration before we start. Finally, we begin insert each twins opening statement right after the delimiter. So that's the prompt. That is what we will run. That is what I will show you. Before we go further, I want to actually go down. I actually broke this out into principles that we can look at. Uh, and I also broke out takeaways. And so I want to spend a second looking at the takeaways and the principles and make sure you understand why I did what I did before I go to the actual examples. So principle number one, identity lockin. I want to make sure that it's a digital twin and I want to make sure I invoke that corner of latent space. It is a deterministic state machine which is a fancy way of saying I am deliberately creating a fixed numbered question script to gather input on a path. This turns an open-ended chat into something that is very repeatable and something where the uh process can be deliberately shifted for ease of use in learning about different future timelines. So, if you want to game out a timeline where you open with 210 for your comp or a timeline where you open with 180 or a timeline where you open with 150, you can do all of those things in separate chats and you get a really tight controlled uh simulation of how that conversation might unfold. Similarly, if you're doing a job interview, which you could use for this, you can game out in multiple different chats, what if I answered this way? and you can watch your other stakeholders respond and actually like game that through and think that through more easily. Humans are not great at simulating entire digital scenarios in our head with multiple stakeholders at high fidelity. That is what this prompt is designed to do. Progressive disclosure. We talked about asking one question at a time. Echo confirmation loop. Rephrase. Actively listen. Actively listen might have been a better way to put this. Explicit output contract. This is the contract that we described up here that sets the terms of the debate. It says here's your purpose, here's your mode, here's your effort, here's your instructions, here's your references, and here's your output. It's really important to be clear and explicit about that when you're doing digital twin work. Okay. And then we get to handoff embed all the requisite data inside the runnable block. This was one of the challenges I had and this is why we named this V2. It is hard to get all the data inside a runnable block, collect all of it, make it run inside the same prompt. One of the keys to getting it to do that is to be very very explicit about that reiteration of the contract and explicit in the questions about what you are gathering. And so if you look back here, we are being very explicit about what we want in this question setup here, these nine questions. And we are specifying it needs to be runnable and we are specifying it needs to begin now. We are not giving the model any choice. We are saying here's all the information and you must begin now. And that was very deliberate. Context switching invokes the model's opening moves very deliberately and we define what we expect for the first move which helps the model get into that space. We say right up here, we need you to make opening statements that because you could begin a lot of different ways, but we say opening statements because that enables the model to enter the simulation space in a predictable way. If you leave that blank, you are giving the model cart blanch to open any way it wants. And you don't want that for a predictable simulation builder. You actually want a little bit of predictability so you can start to insert variables and learn. Okay. From there we get into uh visual parsing and bounded variables. So users can set rounds, they can set word limits, users can um actually see what is going on easily because we're using those asy gutters like the delimiters. I don't want to say these are fantastic principles. Like don't make me tell you that begin now with special asy gutters is somehow going to be more magical than begin now. It's not. But it sure is easier to read. And if we're reading these large prompts like I've been describing, it is sometimes nice to have clean gutters and bulleted lists. Finally, there are error rules for failure modes. And part of the error rules I've already called out to you. Like if you go back up here, one of the hidden error uh rules is the confirmation phrase. If there is a problem, you are going to see it because it's going to come back and tell you because the user answer paraphrase is going to be correct. But there's other ones too like do not ask further setup questions after the honorable prompt is admitted. We are scoping down so it doesn't go forever. We are demanding that it remain in character. We want to ensure it retains the detail. We are demanding that it only asks one question at a time. We are giving it a lot of constraints. Okay. Now I want to finish by talking about the structure and starting with the system ro declaration is classic. Getting to the mission is the correct overall next step. And by the way, these are larger pro uh prompt structures that you can use in other prompts, not just for these super macro prompts, right? If you start with, hey, here's my system role to move you into latent space. Here's the mission that I have for you. Uh and then here's the content that I want you to engage with. In this case, it's the script. you're going to be in a good spot for a lot of different prompts. If you frame how you want the response to work, which is the confirmation phrase template in my case, but could be something totally different for a prompt of yours, it's going to be really, really helpful. And finally, if you specify a contract and how you begin, if you're trying to do a super prompt like this and you specify a runnable prompt contract at the end and you also specify how you want the model to begin, it increases the odds that your prompt is going to actually run successfully. Okay, we are going to skip the micro details that add delight. We've talked about the asy. We've talked about markdown. Aren't you glad I can make things pretty? Uh we will talk briefly about how these pieces reinforce one another. The fixed question order reinforces the deterministic state machine. The builder never deviates from the script and always gets the questions the same way. And you can treat it like an automaton in that regard. The only difference is the power of the LLM behind it, which is really interesting because you'll see in the examples how 03 versus 40 is different. If you are teaching this, and I know some folks that watch my videos teach my work to others, and that's fantastic. You want to remind people of the principle of progressive disclosure and the importance of template integrity. Be careful with your placeholders. Be careful with asking too much of the model in one go without those checks and balances that I showed you in the prompt, without asking it to reiterate the contract, without asking it to be specific in its summary as it comes back to you. We are giving the prompt the token scaffolding it needs to be successful. Finally, potential pitfalls. You want to make sure that you are giving it limits. And so that is one of the things that we did not go as explicit here that I find that the model tends to get to in practice, as we'll see. You want to not be overcommitting the model to responses it can't deliver. Another example that would have strengthened this prompt more that you might want to use if you add more files is to summarize key numbers in two to three lines to force the model to answer back on files because you don't want it to just skip over the file content. So there are little things that think of these is essentially tweaks you can make depending on what you're looking to accomplish. We've gone on long enough. Let's move to digital twin negotiation builder v2 using 03 and see how the conversation went. Here we are. I run the prompt just as you described. The situation we're negotiating is a product pitch LLM to SQL project. It understands it. It comes back. Here's who I'm pitching to. CEO, CTO, CFO, director, me and the CRO here. I I want approval to build the product and launch. That's my goal. I have been in these situations. I'm picking something I know well so I can assess the quality. Next question. Which twin will you play? I'm going to play me and be the director of product. Great. How many turns before timeout? Let's do three rounds cuz most CEOs don't tolerate more than that. And then I throw it a curveball. This was not planned for in the prompt. I throw it 300 words on my product and I say this is what I pitched them. Right? It's all about how amazing this imaginary product is. I I am okay with the numbers being made up because this is an example and this is my ask Q3 roll out request. Got it. Next question. Provide any key numbers and I basically say I could have said just stick with these numbers up here but I want to think about the deals in this case because I think that's going to matter for the simulation. Most most seuite conversations in a B2B SAS have to do with deals at some level. I say we're chasing million-dollar deals with enterprise clients. We've had a pipeline slowdown in the last 6 months. Okay, great. The key data we're pursuing is this. It reiterates. It asks me to talk about the different characters. And so this is me like you basically make up the characters you want. If you don't know, you have to infer and guess. I had fun making these up. These are fictional, but they're plausible, right? The CTO is worried about hitting the schedule. The director of engineering is somewhat hostile because he thinks we're we're missing on core product. The CFO, she's worried about close rates and pipeline. The CEO, he's a business guy. He believes in enterprise and he loves AI, but he doesn't know how it works. Like these are all very plausible and I need a promotion, right? Like because I I' I've definitely been in that spot. So there it is. And then it asks, "What are the open legal or approval issues?" Super simple. Uh there's an open legal issue around LLM and data privacy. There's also an open question around pricing for usage, which is a huge issue more broadly. Different video. It reiterates and I say, "Please generate a script style transcript. Set the limit for debrief at 500 words. Leave room to speak." Now it is going to reiterate the contract. This is a contract. It writes, it's all writing all of this and it begins with opening statements. Begin out round one now. And it does. So the CEO sets the terms. The CTO says in line with his character, it's viable, but I worry. Enterprise pro prospects ask. You get the idea. It's now my move. I respond. I say, listen, we have to do this because we are losing in the market. A strong AI feature can add sizzle, and if we combine it with uh the CRO's concerns around SOCK 2, we should unstick some deals. It then moves forward. I'm not going to read all of these in detail, don't worry. We get to the second round, we see that it's playing the roles correctly. I then start to negotiate. I say, "Listen, we shouldn't just look at new customers. We should look at existing expansion revenue. I'm starting to move forward. This is third round. I've got to finish up." The CRO basically says, "Okay, if we're talking about expansion revenue, maybe I can get on board." The CFO who's been worried about the money says, "Okay, that that unlocks that for me, etc." And at the end, it gives me a scorecard. It says, "I got a partial approval." It gives itself a scorecard for twin realism and it gives me a debrief. What did it hinge on? Where did the tension surface? How did it work? I think this is the most useful part of this whole exercise because if you want to game out different scenarios like for a job interview, you get debriefs on your performance like this. I think it's really cool. Next, let's actually go into the job search arena and let's look at a real example of compensation negotiation, the final stage of job search. Okay, we are back. I'm not going to rerun this prompt in more detail. You get the idea. We went through the different situations. We're negotiating compensation this time. Smaller group, head of HR, CPO, and me. Uh, the win is dollars. We want more of them. Uh, we have six rounds. And I give it uh my current offer. Uh, I'm totally making up these numbers, but they're not completely implausible. And it says it's got it. I give it personality. The CPO is a hard-bitten guy. HR wants to follow policy. I realize this sounds right out of central casting, but we're having fun. Okay. And I give it instructions. Again, all of this is necessary to set up the fidelity of the digital twins world. And so it then starts to print out what it's going to do. It prints out all of the stuff it's working with, all the stuff it knows so far. Begins round one. It gives opening statements based on what I've said, what the CPO said, what HR has said, and then it asks me to go from here. Essentially, they say no. And so I say, "Hey, this reflects the market average. Like, this is legit." And so they start to shift a little bit. They bring up finance and approvals as an issue. Uh HR is really concerned about it. It's my move. So I say, "Okay, I want to play with equity and bonus a little bit. What if I drop the comp down?" This is actually how a lot of comp negotiations go. But we don't get the chance to play them out. The exact reason we have digital twins is so that we can do stuff like this in a controlled environment because I could simulate this whole thing again at a different number and walk out with a different sense of how the narrative went. Okay, so director of product, CPO and head of HR come back, they talk through that we're getting closer. I love that it's keeping a concession ledger so we can actually see how it's going. I wish that was true in real life. This is one way that it's easier in this uh in this simulated environment. uh we are arguing over the clause for equity. I can live with a clause for more equity that's dependent on period of employment, I say, but I don't think it's reasonable to make it dependent on product revenue goals if the CPO's equity is not similarly tied. And the CPO dodges the question as real CPOS tend to do and then moves on and says fine, we won't we won't make that a thing. We are now close to an agreement as you can see from here. And at the end of the day, the only thing that's an issue is what if finance pushes back? And I provide a savvy approach in terms of how finance pushes back. What do we do? How do we hand? And so then they come back and they say, "Okay, basically we've got a deal." I say, "Let's get a deal done." It then gives me a scorecard. It gives me comp. It gives me uh a debrief on how it went and it gives me like madeup next steps for what I would do. I think this is the most useful bit. It talks through how I handled finance resist. It talks through like the good the way I anchored on local market data and insisted on par with executive incentives was really smart. Um it's just going to give you feedback and you can you can ask it at that point will give me more critical feedback, right? Like push me harder and it will do that. Last thing I want to show you is what happens if we run this exact same scenario token for token. Same like same answers all the way through but we used a different model. So, we're going to go and use Chad GPT40. Okay, here we are. Chad GPT40 up here. I am not going to rerun. These are all exactly the same. Exactly the same. Set it up exactly the same. Yep. Great. Go. It then prints out the entire contract and begins. What I notice immediately with 40 is that 40 has more personality. Look at the way the CPO talks. >> I've been in this game a long time, and I'll be straight with you. We think you're the right person, but we're not playing paying fantasy baseball salaries. That is 40 language. That is not 03 would never do that. So, the personality difference pops out right away. I come back as much as I can. I'm using token for token the same thing. So, we focus you on model differences. Um, the CPO continues to have personality. Head of HR continues to be very bland. And moving forward, I say, okay, I can, you know, negotiate. I can adjust. Again, I'm keeping this exactly the same as I did for the 03 example. The CPO then begins to praise me, which would not happen in real life and is one of our first indications that the model is not as smart as 03. This is a little bit out of character for a CPO, but he continues to be very, very chatty. I then give the same response, and what's interesting is I decided to give the same response to keep the model as clean as possible. But you'll notice that I gave that response when we were talking about clauses and 4 is not talking about clauses here. So this is me literally throwing a little bit of a curveball to keep the exact same token stream for the model to maintain the test as cleanly as possible. Okay, CPO comes back. Head of HR understands. And you know what's interesting? This is where the model really begins to diverge right here. They just agree. That did not happen with 03. One of my top takeaways looking at this example is that 4 shows its dumbness by being too agreeable in digital twin scenarios. If you were simulating this with 4, I worry you would walk away with a false idea of how tough these negotiations can be. I thought 03 did a much better job simulating how deep into the weed sometimes comp negotiations can go. And here I I just say I can get a deal done, right? like they've basically given me what I want. And if you walk out, you can see that I got more cash. The offer was at 190 and I walked out at 200 instead of 194. Essentially, you can literally measure in dollars the dumbness of the model. 40 gave me $6,000 that 03 was able to withhold for me because it was a sharper negotiator, which is actually better for you when you're looking to simulate. So, with that, there you go. We have three different actual conversation examples. We have a detailed breakdown of how to build a digital twin in chat GPT. You don't have to do anything. You don't have to run any code. You understand the principles behind that prompt. You understand how it hangs together. You understand how you could tweak it or adjust it for other scenarios. And the prompt itself is a super prompt, which means that you can run that prompt and give it other scenarios. Don't just do compensation. Don't just do product proposals. You can do it with sales negotiations. You can do it with job interviews. Anything that requires multiple parties to discuss and agree, you got options. You can run this prompt to simulate it. This is what I mean about the power of AI for digital twins. It is a huge deal. Most of us are sleeping on it. And I think part of it is it's been tricky to know how to prompt. And so this is my attempt to like bring the bridge over so that you can see like we're going to build the bridge. You can see how the prompt works and it's not a mystery anymore. Hope that was helpful. Tips.
