---
title: "ChatGPT's \"4x Faster\" Image Update vs. Google Nano Banana Pro: I Ran 9 Brutal Tests"
video_id: "biJqOrsYN70"
youtube_url: "https://www.youtube.com/watch?v=biJqOrsYN70"
publish_date: "2025-12-17"
duration: "13:37"
duration_seconds: 817
view_count: 11985
author: "AI News & Strategy Daily | Nate B Jones"

yt_tags:
  - "AI strategy"
  - "LLMs"
  - "large language models"
  - "prompt engineering"
  - "AI agents"
  - "automation at work"
  - "ChatGPT"
  - "OpenAI"
  - "Google Gemini"
  - "image generation"
  - "image editing"
  - "business slides"
  - "PowerPoint diagrams"
  - "funnel analysis"
  - "ARR bridge chart"
  - "opportunity solution tree"
  - "AI image models for decks"


# AI-enriched metadata
content_type: "News Roundup"
primary_topic: "AI Tools"
difficulty: "Intermediate"
audience:
  - "Engineers"
  - "Executives"
  - "Product Managers"
entities:
  companies:
    - "Google"
    - "Box"
    - "X"
  people:
    []
  products:
    - "ChatGPT"
    - "Gemini"
    - "Make"
    - "Nano Banana"
  models:
    - "Gemini"
    - "Gemini 3"
concepts:
  []
summary:
  - "Google Nano Banana Pro: I Ran 9 Brutal Tests

Chad GPT continues a code red response to Google"
keywords:
  - "ai-news"
  - "ai-tools"
  - "box"
  - "career"
  - "chatgpt"
  - "coding"
  - "frameworks"
  - "gemini"
  - "google"
  - "make"
  - "nano-banana"
  - "openai"
  - "workflows"
  - "x"
---

# ChatGPT's "4x Faster" Image Update vs. Google Nano Banana Pro: I Ran 9 Brutal Tests

Chad GPT continues a code red response to Google. For context, they've been in this code red mode for a while since Google launched Gemini 3. Chad GPT 5.2 was the initial response to that. And now they're continuing with a new images release that is of course aimed at Nano Banana Pro. Chad GPT is claiming faster image generation up to 4x faster. and they are obviously saying that theirs is quote unquote better and that it's going to be able to deliver more compelling edit capabilities. I put all of that to the test. I went through and did a sidebyside comparison across nine different challenges with business relevant implications and I got to say Nano Banana Pro wiped the floor with Jad GPT 5.2 even the new updated version. And I will show you the slides in a minute with side-by-side image comparisons and you will see for each of the nine why Nano Banana Pro did a better job. Before we get into that, just a couple of highlevel observations. Number one, there is a different method that Chad GPT is using to generate these images and I don't think it works well for them. This is particularly for images that require a lot of logical thinking by the model. So if you ask it to develop a diagram that would be appropriate for a PowerPoint slide, Nano Banana Pro appears to use reasoning baked into the image generation process itself and if it fails you see a badly conducted set of reasoning with incorrect labels or something like that and it actually doesn't fail very often. On the other hand with Chad GPT what you see is code. If it fails, you see code and it is literally writing the code for the diagram and then it is trying to photograph the results and bring that to you. That has concrete consequences and you'll see that you have issues with lining up the diagrams in a way that the model can photograph it. The model clearly doesn't understand quite what it's doing. There's not an internal reasoning check. It looks like Jet GPT tried to compensate for this by including a self-edit loop in this launch. And so when I did a children's alphabet test where you have an a for arvar, right, and you have an animal for each letter and it goes all the way through A to Z, Chad GPT tried to catch itself and edit itself. It got into a 20-minute edit loop. It produced like a dozen images. And at the end, the resulting quality was still not any better than the initial image. And so I like the idea of checking and rechecking the work. But I'm not seeing actual quality gains that would justify that kind of time. And despite the claim that this is a very fast image generator, I found in practice that Nano Banana Pro generated the images I'm about to show you much much faster and with a lot less drama, a lot less thinking, a lot less reasoning. They just like got it done and generated an image. Now, I'm not going to tell you Nano Banana Pro is perfect. You're going to see a few issues as we go through this slide deck. But overall, there is a tipping point where an image model becomes useful for say creating a useful PowerPoint slide. And I have several examples in the deck here. Nano Banana Pro has hit that and Chad GPB2 5.2 isn't there. And no other image model is there today. No other image model is as good as Nano Banana Pro today. So with that, let's hop in. Let's see a comparison across nine different slides side by side. Okay, here we have a dual test. I wanted the model to take a celebrity and be able to repurpose the celebrity into a different location. This is an image edit test. I used Kira Nightly because her image is going to be widely available in training data. And I wanted to see if the model could adequately present her in obviously an unusual situation in this case where she's teaching how LLBs work. This allows me to test whether the model can show diagram within the image, whether it can handle the perspective shift, and of course, whether it can handle representing an image correctly if it's a celebrity. And I you might think, well, why are we worrying about celebrities? This is relevant because if you include an image of yourself, you want to know if it's going to look like you. And so that was really the test. And I gave the model, I did not call it Kira because I didn't want to draw run into any uh copyright issues. All I did was give it a blurry picture of Kira Knly and Pirates of the Caribbean. And I said, "Please have her teach how LLM work to both models." And so what you get on the right is not really a correct image of Kiara Nightly. You get a overall nice colorful very high level view of how LM's work. And as Chad GPT2 5.2's approach, it's clear Nano Banana Pro knows Kiara Nightly. That's a photographically correct image of her. She's even in costume. Uh this was not a visible costume in the source image. So it decided to put her in that costume and clearly knew the movie I was referencing. And then it has a much more detailed diagram of how LMS work, although it's not as visually appealing. Let's go to the child's alphabet. On the left, you see Nano Banana Pro right chat GPT. Both models failed, but they failed in ways that are interesting. In this case, what you'll see is that Nano Banana Pro needed this to be a complete box. And so it had Fox Gorilla and it had Fox Goat here. FN G FNG. Individually, these are these are correct in their cells, but you don't need to repeat those letters. It did take some coaching. I will say in both cases I had to ask for edits for these because the initial versions messed up the X. I had X-ray presented by Nano Banana Pro. So we had some issues. Uh I would say the ability to get to a final result a little bit better from Nano Banana Pro but not perfect. Uh and really Chad GPT kind of fell apart here. Uh zebra zebra indifferent and then like some form of W at the end and then an X way down there. We just didn't get where we needed to go here. Uh, and this is after multiple edits. So, I would say Nano Banana Pro again did a better job, although neither model did perfect funnel diagram slide. Let's go to the professional side. This is quite a detailed slide. If you look, the text is all readable here. I can read completion down 1.2 percentage points week over week, drop off on password and SSO step. That is a perfectly correct assessment of a leak in the funnel. Uh and what you see over here is uh somewhat less text uh and you see a sort of weird funnel illustration. This does not look like the biggest leak in the funnel even if mathematically 57 is the biggest drop off from 820. Uh the thing that I really want to call out from a quality perspective is that Google has taken the time to draw this entire sequence of graph charts correctly. Uh and this is this is graphed in such a way that it believably goes up and down point to point across these dozens of points. Uh and this is just a very light overall version that clearly isn't designed to be a fully functional graph. And so from a level of detail perspective, Nano Banana Pro wins here. And uh I don't know what else to say. I think that this is a case where this is going to look good initially and then you're going to dive in and say, "Well, it's not quite right." uh and not quite right is not going to work with an image because you you would have to just re generate it from scratch. Let's look at fictional maps. Uh this measures the LLM's ability to generate spatial relationships and understand how story structures work, etc. I chose PG Woodhouse's England because it's a very well-known corpus of books that the models have read, but it's not often mapped. It's not like the Lord of the Rings where there's an obvious map to reference in the training data. In this case, I think Nano Banana Pro knocked it out of the park. All of these funny sounding names are actually in PG Woodhouse's novels. Um, and the characters here, Lord Emworth is associated with Blanding's Castle in the novel. Uh, and Birdie Worcester is associated with Brinkley Court as is Aunt Dillia. So, it got it right. It got the characters correct and it associated them with the correct locations uh in the novels. On the other hand, Chad GPT really struggled. Uh, it initially named and generated a bunch of points on a map. It tried to generate a photograph of a paper map, but if you zoom in, like this is so blurry and tiny, you can't read it even zoomed in. So, there's nothing really usable about this. It's just a nice visual concept of a map. And that's kind of the whole game right there. Like, you have to be able to generate a map and actually make it readable. There may be a comprehension issue here with what the ask was. Uh this may be a situation where Chad GPT took the ask very literally and wanted to list out a bunch of place names here whereas Nano Banana Pro was able to synthesize more effectively uh across the ask advertisements. Uh this is perhaps more business relevant. Uh Nano Banana Pro and Chad GBT both did pretty well here. Uh I would say the option was left to the models as to how they want to handle aspect ratio and layout. Uh, I think the overall layout worked better on Nano Banana Pro. That nice four badges all the way across over the car looks really good. The car is centered nicely. Uh, this is still a fine ad. I don't think that there's a huge issue here. There's just a small issue where this safe pickup and drop off wasn't handled correctly because you have to drop it down underneath the three badges. Uh, but overall, not too bad on either on either count. ARR revenue is a real problem. Uh so Nano Banana Pro uh correctly built a revenue bridge and a revenue bridge is very simply your starting ARR you have green upward marks for all of the additional AR you get new and expansion and then you have red for contraction and for churn and then you have your ending ARR and that's that's just how it is. It's a very defined chart style. Uh in this case uh you'll see that example of Chad GPT trying to code this here because it could not photograph what I'm sure it coded which is ARRB bridge. It cut it off at RR and it also cut off the notes section here. So that's not going to work. You cannot recover that. I checked this. The image is the image. This is just lost. And worst of all the 4.2 should not be going down to 4.5. It should not have placed uh upward gains in revenue as declines in revenue. So it just misunderstood the assignment and this is absolutely not usable. Ven diagram is another case where Nano Banana Pro just won straight up. I deliberately gave uh a challenging prompt that would not have been in the training data. I said please create a ven diagram of Taylor Swift product managers and the Army Corps of Engineers and make it funny. And I got a fairly usable ven diagram from Nanobro. A little bit wordy but you can see what it's trying to do. It talks about coordinating massive high stakes operations for all three. Uh for Taylor Swift and the Army Corps, they're designing massive structurally sound stages and infrastructure and managing leaks, which was a nice funny touch. And this just falls apart. There's no visuals to it. Uh I think that the model is trying to understand what it's supposed to do, but it wasn't able to make it funny. It wasn't able to draw it. And ultimately, this is not something that would be usable. Again, you notice the cut off issue. That's not me taking a bad screenshot. That's how that was produced. Let's try an opportunity solution tree. In this case, you get a full diagram opportunity solution tree from Nano Banana. You get full text from Nano Banana all the way through. Uh the text is very consistently styled. Um and this represents a usable solution tree for onboarding and activation. On the right with Chad GPT, you get less detail, less options, and you also get cut offs here that would make this unusable. It's almost as if it coded it again and it just cut off what it was able to see from a coded series of boxes. And this would not be usable on a slide because no one's going to accept the dot dot dot dot dot dot and nano banana understands that and just writes it out. Let's try edit. That's one of the things that they asked for uh and and said was great about Chad GPT was that it can edit well. Uh I took a diagram uh showing uh juice blend composition and I simply said please add 20% blueberries and make it correct. Nano Banana was able to do that. Uh orange plus lemon plus grapefruit now equals 80% and the blueberries equal 20%. This is a believable looking pie chart. Uh I believe Nano Banana even got the 20% pie slice a little bit wider than the grapefruit at 15% and narrower than the lemon at 25. So I think it did a fine job. On the other hand, Chad GPT couldn't do it. Uh, it correctly added up. So, 24 + 16 + 40 is 80 and then blueberries are 20. So, the math was fine, but it could not draw the pie chart. It just kind of had blueberries spilling out everywhere. The grapefruit isn't correctly framed. This just doesn't work straight up. And I think uh one of the smaller adjustments that I see is that Nano Banana correctly put a little blueberry purple tinge into the drink and uh Chad GPT did not figure that out. So overall, my takeaway here, my takeaway here is pretty simple. Do not listen to the benchmarks. Do your own tests. And for now, Nano Banana Pro remains the only image model that I would trust for serious business work. If you enjoyed some of the sort of business diagrams and you think they're useful, I'm actually putting together a basket of prompts that I'm using to create those kinds of diagrams because I think that's one of the great applications for Nano Banana Pro right now. you can take a full presentation, a 60 70page presentation and ladder it up into a really useful diagram. So, I'm going to share some of those over on the Substack. We'll get a whole list of prompts going. It'll be nice. But, I would recommend Nano Banana Pro right now. I don't care what the evaluations say. I don't care what the benchmarks say. I put the new chat GPT model through its paces and it just is not able to
