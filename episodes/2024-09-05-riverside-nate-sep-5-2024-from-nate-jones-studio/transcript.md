---
title: "Riverside Nate Sep 5 2024 from Nate Jones Studio"
video_id: "zLSSXIbRlW0"
youtube_url: "https://www.youtube.com/watch?v=zLSSXIbRlW0"
substack_url: null
publish_date: "2024-09-05"
duration: "6:47"
duration_seconds: 407
view_count: 210
author: "AI News & Strategy Daily | Nate B Jones"

yt_tags:
  []



# AI-enriched metadata
content_type: "News Roundup"
primary_topic: "AI Strategy"
difficulty: "Intermediate"
audience:
  - "Engineers"
  - "Executives"
  - "Founders"
entities:
  companies:
    - "Anthropic"
    - "GitHub"
  people:
    - "Nate Jones"
  products:
    - "Claude"
    - "Make"
  models:
    []
concepts:
  []
summary:
  []
keywords:
  - "ai-agents"
  - "ai-news"
  - "ai-strategy"
  - "ai-tools"
  - "anthropic"
  - "claude"
  - "coding"
  - "deep-dives"
  - "frameworks"
  - "github"
  - "leadership"
  - "make"
  - "product-management"
  - "tutorials"
  - "workflows"
---

# Riverside Nate Sep 5 2024 from Nate Jones Studio

real quick two pieces of AI news and one very juicy AI rumor I don't think we can classify it as news we'll get to that at the end so first Claud for Enterprise released so as you may know the way you monetize llms is fundamentally not through all these folks who are charging consumers 10 20 bucks a month that gets you into millions maybe hundreds of millions of dollars maybe even billions but it doesn't justify the immense cost that goes into training these models to get that kind of Roi you need to get very large companies to pay you very large sums of money huge huge huge contract values and how you get there is by building tools that enterprises can use and so we see open AI going into the Enterprise space and now this is the news we see Claude going into the Enterprise space so anthropic released Claud for Enterprise uh which if you dig in looks like a massive context window 500,000 tokens which is uh I don't know equivalent to dozens of 100 plus page documents right I think of it as like an absolutely massive window where you can put thousands of pages through uh or even code bases right entire code bases sometimes fit into 500,000 tokens depending on the size now in Enterprise codebase probably not and that brings me to the second feature they are enabling you to integrate with GitHub uh so engineering teams can sync their GitHub repositories with claw and that means that you can work alongside the codebase um and quickly on board if new Engineers need to understand the codebase well means you can make edits with code Etc they're teasing additional integration soon they say GitHub is in beta and they're looking for partners to sort of help them test it out we'll see how this goes this is another step in the direction of making these models useful enough to Enterprise that you actually can earn very large contract values with them so essentially what anthropic is betting here is that a lot of the value comes from Sonet 3.5s uh documented expertise in writing code and if they can get you into GitHub syncing with GitHub get you writing code uh using their model they think that that's going to dramatically increase the value now obviously that's not the only thing that you can do because it's an llm you can also bring in sales calls and other things um and so I think part of what they're going for here is that they are going to become a hub where you can start to collaborate they're using their team features uh and pull synced sources in pull very large uh tokenized contexts in so basically pull in large documents uh and use all of that as a way to get you to put more of your thinking and knowledge into anthropic for analysis reprocessing summarization Etc they want to become the hub for work so we'll see if that works but that's sort of their play when you look at the next piece of AI news it's a whole lot different and it reminds you how Wild this space is so this is from a company named Altera they have been doing uh simulations in Minecraft trying to understand the balance between Free Will and uh a desire for social good on the part of autonomous AI agents so they have these AI Agents set up in Minecraft they're giving them different sort of waiting on their personality scales and they're looking to see what happens uh they have had uh I think the largest simulation run so far a thousand autonomous agents building worlds uh open-ended not necessarily goal oriented and what you see is some really humanlike behavior from these agents which doesn't necessarily mean that they are humanlike in the sense that they have uh you know true thought patterns Etc it more means that they're able to get the waiting correct so it simulates human behavior so for instance uh they had a farmer decide to go on a trip after hearing Tales From Another character about far away places and then the farmer decided to stay because the community persuaded the farmer agent that it needed to grow food for the rest of the community they had uh governance uh Democratic uh debates and uh Amendments of constitutions based on values of these agents I'm going to link the full article there's a lot of wild stuff in here and I think I think the takeaway for me is not the particular actions these agents took because you rerun the simulation and you're going to get something different these are autonomous creatures instead the interesting thing is that we're getting better at adjusting the weight so that we can mimic humanlike behavior for better and For Worse um so we we will see where that all ends up altera's ultimate goal is to quote unquote build a digital human I'm not sure that they know what that means yet but they're basically using these autonomous agents is a way of testing out their the sort of incentives involved in Waiting group versus autonomous cooperation I think it's going to be a factor when you have multi-agent workflows and that's something that I expect to see a lot more of in the next year and so that's part of why I'm calling it out okay last thing I promised you a rumor the rumor is coming from open AI at a presentation they gave in Japan uh yesterday where the CEO or lead exec for open AI Japan Ops uh tadada Nagasaki teased a new llm coming uh called GPT next which he claimed was related to strawberry and which he said was a 100 times more powerful than uh gp4 I don't know if he was allowed to say that I don't know if that was approved back at headquarters everyone is asking questions about it I tend to take those kinds of leaks from conferences with like the biggest block of salt it's so difficult to know in advance what is actually going to be delivered frankly it's difficult to know what 100x performance even means how do you evaluate 100x performance over gp4 what does that mean does that mean like a larger context window does that mean faster does that mean more capable of solving a particular set of Novel puzzles he doesn't clarify so I categorize it in the rumor mail I share it because rumors are all we've got sometimes to understand what's coming next on a technology front that is changing all of our lives and so the best thing we can do is understand what's coming take it with a block of salt and see how future news shapes our understanding of next releases from open Ai and frankly from other other startups as well okay so there you go two pieces of news and one rumor
