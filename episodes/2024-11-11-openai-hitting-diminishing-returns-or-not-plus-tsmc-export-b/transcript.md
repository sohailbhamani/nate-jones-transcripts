---
title: "OpenAI Hitting Diminishing Returns or Not plus TSMC export ban to China plus tariffs and TSMC"
video_id: "Ey811OUpX70"
youtube_url: "https://www.youtube.com/watch?v=Ey811OUpX70"
substack_url: null
publish_date: "2024-11-11"
duration: "7:37"
view_count: 1040



# AI-enriched metadata
content_type: "News Roundup"
primary_topic: "AI Strategy"
difficulty: "Intermediate"
audience:
  - "Engineers"
  - "Executives"
  - "Product Managers"
entities:
  companies:
    - "OpenAI"
    - "TSMC"
  people:
    []
  products:
    - "Make"
    - "o1"
  models:
    - "o1"
concepts:
  []
summary:
  - "# OpenAI Hitting Diminishing Returns or Not plus TSMC export ban to China plus tariffs and TSMC

We have three really big pieces of AI news today"
keywords:
  - "ai-news"
  - "coding"
  - "deep-dives"
  - "frameworks"
  - "leadership"
  - "make"
  - "o1"
  - "openai"
  - "product-management"
  - "prompting"
  - "tsmc"
---

# OpenAI Hitting Diminishing Returns or Not plus TSMC export ban to China plus tariffs and TSMC

We have three really big pieces of AI news today. Number one, over the weekend, a publication called The Information broke the news that OpenAI was seeing diminishing returns on their work with AI. And this was based apparently on anonymous conversations with OpenAI employees and specifically on the results of the 20% finished model training run for the o1 model the speculation is the 20 mark is roughly where GPT 4.5 would be and what the leakers suggested is that this was only like marginally better not necessarily better at all at code etc well a whole bunch of people and not just from open AI spent the weekend pushing back I mean, you expect the leadership of OpenAI to push back, right? The VP of product basically said this is not true without directly addressing it. And what I thought was interesting is it wasn't just the OpenAI top brass. It was also a bunch of other folks in the industry who really are only thinking about what is the correct solution for artificial general intelligence and do we hit a wall here that would prevent us getting there? And so the information broke earlier in the weekend and by Sunday, it was evident that most of the people who were well-versed in AI and who are not at OpenAI were coming to OpenAI's defense and essentially saying, you know what? The information got this one wrong. And the reason they got it wrong is that they're confusing large language models with the reasoning that 01 has simply because 01 presents as a reasoning model. So when we're using 01 preview, we type it into the same chatbot window, but it does reasoning at the time of inference so when you type it in it can go and explore different chains of thought and reverse and change itself reverse and change itself reverse and change itself and use what are called reasoning tokens to eventually get to the correct answer if you ever want to see how that works i'll give you a really simple prompt for that just ask it to do a fairly complicated discount flow analysis in finance or ask it to do a compound annual growth return in finance it knows those formulas but if you don't give it too much information, it has to infer a lot. And so it will, and you will actually see it sometimes correct itself and you'll see it eventually lay out a really clear methodology for how it solves the problem. If you give that same problem to 4.0, it will not work nearly as well. In fact, I did that last night and what I saw was clearly an actual rational response from 0.1 and clearly much more simple next token prediction from 4.0. And so I think what, The OpenAI's VP of products got it right. At the end of the day, the question of whether an LLM is hitting a diminishing rate of return on training on data is different than whether or not you are getting more value out of reasoning. And OpenAI has been telegraphing for months that they see a lot of the value in scaling intelligence as scaling at the time of inference or scaling reasoning. So we will see. But It just looks like the information got very, very excited about reporting something that they thought was scandalous and surprising and rushed it to print a little bit too much because it gave the impression that OpenAI was out of juice. And the reality is OpenAI is just at the beginning of releasing something interesting. And I actually think that is one of the things that makes this leak seem a little bit malicious. O1, the full O1 model is rumored to be released this week. I've been doing this for a bit. I've been seeing these rumors come out. So that's not that surprising that they're rumoring it this week. Maybe it will happen this week, maybe not. But it's supposed to happen by the end of the year. We're coming up into the teeth of the end of the year. And it is very interesting that they would choose to play for clicks in this way right now. All right, I've said enough about that. Number two, the US has ordered TSMC to halt export of, roughly speaking, AI chips to China. If you want to dig into the details, it's chips below the 7 nanometer architecture, specifically going for GPUs used in AI applications. And you might wonder, I wondered, how on earth is the United States government able to restrict exports from Taiwan to China? It doesn't make sense. Well, it turns out that we have a special set of rules called the EAR, the Export Administrative something. I'm going to have to look this up a second. It's the Export Administrative Rules that are authorized by the Export Control Reform Act of 2018. I did my research on this. And basically what it does is it allows you to, if you are the US government, regulate the export from other countries of things that are produced using US tech. And in this case, the chips have US design input. A lot of the sort of routine in TSMC is you get the chip design from the US and then you manufacture it in Taiwan. On that basis of the intellectual property and the chips, the Chamber of Commerce, the US Department of Commerce is able to regulate export of the chips from Taiwan. And that's what they're doing. And the reason they did it, and this is not as widely reported, is that a chip that had gone to a Chinese customer, which was legal at the time, ended up in a Huawei device, which is not legal because the US has put Huawei on a export restrictions list. And so basically, seeing that like there's some unlicensed transfer of these chips inside China, the Department of Commerce basically said, no, just stop exporting to China until we figure this out. And so that's what, as of today, TSMC is doing. Now, separately, people are wondering how tariffs, if they come, will affect AI chip production. And one of the plays for a lot of other materials is that people ask themselves, can we do final assembly in the US? In this case, Taiwan has sent a very clear signal that you won't be able to because it is said explicitly that they have regulations on the books in Taiwan that say that advanced chip manufacturing capabilities, in this case, the current top generation is two nanometer, that they will not be able to make them elsewhere because they have regulations saying that capability stays on Taiwanese soil. So we will see, we have some competing regulations. And in the meantime, I'm hoping that these weird photos that OpenAI employees continue to post about the Orion Nebula end up meaning something, right? Like surely they can't just post pictures of the stars and not release models. We will see.
