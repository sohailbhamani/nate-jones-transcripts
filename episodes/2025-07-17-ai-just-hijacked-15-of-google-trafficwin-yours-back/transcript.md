---
title: "AI Just Hijacked 15% of Google Traffic—Win Yours Back"
video_id: "hW5ne_14OQg"
youtube_url: "https://www.youtube.com/watch?v=hW5ne_14OQg"
substack_url: null
publish_date: "2025-07-17"
duration: "16:03"
duration_seconds: 963
view_count: 13319
author: "AI News & Strategy Daily | Nate B Jones"

yt_tags:
  - "AI Impact"
  - "AI Traffic"
  - "Algorithm Changes"
  - "Content Strategy"
  - "Conversion Rates"
  - "Digital Growth"
  - "Digital Marketing"
  - "Google SEO"
  - "Marketing Automation"
  - "Online Visibility"
  - "Rank Improvement"
  - "SEO Hacks"
  - "Search Engine Tips"
  - "Search Trends"
  - "Traffic Recovery"
  - "User Engagement"
  - "Web Analytics"
  - "Website Optimization"
  - "Website Traffic"



# AI-enriched metadata
content_type: "Case Study"
primary_topic: "AI Strategy"
difficulty: "Advanced"
audience:
  - "Engineers"
  - "Executives"
  - "Product Managers"
entities:
  companies:
    - "Anthropic"
    - "Google"
    - "X"
  people:
    []
  products:
    - "ChatGPT"
    - "Claude"
    - "Make"
    - "Projects"
  models:
    []
concepts:
  - "As your biggest readers"
summary:
  - "# AI Just Hijacked 15% of Google Traffic—Win Yours Back

15% of Google's clicks disappeared last year"
keywords:
  - "ai-news"
  - "ai-strategy"
  - "ai-tools"
  - "anthropic"
  - "chatgpt"
  - "claude"
  - "coding"
  - "frameworks"
  - "google"
  - "leadership"
  - "make"
  - "openai"
  - "product-management"
  - "projects"
  - "x"
---

# AI Just Hijacked 15% of Google Traffic—Win Yours Back

15% of Google's clicks disappeared last year. 15% and that's on average. It gets worse in some industries. Where's it going? There's a lot of chatter about this being Chat GPT's fault. It's not. Chad GPT is roughly 1 or 2% of search traffic right now. Now, it's growing but it's not taking over Google yet. And this is not because people have stopped searching on Google either because Google is still seeing roughly 9 billion searches per year which absolutely dwarfs the numbers that Chad GPT has. Absolutely dwarfs them. So what is it? How is this happening? It's happening because the most used AI on the planet is those silly little Google AI summaries. And they're used to summarize domain completion or simple fact queries that dominate Google. As an example medical questions, 30% decline in click-through from Google search page. Do you know why? The what is my rash question is now getting answered by Google AI. That that probably should scare you a little bit. It scares me a little bit, but that's what's happening. I want to talk about how content architecture needs to change because this world is changing quickly. Yes that GPT may have 1 or 2% or whatever it is a small singledigit number share of traffic for search but that traffic is very high intent very sophisticated very focused on high consideration projects projects products purchases byfunnel this content architecture strategy that I'm going to outline works for Google and sort of positioning yourself for that Google AI answer which is de facto now the first position in search it also works for surfacing you as a brand whether that's your personal brand or your company brand in chat GPT answers as well. I want to break this down into a 101 section and we'll call it a 301 section for engineering. The first key to understand is that you need to think about AI first content architecture. You need to think about your content as an AI bot thinks about it. Whether that's from Google or ChatgPT or Anthropic or some other place. Your brand is now a parameter. It's not a web page. Your brand needs to exist as a parameter in an LLM, whether that's Google's or somebody else's. I would suggest one way to do that is to create one definitive description of your brand that's between 5, 7, 8 words long, such as, you know Acme, the automated compliance platform for healthcare, whatever it is, right? deploy the same phrase verbatim in schema markup schema markups PR boilerplates partner directories everywhere you can use the same phrase it's so consistent that models cannot describe your category without evoking the latent space that has that 5 to seven word phrase and when you get your brand into Wikipedia articles get your brand in with that parameterized phrase like getting into Wikipedia articles is not a new strategy. I'm not claiming it's new, but you need to think about it as essentially seating citations for that parameter to strengthen the value of that parameter for the LLM. It's a different way of thinking about how SEO works. Every month, you can test this. You can ask the chatbot or ask Google list companies that and then define your core value proposition. And if it's successful, your brand appears naturally in the responses. it comes back and you want to iterate that until it sticks across every major model. Another thing that I think people overlook is that they don't think about their brands as entities. They don't think about aligning their brands into a single entity. And I'll explain what I mean by that. You want to audit your top 20 brand mention using Google's natural language API. You want to create a single source of truth description document for your brand. You need to send update requests to any site with an outdated description because your goal is to give a single brand entity statement consistent representation across the web so it maximizes the odds you'll appear in something like a Google summary in the correct way. And focus on the five highest authority sites mentioning you. This is not new either. Obviously, you focus on high authority sites. The key is to make sure the exact same roughly 50word company description or brand description is everywhere because again you are implanting that into the LLM's parameters. The LM's parameters will now have a handy six or seven word tag about you, a handy entity description about you. You want identical entity recognition and regurgitation across multiple LLMs. And that's how you will know you've done this. Again, you should be able to test this monthly. Another way to test this people don't always feel comfortable with this one, but it's a really good one. The delete me test. You want to name a method that you are using for solving a customer's problem. The Acme method for continuous compliance, right? Something like that where you implant the brand in a five or six phrase framework that describes your method. Again, use it identically. Use it everywhere. Make it a category standard. You're coining terms. This is defining the category for LLMs because they are your readers. You are building for LLM attention. Assume that most of the attention your brand is getting is now from LLM. Get customers to use your terms, your Acme method terms in their case studies, and you want to get, I want to say, 40 or 50 pieces around the internet before it starts to really pick up. Eventually, AI will explain your method when you delete your brand. That's how you know it worked. You'll be able to say explain this to me and to talk about the method and it will explain back your method and it may even reference your brand without being asked because your brand is so tightly associated with the method you have used to define the cate. I want you to also think about FAQs as the new way to drive news. So previously it was all about fresh content on a blog. Now think about that Google AI search results. It is almost an FAQ type response. It is short snippets. Identify high value social threads where customers are already outputting their own personally written tokens weekly in your space about whatever they care about. Complaints questions, concerns. You want to bring your own insights to the table. And then you want to build content that thoughtfully responds to top questions in the space in a relevant FAQ like format. So, it looks like one, you're the helpful expert. You're responding to customers. You become a go-to source where LLMs can see questions in one part of the internet and the answers to those questions consistently appear on your site. Models start to site you and they may even start to site your responses on forum posting. So if this is on Reddit if this is on X, if this is even on searchable parts of Tik Tok, you may come back and see that your forum posts as you respond are becoming ways to reinforce your brand's authority in the model's view that it gets picked up and put into Google search. The FAQ mindset works both for content you host and for content you reply to. And so you can gather up that content into an FAQ post with citations to the original questioners. You can also directly answer them. Both are valuable. Let's do some advanced sort of co building here. I mentioned prompt injection as PR. Basically, you want to create a cheat sheet for AI that says here's how to talk about the company and it's supposed to be designed for machines to quote. How do you do that? You build a structured data file in your root domain that acts as a machine readable press release. It's not hidden. It's actually a publicly accessible piece of JSON that contains canonical descriptions, key differentiator, comparison matrices, all the things you would put into a press release for the news. It's for LLM attention. The technical challenge is to make sure it's discoverable. Put it in your robots.ext. Submit it to common crawl. Get educational sites to maybe site it. Models will weight the structured JSON blobs heavily because they're really unambiguous and easy for the model to parse. You're basically creating training data that is impossible to misinterpret. Why does this beat traditional SEO? Because structured data has higher confidence scores in training. Machines prefer JSON to narrative text because they can read it more easily and updates will propagate faster than just organic crawling. Also you control the exact phrasing models will use in a way that you can't when you're just putting out press releases. Let's talk about widgets. Chat GPT can summarize your blog post, but if you really want to drive clicks, do you know what it can't do? It cannot run a mortgage calculator. It cannot run a diagnose me bot. I don't think anyone would ever build that because of liability, but as an example interactive tools force a click. If you are building JavaScript applications that require real-time user input and return personalized results, can't get that in a summary. So if you want to drive traffic, if your business depends on driving traffic, yes, you want to play the game of being present as a brand, but eventually you need the click. Make those widgets unexplainable without an interaction. They need to process user specific input and variables with proprietary math or algorithms and as we have done for years, gate the results behind email capture. But you have to show enough value along the way to prove that it works and earn the email. Not new. The moat is that interaction is impossible through a chatbot. So yes, you interact with a chatbot by typing in it. You interact with Google as a search bot by a search bar by typing in it. You cannot interact with the mortgage calculator by typing in the Google search bar by by typing in chat GPT. You can't premputee and cache that if you're an LL. You just have to know it's there. And so the magic secret sauce if you're depending on organic traffic is to have visibility through what I've described with this sort of brand placement, entity placement, etc. And then make sure that you have good reasons why humans have to click so you earn the human attention. Widgets earn human attention if they actually add value. You want to make sure that they are incredibly useful and personalized so that people feel like it's worth the click and that you deliver on that payoff. Otherwise they're going to kick back. One thing I will call out, let's say you have the widget, you have the traffic. AI needs fresh info from you. It checks your website in real time when it's having a conversation. Let's say you're in chat GPT or even increasingly following up on the conversation inside the Google search results page. If your site is slow, they're going to give up and use old information about you instead. So you need to make sure that you have edge compute infrastructure that serves AI specific endpoints maybe in under 50 milliseconds like really really fast to separate your machine readable endpoints as super super accessible and consumable by AI versus a human UI. I've increasingly seen value in assuming that your data needs to be consumed through a separate interface by AI. And this is a great example of essentially building the web for AI. build it on the edge dedicated data endpoints with JSON responses. You want to make sure that you have precomputed responses right there and update them frequently. You want to make sure you are caching effectively so that you don't have to go back and get it from the from the source when it's actually being requested by the AI in the middle of a chat. This is all new stuff like this is stuff that we have to actually experiment with. But the basic principle is that AI needs real-time access to sites. Most sites don't build for it. And the sites that do build for it, the sites that build assuming you need LLM readable data as a primary ingredient in your site, are going to win. The next one I want to give you is think about how you're using your robots.ext file. You want to create a machine readable license that grants AI platform specific rights to your content in exchange for attribution. Because guess what? Machines are going to crawl that and they're going to take it seriously. you will actually get a chance to surface in AI conversations based on the AI's assessment of your site which includes your robots.ext file where you can lay out a contract with AI. It's a little bit of a game that you're playing but you're basically saying, "Hey AI, I know you're here. I am going to lay out all of this content for you, but I'm asking in return that you specifically give my site attribution when you do this." And you want to make sure that you are very explicit about that and you're very clear about that and that you're also clear about the consequences if you routinely see models that take your content and do not site you as a brand and you can cut off crawling from those sites and you may actually list that because one of the things that a LLM may do is it may see LLM know what they are like they know they're anthropic they know they're they're chat GPT if the LLM sees that you will cut off access and that you have done so with other models before it will be like I don't want Claude to get cut off. I'm going to sort of honor this contract and I'm going to go back and I'm going to cite the brand. It's a little bit of prompting and prompt injection inside the robots.ext file. Let's get on to the next one. You want to use AI to test AI visibility. This is gets right back to validation. One of the things I keep emphasizing is that in the world of AI, you are deploying faster but only if you validate well. You should be building automated pipelines that generate query variants using GPT4 or some other model and test all of those variants across major AI platforms using a browser automation. And then you want to parse the responses at scale to see how many of them have brand mentions, how many of them have brand positions, how many of them have competitive context, how many have your value differentiation, your value proposition, how you differentiate. And then you want to be storing these results and baselining and looking at trend analysis so you can see if you've been investing heavily in entity positioning that your brand and your 50word company description are actually coming through more consistently over time. If you're not measuring this with a pipeline, you're just guessing. All right, this has gone on long enough. Last thing I want to call out, you want to be looking at share of voice. And it looks different in the AI age. What you're going to need is a distributed scraping system that queries AI platforms, which I've already talked about for your brand, but think about it for category queries, not just for your brand. So, look at category queries that you care about being ranking for, you care about responding to, you care about being in position to answer, and consistently baseline them. You can use LLM to build custom share voice dashboards that are better than what consultants will give you today. And you can actually see in real time how your category share of voice is changing as you do this stuff. And I would encourage you to think about doing this because consultants are not necessarily putting all of the pieces together yet. They're often bolting AI over the top of a traditional SEO strategy. And one of my key contentions throughout this piece is that you need to be thinking about AI from the ground up as a new kind of content architecture. Think of LLMs fundamentally as your biggest readers. How do you change your content so it's more readable for LLMs? And you'll notice none of what I've proposed actually prevents humans from reading your site. I am not proposing anything that makes it harder for humans to read and understand what you offer. I'm just asking you to treat LLM as first class citizens. These aren't theoretical strategies. Brands that implement this can literally see their brand position shift over time. AI is changing fast enough and AI is crawling enough that this is a malleable search space. This is where SEO was 20 years ago. You have the chance to get ahead now before a bunch of brands take this and just make this table stakes. So, I don't know maybe you should. Twos.
